<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models – Theory and Case Studies in R</title>
<meta name="author" content="Olivier Gimenez">
<meta name="description" content="1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to...">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models – Theory and Case Studies in R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://oliviergimenez.github.io/bayesian-cr-workshop/crashcourse.html">
<meta property="og:image" content="https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png">
<meta property="og:description" content="1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 1 Bayesian statistics &amp; MCMC | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models – Theory and Case Studies in R">
<meta name="twitter:description" content="1.1 Introduction In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to...">
<meta name="twitter:image" content="https://oliviergimenez.github.io/bayesian-cr-workshop//images/satellite.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs/header-attrs.js"></script><script src="libs/jquery/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap/bootstrap.bundle.min.js"></script><script src="libs/bs3compat/tabs.js"></script><script src="libs/bs3compat/bs3compat.js"></script><link href="libs/bs4_book/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book/bs4_book.js"></script><script src="libs/kePrint/kePrint.js"></script><link href="libs/lightable/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models – Theory and Case Studies in R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="about-the-author.html">About the Author</a></li>
<li class="book-part">Theory</li>
<li><a class="active" href="crashcourse.html"><span class="header-section-number">1</span> Bayesian statistics &amp; MCMC</a></li>
<li><a class="" href="intronimble.html"><span class="header-section-number">2</span> Introduction to Nimble</a></li>
<li><a class="" href="hmmcapturerecapture.html"><span class="header-section-number">3</span> Hidden Markov models</a></li>
<li><a class="" href="survival.html"><span class="header-section-number">4</span> Survival</a></li>
<li><a class="" href="transition.html"><span class="header-section-number">5</span> Transition</a></li>
<li><a class="" href="covariates.html"><span class="header-section-number">6</span> Covariates</a></li>
<li><a class="" href="uncertainty.html"><span class="header-section-number">7</span> Uncertainty in state assignment</a></li>
<li><a class="" href="abundance.html"><span class="header-section-number">8</span> Abundance</a></li>
<li><a class="" href="hsmm.html"><span class="header-section-number">9</span> Hidden semi-Markov models</a></li>
<li><a class="" href="states.html"><span class="header-section-number">10</span> Hidden states</a></li>
<li><a class="" href="speed.html"><span class="header-section-number">11</span> Speed up MCMC</a></li>
<li><a class="" href="conclusions.html"><span class="header-section-number">12</span> Conclusions</a></li>
<li class="book-part">Case studies</li>
<li><a class="" href="senescence.html"><span class="header-section-number">13</span> Actuarial senescence</a></li>
<li><a class="" href="heterogeneity.html"><span class="header-section-number">14</span> Individual heterogeneity</a></li>
<li><a class="" href="tradeoffs.html"><span class="header-section-number">15</span> Life-history tradeoffs</a></li>
<li><a class="" href="breeding.html"><span class="header-section-number">16</span> Breeding dynamics</a></li>
<li><a class="" href="rd.html"><span class="header-section-number">17</span> Robust design</a></li>
<li><a class="" href="stopover.html"><span class="header-section-number">18</span> Stopover duration</a></li>
<li><a class="" href="disease.html"><span class="header-section-number">19</span> Disease dynamics</a></li>
<li><a class="" href="sex.html"><span class="header-section-number">20</span> Sex uncertainty</a></li>
<li><a class="" href="dependence.html"><span class="header-section-number">21</span> Dependence among individuals</a></li>
<li><a class="" href="covariateselection.html"><span class="header-section-number">22</span> Individual and temporal variability</a></li>
<li><a class="" href="mortalities.html"><span class="header-section-number">23</span> Cause-specific mortalities</a></li>
<li><a class="" href="prevalence.html"><span class="header-section-number">24</span> Prevalence</a></li>
<li><a class="" href="faq.html">FAQ</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/oliviergimenez/banana-book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="crashcourse" class="section level1" number="1">
<h1>
<span class="header-section-number">1</span> Bayesian statistics &amp; MCMC<a class="anchor" aria-label="anchor" href="#crashcourse"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction" class="section level2" number="1.1">
<h2>
<span class="header-section-number">1.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction"><i class="fas fa-link"></i></a>
</h2>
<p>In this first chapter, you will learn what the Bayesian theory is, and how you may use it with a simple example. You will also see how to implement simulation algorithms to implement the Bayesian method for more complex analyses. This is not an exhaustive treatment of Bayesian statistics, but you should get what you need to navigate through the rest of the book.</p>
</div>
<div id="bayes-theorem" class="section level2" number="1.2">
<h2>
<span class="header-section-number">1.2</span> Bayes’ theorem<a class="anchor" aria-label="anchor" href="#bayes-theorem"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Ajouter quelque chose sur la démarche scientifique?</strong></p>
<p>Let’s not wait any longer and jump into it. Bayesian statistics relies on the Bayes’ theorem named after Reverend Bayes. <strong>expliquer avec des mots ce que fait ce théorème, puis donner la formule mathématique</strong></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="images/amazing-thomas-bayes-illustration.jpg" alt="Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)" width="70%"><p class="caption">
Figure 1.1: Cartoon of Thomas Bayes with Bayes’ theorem in background. Source: <a href="https://www.elmhurst.edu/blog/thomas-bayes/">James Kulich</a>
</p>
</div>
<p>The Bayes’ theorem states that for events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we have:
<span class="math display">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}\]</span>
It is all about conditional probabilities, which are not that easy to understand. <strong>What are conditional probabilities? Link towards nice videos</strong>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="images/bayes_neon.jpeg" alt="Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)" width="400"><p class="caption">
Figure 1.2: Bayes’ theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Wikipedia</a>
</p>
</div>
<p>I don’t know about you, but I have a hard time not messing the letters around. It is easier to remember Bayes’ theorem written like this:</p>
<p><span class="math display">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>
The <em>hypothesis</em> is what you want to learn about using the data. For capture-recapture models, the <em>hypothesis</em> is a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. <strong>Citer Taj Mahr comme source</strong>. Bayes’ theorem tells you the probability of the hypothesis given the data. This is great because think about it, what is doing science after all? We’d like to know how plausible is some hypothesis given the data? <strong>dire des trucs sur les termes de droite</strong> In that respect, the Bayesian reasoning matches the scientific reasoning. You might ask then, why is Bayesian statistics not the default in statistics? Clearly, until recently, there were practical problems to implement the Bayesian approach. Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last three decades. Also, because of futile wars between (male) statisticians, little progress was made for over two centuries. <strong>en dire un peu plus sur ces guerres</strong></p>
</div>
<div id="what-is-the-bayesian-approach" class="section level2" number="1.3">
<h2>
<span class="header-section-number">1.3</span> What is the Bayesian approach?<a class="anchor" aria-label="anchor" href="#what-is-the-bayesian-approach"><i class="fas fa-link"></i></a>
</h2>
<p>Typical statistical problems involve estimating parameter(s) <span class="math inline">\(\theta\)</span> with available data. To do so, you might be more used to the frequentist rather than the Bayesian method. The frequentist approach, and in particular maximum likelihood estimation (MLE), assumes that the parameters are fixed, and have unknown values to be estimated. Therefore classical estimates are generally point estimates of the parameters of interest. In contrast, the Bayesian approach assumes that the parameters are not fixed but have some fixed unknown distribution – a distribution for the parameter. <strong>qu’entend-on par distribution?</strong></p>
<p>The Bayesian approach is based upon the idea that you, the experimenter, begin with some prior beliefs about the system. In other words, you never start from scratch. Then you collect data and update your prior beliefs on the basis of observations. These observations might arise from field or lab work. This updating process is based upon the Bayes’ theorem which we’ve seen earlier:</p>
<p><span class="math display">\[\Pr(A \mid B) = \frac{\Pr(B \mid A) \; \Pr(A)}{\Pr(B)}\]</span>
Loosely, let’s say <span class="math inline">\(A = \theta\)</span> and <span class="math inline">\(B = \text{data}\)</span>, then the Bayes’ theorem gives you a way to estimate parameter <span class="math inline">\(\theta\)</span> given the data you have. Indeed, the formula becomes:</p>
<p><span class="math display">\[{\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \; \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}.\]</span>
Let’s spend some time going through each quantity in this formula.</p>
<p>On the left-hand side, we have the <span class="math inline">\(\color{red}{\text{posterior distribution}}\)</span>. It represents what you know after having seen the data. This is the basis for inference and clearly what you’re after, a distribution, possibly multivariate if you have more than one parameter.</p>
<p>On the right-hand side, there is the <span class="math inline">\(\color{blue}{\text{likelihood}}\)</span>. This quantity is the same as in the MLE approach. It captures the information you have in your data, given a model parameterized with <span class="math inline">\(\theta\)</span>.</p>
<p>Then we have the <span class="math inline">\(\color{green}{\text{prior distribution}}\)</span>. This quantity represents what you know before seeing the data. This is the source of much discussion about the Bayesian approach. We’ll get back to it at length.</p>
<p>Last, we have <span class="math inline">\(\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}\)</span> which is a <span class="math inline">\(N\)</span>-dimensional integral if <span class="math inline">\(\theta = \theta_1, \ldots, \theta_N\)</span>. This quantity is difficult, if not impossible, to calculate. This is one of the reasons why the Bayesian method wasn’t used until recently. And this is the reason why we need simulation algorithms to estimate posterior distributions. <strong>simulation ou stochastic algorithms? si stochastic, expliquer</strong></p>
</div>
<div id="approximating-posterior-distributions-via-numerical-integration" class="section level2" number="1.4">
<h2>
<span class="header-section-number">1.4</span> Approximating posterior distributions via numerical integration<a class="anchor" aria-label="anchor" href="#approximating-posterior-distributions-via-numerical-integration"><i class="fas fa-link"></i></a>
</h2>
<p>Let’s take an example. Say we capture, mark and release <span class="math inline">\(n = 57\)</span> animals at the beginning of a winter, out of which we recapture <span class="math inline">\(y = 19\)</span> animals alive<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;We used this example in King et al. 2009&lt;/p&gt;"><sup>1</sup></a>. We’d like to estimate winter survival <span class="math inline">\(\theta\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">19</span> <span class="co"># nb of success</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">57</span> <span class="co"># nb of attempts</span></code></pre></div>
<p><strong>Préciser quelque part qu’on prend formalisme McElreath pour présenter les modèles</strong>. We build our model first. Assuming all animals are independent of each other and have the same survival probability, then the number of alive animals at the end of the winter is a binomial distribution:</p>
<p><span class="math display">\[\begin{align*}
y &amp;\sim \text{Binomial}(n, \theta) &amp;\text{[likelihood]}
\end{align*}\]</span></p>
<p>In the Bayesian approach, priors are part of the model. For parameters that are probabilities, we often go for the uniform distribution <span class="math inline">\(U(0,1)\)</span>. <strong>vague prior (or non-informative?), voir dans d’autres bouquins; expliquer equiprobabilité, et renvoyer à la section où on en dit plus</strong></p>
<p><span class="math display">\[\begin{align*}
\theta &amp;\sim \text{Beta}(1, 1) &amp;\text{[prior for }\theta \text{]}
\end{align*}\]</span></p>
<p>Now we apply the Bayes’ theorem. We write a function that computes the product of the likelihood times the prior, or the numerator in the formula of the Bayes’ theorem: <span class="math inline">\(\Pr(\text{data} \mid \theta) \; \Pr(\theta)\)</span></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">numerator</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>,<span class="va">n</span>,<span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p</span>,<span class="va">a</span>,<span class="va">b</span><span class="op">)</span></code></pre></div>
<p>We write another function that calculates the denominator, which we sometimes call the averaged likelihood: <span class="math inline">\(\Pr(\text{data}) = \int{L(\theta \mid \text{data}) \; \Pr(\theta) d\theta}\)</span></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">denominator</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="va">numerator</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></code></pre></div>
<p>Then we get the posterior via numerical integration.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.01</span><span class="op">)</span>
<span class="va">numerical_posterior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>survival <span class="op">=</span> <span class="va">grid</span>, 
                                  posterior <span class="op">=</span> <span class="fu">numerator</span><span class="op">(</span><span class="va">grid</span><span class="op">)</span><span class="op">/</span><span class="va">denominator</span><span class="op">)</span> 
<span class="va">numerical_posterior</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">survival</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>, 
            size <span class="op">=</span> <span class="fl">1.5</span>, 
            col <span class="op">=</span> <span class="va">wes_palettes</span><span class="op">$</span><span class="va">Royal1</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, 
            alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-12"></span>
<img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-12-1.png" alt="Numerical approximation of winter survival posterior distribution." width="672"><p class="caption">
Figure 1.3: Numerical approximation of winter survival posterior distribution.
</p>
</div>
When we use a binomial likelihood together with a uniform prior, the posterior distribution has an explicit form that we can calculate by hand<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;strong&gt;faire qqch sur conjugacy?&lt;/strong&gt;&lt;/p&gt;"><sup>2</sup></a>. We superimpose the exact posterior and its numerical approximation to realise that the two distributions are indistinguishable, suggestion that the numerical approximation is more than fine.
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-13-1.png" alt="Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution." width="672"><p class="caption">
Figure 1.4: Comparison of exact (dashed line) vs. numerical approximation (continuous line) of winter survival posterior distribution.
</p>
</div>
<!-- To finish up, let's add the prior.  -->
<!-- ```{r, echo = FALSE} -->
<!-- ggplot() +  -->
<!--   geom_line(data = numerical_posterior,  -->
<!--             aes(x = survival, y = posterior),  -->
<!--             size = 1.5,  -->
<!--             col = wesanderson::wes_palettes$Royal1[2],  -->
<!--             alpha = 0.5) +  -->
<!--   geom_line(data = dfexpposterior,  -->
<!--             aes(x = survival, y = explicit_posterior), -->
<!--             col = wesanderson::wes_palettes$Royal1[3],  -->
<!--             size = 1.5,  -->
<!--             linetype = "dashed") +  -->
<!--   geom_line(data = dfprior, -->
<!--             aes(x = survival, y = prior), -->
<!--             col = wesanderson::wes_palettes$Royal1[1], -->
<!--             size = 1.5) -->
<!-- ``` -->
<p>In this example, we have a single parameter to estimate. This means dealing with a one-dimensional integral which is pretty easy with a quadrature scheme and the <code>R</code> function <code><a href="https://rdrr.io/r/stats/integrate.html">integrate()</a></code>. Now what if we had multiple parameters? For example, let’s imagine you’d like to fit a capture-recapture model with detection probability <span class="math inline">\(p\)</span> and regression parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> for the intercept and slope of a relationship between survival probability and a covariate, then Bayes’ theorem gives you the posterior distribution of all three parameters together:</p>
<p><span class="math display">\[ P(\alpha, \beta, p \mid \text{data}) = \frac{ P(\text{data} \mid \alpha, \beta, p) \, P(\alpha, \beta, p)}{\iiint \, P(\text{data} \mid \alpha, \beta, p) \, P(\alpha, \beta, p) \,d\alpha \,d\beta \,dp} \]</span>
There are two computational challenges with this formula. First, do we really wish to calculate a three-dimensional integral? The answer is no <strong>dire pourquoi, et qu’on a rien dans R pour faire ça</strong>. Second, we’re more interested in a posterior distribution for each parameter separately than the joint posterior distribution. The so-called marginal distribution of <span class="math inline">\(p\)</span> for example is obtained by integrating over all the other parameters – a two-dimensional integral in this example. Now imagine with tens or hundreds of parameters to estimate, these integrals become highly multi-dimensional and simply too difficult to calculate. In the next section, we introduce powerful simulation methods to circumvent this issue.</p>
</div>
<div id="bayesian-computation-with-markov-chain-monte-carlo-mcmc" class="section level2" number="1.5">
<h2>
<span class="header-section-number">1.5</span> Bayesian computation with Markov chain Monte Carlo (MCMC)<a class="anchor" aria-label="anchor" href="#bayesian-computation-with-markov-chain-monte-carlo-mcmc"><i class="fas fa-link"></i></a>
</h2>
<p>In the early 1990s, statisticians rediscovered work from the 1950’s in physics. In a famous paper that would lay the fundations of algorithms for implementing Bayes’ theorem, the authors use simulations to approximate posterior distributions with some precision by drawing large samples. This is a neat trick to avoid explicit calculation of multi-dimensional integrals we struggle with when using Bayes’ theorem. These simulation algorithms are called Markov chain Monte Carlo (MCMC), and they definitely gave a boost to Bayesian statistics. <strong>simulation algorithm ou stochastic algorithms. Expliquer.</strong></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-14"></span>
<img src="images/metropolis.png" alt="MCMC article cover. Source: [The Journal of Chemical Physics](https://aip.scitation.org/doi/10.1063/1.1699114)" width="582"><p class="caption">
Figure 1.5: MCMC article cover. Source: <a href="https://aip.scitation.org/doi/10.1063/1.1699114">The Journal of Chemical Physics</a>
</p>
</div>
<p>Why are MCMC methods so useful? Well to understand <em>why</em>, we need to better explain the <em>what</em>. MCMC are stochastic algorithms to produce sequence of dependent random numbers from a Markov chain. What is a Markov chain? A Markov chain is a discrete sequence of states, in which the probability of an event depends only on the state in the previous event. <strong>donner example de la météo?</strong> By construction, a Markov chain has an equilibrium (also know as stationary) distribution. <strong>expliquer</strong> The cool thing is that the equilibrium distribution is the desired posterior distribution. Yes, MCMC algorithms are used to construct a Markov chain with a given stationary distribution set to be the posterior distribution. This summarizes the core spirit of MCMC algorithms.
<strong>why is it so cool? plutôt que de simuler comme des dingues dans tous les snes, il suffit de tirer dans Markov chain, et eventuellement, on converge vers distribution statitionnaire qui est l’a posteriori! Also For the MCMC algorithm, the posterior distribution is only needed to be known up to proportionality.</strong></p>
<p>There are several ways of constructing these chains: e.g., Metropolis-Hastings, Gibbs sampler. Here I will illustrate the Metropolis algorithm and how to implement it in practice.</p>
<p>Let’s go back to our example on animal survival estimation. We illustrate sampling from survival posterior distribution. We write functions for likelihood, prior and posterior.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># 19 animals recaptured alive out of 57 captured, marked and released</span>
<span class="va">survived</span> <span class="op">&lt;-</span> <span class="fl">19</span>
<span class="va">released</span> <span class="op">&lt;-</span> <span class="fl">57</span>

<span class="co"># binomial log-likelihood function</span>
<span class="va">loglikelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">p</span><span class="op">)</span><span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, size <span class="op">=</span> <span class="va">released</span>, prob <span class="op">=</span> <span class="va">p</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">}</span>

<span class="co"># uniform prior density</span>
<span class="va">logprior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span><span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">p</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">}</span>

<span class="co"># posterior density function (log scale)</span>
<span class="va">posterior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">p</span><span class="op">)</span><span class="op">{</span>
  <span class="fu">loglikelihood</span><span class="op">(</span><span class="va">x</span>, <span class="va">p</span><span class="op">)</span> <span class="op">+</span> <span class="fu">logprior</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="co"># - log(Pr(data))</span>
<span class="op">}</span></code></pre></div>
<p>The Metropolis algorithm works as follows: <strong>pour chaque étape, donner l’intuition</strong></p>
<ol style="list-style-type: decimal">
<li><p>We start at any possible value of the parameter to be estimated.</p></li>
<li><p>To decide where to visit next, we propose to move away from the current value of the parameter – this is a <em>candidate</em> value. To do so, we add to the current value some random value from (say) a normal distribution with some variance.</p></li>
<li><p>We compute the ratio of the probabilities at the candidate and current locations <span class="math inline">\(R = \text{posterior(candidate)/posterior(current)}\)</span>. This is where the magic of MCMC happens, in that <span class="math inline">\(\Pr(\text{data})\)</span>, the denominator of the Bayes’ theorem, cancels out and does not need to be calculated.</p></li>
<li><p>We spin a continuous spinner that lands anywhere from 0 to 1 – call it the random spin <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is smaller than <span class="math inline">\(R\)</span>, we move to the candidate location, otherwise we remain at the current location.</p></li>
<li><p>We repeat 2-4 a number of times – or <em>steps</em> (many steps).</p></li>
</ol>
<p>Enough of the theory, let’s implement the Metropolis algorithm in <code>R</code>. Let’s start by setting the scene.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">steps</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># number of steps</span>
<span class="va">theta.post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">steps</span><span class="op">)</span> <span class="co"># vector to store samples</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span> <span class="co"># for reproducibility</span></code></pre></div>
<p>Now we follow the 5 steps we’ve just described. First, we pick a starting value, and store it (step 1).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">inits</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>
<span class="va">theta.post</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">inits</span></code></pre></div>
<p>To go to the next steps, we’ll need a function to propose a candidate value.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">move</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">away</span> <span class="op">=</span> <span class="fl">.2</span><span class="op">)</span><span class="op">{</span> 
  <span class="va">logitx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">x</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span>
  <span class="va">logit_candidate</span> <span class="op">&lt;-</span> <span class="va">logitx</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="va">away</span><span class="op">)</span>
  <span class="va">candidate</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="va">logit_candidate</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">candidate</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Now we’re ready for steps 2, 3 and 4. Actually, we will write a look to take care of step 5 as well. Remember we start at initial value 0.5 and run the algorithm for <span class="math inline">\(100\)</span> iterations.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">for</span> <span class="op">(</span><span class="va">t</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">steps</span><span class="op">)</span><span class="op">{</span> <span class="co"># repeat steps 2-4 (step 5)</span>
  
  <span class="co"># propose candidate value for prob of success (step 2)</span>
  <span class="va">theta_star</span> <span class="op">&lt;-</span> <span class="fu">move</span><span class="op">(</span><span class="va">theta.post</span><span class="op">[</span><span class="va">t</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  
  <span class="co"># calculate ratio R (step 3)</span>
  <span class="va">pstar</span> <span class="op">&lt;-</span> <span class="fu">posterior</span><span class="op">(</span><span class="va">survived</span>, p <span class="op">=</span> <span class="va">theta_star</span><span class="op">)</span>  
  <span class="va">pprev</span> <span class="op">&lt;-</span> <span class="fu">posterior</span><span class="op">(</span><span class="va">survived</span>, p <span class="op">=</span> <span class="va">theta.post</span><span class="op">[</span><span class="va">t</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  <span class="va">logR</span> <span class="op">&lt;-</span> <span class="va">pstar</span> <span class="op">-</span> <span class="va">pprev</span>
  <span class="va">R</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">logR</span><span class="op">)</span>
  
  <span class="co"># accept candidate value or keep current value (step 4)</span>
  <span class="va">accept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">R</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
  <span class="va">theta.post</span><span class="op">[</span><span class="va">t</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">accept</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">theta_star</span>, <span class="va">theta.post</span><span class="op">[</span><span class="va">t</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>We get the following values.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">theta.post</span><span class="op">)</span> <span class="co"># first values</span>
<span class="co">## [1] 0.5000 0.4399 0.4399 0.4577 0.4577 0.4577</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span><span class="op">(</span><span class="va">theta.post</span><span class="op">)</span> <span class="co"># last values</span>
<span class="co">## [1] 0.4146 0.3772 0.3772 0.3861 0.3899 0.3624</span></code></pre></div>
Visually, the chain looks like that. <strong>introduire traceplot?</strong>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-21"></span>
<img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-21-1.png" alt="Visualisation of a Markov chain, often called traceplot. Starting value is 0.5." width="672"><p class="caption">
Figure 1.6: Visualisation of a Markov chain, often called traceplot. Starting value is 0.5.
</p>
</div>
Can we run another chain and start at initial value 0.2 this time? Yes, just go through the same algorithm again.
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-22"></span>
<img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-22-1.png" alt="Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue)." width="672"><p class="caption">
Figure 1.7: Visualisation of two Markov chains with starting values 0.2 (yellow) and 0.5 (blue).
</p>
</div>
Notice that we do not get the same exact results. <strong>Stochasticity, mais on average, seems to reach same value and vary aournd it – equilibrium? Stationary? posterior of winter survival</strong> Now let’s increase the number of steps and run a chain with 5000 iterations.
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-23"></span>
<img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-23-1.png" alt="Visualisation of a Markov chains with 5000 iterations." width="672"><p class="caption">
Figure 1.8: Visualisation of a Markov chains with 5000 iterations.
</p>
</div>
<p>We also add two straight lines, one in yellow for the mean of the posterior distribution <strong>dire comment c’est calculé</strong>, and the other in red for the maximum likelihood estimate <strong>c’est quoi ici?</strong>. <strong>expliquer pourquoi, et noter que ça donne la même chose</strong>.</p>
<p>I find it informative to look at the animated version of this figure, it helps understanding the iterative nature of the algorithm, and also to realise how the chains converge to their stationary distribution.</p>
<img src="images/traceplotMCMC.gif" width="100%" style="display: block; margin: auto;"><div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-26"></span>
<img src="images/histMCMC.gif" alt="Sampling values in survival posterior distribution with a MCMC algorithm. Top panel: traceplot. Bottom panel: histogram." width="100%"><p class="caption">
Figure 1.9: Sampling values in survival posterior distribution with a MCMC algorithm. Top panel: traceplot. Bottom panel: histogram.
</p>
</div>
<p><strong>Introduire l’idée de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l’idée de comment on regarde la convergence</strong> Once the stationary distribution is reached, we can regard the realisations of the chain as a (dependent) sample from the posterior distribution (and obtain Monte Carlo estimates). In the next section, we consider several important implementation issues.</p>
</div>
<div id="assessing-convergence" class="section level2" number="1.6">
<h2>
<span class="header-section-number">1.6</span> Assessing convergence<a class="anchor" aria-label="anchor" href="#assessing-convergence"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Les principales questions on doit répondre pour check convergence. Noter qu’en freq c’est plus ou moins fait en backstage. En MCMC pas grand chose pour automatiser.</strong></p>
<div id="mixing-and-autocorrelation" class="section level3" number="1.6.1">
<h3>
<span class="header-section-number">1.6.1</span> Mixing and autocorrelation<a class="anchor" aria-label="anchor" href="#mixing-and-autocorrelation"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-27-1.png" width="672"></div>
<ul>
<li><p>The movement around the parameter space is often referred to as <strong>mixing</strong>.</p></li>
<li><p>Traceplots of for small and big moves provide (relatively) high correlations (known as autocorrelations) between successive observations of the Markov chain.</p></li>
<li><p>Strongly correlated observations require large sample sizes and therefore longer simulations.</p></li>
<li><p>Autocorrelation function (ACF) plots are a convenient way of displaying the strength of autocorrelation in the given sample values.</p></li>
<li><p>ACF plots provide the autocorrelation between successively sampled values separated by <span class="math inline">\(k\)</span> iterations, referred to as lag, (i.e. <span class="math inline">\(\text{cor}(\theta_t, \theta_{t+k})\)</span>) for increasing values of <span class="math inline">\(k\)</span>.</p></li>
</ul>
</div>
<div id="how-do-good-chains-behave" class="section level3" number="1.6.2">
<h3>
<span class="header-section-number">1.6.2</span> How do good chains behave?<a class="anchor" aria-label="anchor" href="#how-do-good-chains-behave"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>Converge to same target distribution; discard some realisations of Markov chain before convergence is achieved.</p></li>
<li><p>Once there, explore efficiently: The post-convergence sample size required for suitable numerical summaries.</p></li>
<li><p>Therefore, we are looking to determine how long it takes for the Markov chain to converge to the stationary distribution.</p></li>
<li><p>In practice, we must discard observations from the start of the chain and just use observations from the chain once it has converged.</p></li>
<li><p>The initial observations that we discard are referred to as the <strong>burn-in</strong>.</p></li>
<li><p>Simplest method to determine length of burn-in period is to look at trace plots.</p></li>
</ul>
</div>
<div id="burn-in" class="section level3" number="1.6.3">
<h3>
<span class="header-section-number">1.6.3</span> Burn-in<a class="anchor" aria-label="anchor" href="#burn-in"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="bayesHMMcapturerecapture_files/figure-html/unnamed-chunk-28-1.png" width="672"></div>
<p>If simulations cheap, be conservative.</p>
</div>
<div id="effective-sample-size-n.eff" class="section level3" number="1.6.4">
<h3>
<span class="header-section-number">1.6.4</span> Effective sample size <code>n.eff</code><a class="anchor" aria-label="anchor" href="#effective-sample-size-n.eff"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>How long of a chain is needed to produce stable estimates ?</li>
<li>Most MCMC chains are strongly autocorrelated.</li>
<li>Successive steps are near each other, and are not independent.</li>
<li>The effective sample size (<code>n.eff</code>) measures chain length while taking into account the autocorrelation of the chain.</li>
<li>
<code>n.eff</code> is less than the number of MCMC iterations.</li>
<li>Check the <code>n.eff</code> of every parameter of interest.</li>
<li>Check the <code>n.eff</code> of any interesting parameter combinations.</li>
<li>We need <span class="math inline">\(\text{n.eff} \geq 100\)</span> independent steps.</li>
</ul>
</div>
<div id="potential-scale-reduction-factor" class="section level3" number="1.6.5">
<h3>
<span class="header-section-number">1.6.5</span> Potential scale reduction factor<a class="anchor" aria-label="anchor" href="#potential-scale-reduction-factor"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Gelman-Rubin statistic <span class="math inline">\(\hat{R}\)</span>
</li>
<li>Measures the ratio of the total variability combining multiple chains (between-chain plus within-chain) to the within-chain variability.</li>
<li>Asks the question is there a chain effect? Very much alike the <span class="math inline">\(F\)</span> test in an ANOVA.</li>
<li>Values near <span class="math inline">\(1\)</span> indicates likely convergence, a value of <span class="math inline">\(\leq 1.1\)</span> is considered acceptable.</li>
<li>Necessary condition, not sufficient; In other words, these diagnostics cannot tell you that you have converged for sure, only that you have not.</li>
</ul>
</div>
<div id="what-if-you-have-issues-of-convergence" class="section level3" number="1.6.6">
<h3>
<span class="header-section-number">1.6.6</span> What if you have issues of convergence?<a class="anchor" aria-label="anchor" href="#what-if-you-have-issues-of-convergence"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Increase burn-in, sample more.</li>
<li>Use more informative priors.</li>
<li>Pick better initial values (good guess), using e.g. estimates from simpler models.</li>
<li>Reparameterize:</li>
<li>Standardize covariates.</li>
<li>Non-centering: <span class="math inline">\(\alpha \sim N(0,\sigma)\)</span> becomes <span class="math inline">\(\alpha = z \sigma\)</span> with <span class="math inline">\(z \sim N(0,1)\)</span>.</li>
<li>Something wrong with your model?</li>
<li>Start with a simpler model (remove complexities).</li>
<li>Use simulations.</li>
<li>Change your sampler. More later on.</li>
</ul>
</div>
</div>
<div id="summary" class="section level2" number="1.7">
<h2>
<span class="header-section-number">1.7</span> Summary<a class="anchor" aria-label="anchor" href="#summary"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Run multiple chains from arbitrary starting places (initial values).</li>
<li>Assume convergence when all chains reach same regime</li>
<li>Discard initial burn-in phase.</li>
<li>Proceed with posterior inference.</li>
<li>Use traceplot, effective sample size and <span class="math inline">\(\hat{R}\)</span>.</li>
</ul>
<p><strong>Takes some trainig</strong></p>
</div>
<div id="further-reading" class="section level2" number="1.8">
<h2>
<span class="header-section-number">1.8</span> Further reading<a class="anchor" aria-label="anchor" href="#further-reading"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>McCarthy, M. (2007). <a href="https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201">Bayesian Methods for Ecology</a>. Cambridge: Cambridge University Press.</p></li>
<li><p>McElreath, R. (2020). <a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)</a>. CRC Press.</p></li>
<li><p>Gelman, A. and Hill, J. (2006). <a href="https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983">Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)</a>. Cambridge: Cambridge University Press.</p></li>
<li><p>Animating MCMC - 2D example; Code <a href="https://mbjoseph.github.io/posts/2018-12-25-animating-the-metropolis-algorithm/">here</a>.</p></li>
</ul>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/include_graphics.html">include_graphics</a></span><span class="op">(</span><span class="st">"images/create-gif.gif"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure">
<img src="images/create-gif.gif"><!-- -->
</div>
<ul>
<li>The MCMC Interactive Gallery (more <a href="https://chi-feng.github.io/mcmc-demo/">here</a>)</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/include_graphics.html">include_graphics</a></span><span class="op">(</span><span class="st">"images/galery.png"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="images/galery.png" width="992"></div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="about-the-author.html">About the Author</a></div>
<div class="next"><a href="intronimble.html"><span class="header-section-number">2</span> Introduction to Nimble</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#crashcourse"><span class="header-section-number">1</span> Bayesian statistics &amp; MCMC</a></li>
<li><a class="nav-link" href="#introduction"><span class="header-section-number">1.1</span> Introduction</a></li>
<li><a class="nav-link" href="#bayes-theorem"><span class="header-section-number">1.2</span> Bayes’ theorem</a></li>
<li><a class="nav-link" href="#what-is-the-bayesian-approach"><span class="header-section-number">1.3</span> What is the Bayesian approach?</a></li>
<li><a class="nav-link" href="#approximating-posterior-distributions-via-numerical-integration"><span class="header-section-number">1.4</span> Approximating posterior distributions via numerical integration</a></li>
<li><a class="nav-link" href="#bayesian-computation-with-markov-chain-monte-carlo-mcmc"><span class="header-section-number">1.5</span> Bayesian computation with Markov chain Monte Carlo (MCMC)</a></li>
<li>
<a class="nav-link" href="#assessing-convergence"><span class="header-section-number">1.6</span> Assessing convergence</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#mixing-and-autocorrelation"><span class="header-section-number">1.6.1</span> Mixing and autocorrelation</a></li>
<li><a class="nav-link" href="#how-do-good-chains-behave"><span class="header-section-number">1.6.2</span> How do good chains behave?</a></li>
<li><a class="nav-link" href="#burn-in"><span class="header-section-number">1.6.3</span> Burn-in</a></li>
<li><a class="nav-link" href="#effective-sample-size-n.eff"><span class="header-section-number">1.6.4</span> Effective sample size n.eff</a></li>
<li><a class="nav-link" href="#potential-scale-reduction-factor"><span class="header-section-number">1.6.5</span> Potential scale reduction factor</a></li>
<li><a class="nav-link" href="#what-if-you-have-issues-of-convergence"><span class="header-section-number">1.6.6</span> What if you have issues of convergence?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary"><span class="header-section-number">1.7</span> Summary</a></li>
<li><a class="nav-link" href="#further-reading"><span class="header-section-number">1.8</span> Further reading</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/oliviergimenez/banana-book/blob/master/01-bayesMCMC.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/oliviergimenez/banana-book/edit/master/01-bayesMCMC.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models – Theory and Case Studies in R</strong>" was written by Olivier Gimenez. It was last built on 2021-09-09.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
