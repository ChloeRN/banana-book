[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome website book Bayesian Analysis Capture-Recapture Data Hidden Markov Models – Theory Case Studies R Olivier Gimenez. Note book also available PDF format.’m currently writing book, welcome feedback requests content .Many thanks!Last updated: September 10, 2021","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology. parallel, Bayesian statistics relatively well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, nimble) allow practitioners code analyses.However, knowledge, full Bayesian treatment HMMs applied capture-recapture data yet proposed book. propose book. Besides, popular software solutions come computational limitations ecologists deal complex models /big data. use Nimble seen many future ecological data modelling extends BUGS language writing new functions distributions, provides samplers can deal discrete latent states contrast Stan.book, cover theory HMMs capture-recapture data, applications models empower practitioners fit models confidence. important part book consist case studies presented tutorial style abide “learning ” philosophy.\nonline version book licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. ","code":""},{"path":"preface.html","id":"why-read-this-book","chapter":"Preface","heading":"Why read this book","text":"","code":""},{"path":"preface.html","id":"structure-of-the-book","chapter":"Preface","heading":"Structure of the book","text":"Blabla.","code":""},{"path":"preface.html","id":"software-information-and-conventions","chapter":"Preface","heading":"Software information and conventions","text":"book uses primarily R package nimble, need least install R nimble package.R session information compiling book shown :add prompts (> +) R source code book, comment text output two hashes ## default, can see R session information . convenience want copy run code (text output ignored since commented ). Package names bold text (e.g., nimble), inline code filenames formatted typewriter font (e.g., knitr::knit('foo.Rmd')). Function names followed parentheses (e.g., nimble::nimbleCode()). double-colon operator :: means accessing object package.","code":"\nsessionInfo()\n## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Catalina 10.15.7\n## \n## Matrix products: default\n## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## other attached packages:\n##  [1] wesanderson_0.3.6 pdftools_3.0.1   \n##  [3] magick_2.7.3      MCMCvis_0.15.3   \n##  [5] nimble_0.11.1     patchwork_1.1.1  \n##  [7] forcats_0.5.1     stringr_1.4.0    \n##  [9] dplyr_1.0.7       purrr_0.3.4.9000 \n## [11] readr_2.0.0       tidyr_1.1.3      \n## [13] tibble_3.1.3      ggplot2_3.3.5    \n## [15] tidyverse_1.3.1   forecast_8.15    \n## \n## loaded via a namespace (and not attached):\n##  [1] tseries_0.10-48   httr_1.4.2       \n##  [3] sass_0.4.0        jsonlite_1.7.2   \n##  [5] modelr_0.1.8      bslib_0.2.5.1    \n##  [7] assertthat_0.2.1  askpass_1.1      \n##  [9] TTR_0.24.2        cellranger_1.1.0 \n## [11] yaml_2.2.1        qpdf_1.1         \n## [13] pillar_1.6.2      backports_1.2.1  \n## [15] lattice_0.20-44   glue_1.4.2       \n## [17] quadprog_1.5-8    digest_0.6.27    \n## [19] rvest_1.0.1       colorspace_2.0-2 \n## [21] htmltools_0.5.1.1 timeDate_3043.102\n## [23] pkgconfig_2.0.3   broom_0.7.9      \n## [25] haven_2.4.3       bookdown_0.23    \n## [27] scales_1.1.1      downlit_0.2.1    \n## [29] tzdb_0.1.2        generics_0.1.0   \n## [31] farver_2.1.0      ellipsis_0.3.2   \n## [33] withr_2.4.2       urca_1.3-0       \n## [35] nnet_7.3-16       cli_3.0.1        \n## [37] quantmod_0.4.18   magrittr_2.0.1   \n## [39] crayon_1.4.1      readxl_1.3.1     \n## [41] evaluate_0.14     fs_1.5.0         \n## [43] fansi_0.5.0       nlme_3.1-152     \n## [45] xts_0.12.1        xml2_1.3.2       \n## [47] tools_4.1.0       hms_1.1.0        \n## [49] lifecycle_1.0.0   munsell_0.5.0    \n## [51] reprex_2.0.1      compiler_4.1.0   \n## [53] jquerylib_0.1.4   rlang_0.4.11     \n## [55] grid_4.1.0        rstudioapi_0.13  \n## [57] igraph_1.2.6      labeling_0.4.2   \n## [59] rmarkdown_2.10    gtable_0.3.0     \n## [61] fracdiff_1.5-1    DBI_1.1.1        \n## [63] curl_4.3.2        R6_2.5.0         \n## [65] zoo_1.8-9         lubridate_1.7.10 \n## [67] knitr_1.33        utf8_1.2.2       \n## [69] stringi_1.7.3     parallel_4.1.0   \n## [71] Rcpp_1.0.7        vctrs_0.3.8      \n## [73] coda_0.19-4       dbplyr_2.1.1     \n## [75] tidyselect_1.1.1  xfun_0.25        \n## [77] lmtest_0.9-38"},{"path":"preface.html","id":"acknowledgments","chapter":"Preface","heading":"Acknowledgments","text":"CNRS. Jean-. Roger. Rémi. students. Chloé, Sarah, Perry, Daniel. Rob Chapman & Hall/CRC. Workshop attendees. Feedback . FIP radio. Marc Kéry support advice write book. Proofreading . family.\nOlivier Gimenez\nMontpellier, France\n","code":""},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the Author","heading":"About the Author","text":"Je m’appelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Après des études universitaires en mathématiques, j’ai fait une thèse en statistiques pour l’écologie. J’ai passé mon Habilitation à Diriger des Recherches en écologie et évolution. Récemment, je suis retourné sur les bancs de l’université pour m’initier à la sociologie.J’ai écrit des articles scientifiques faisant appel à la statistique bayésienne, et co-écrit avec des collègues britanniques un livre sur les analyses bayésiennes pour l’écologie des populations.Vous pouvez retrouver sur Twitter (https://twitter.com/oaggimenez), ou bien contacter via mon adresse email qui s’écrit olivier suivi d’un point puis gimenez, ensuite arobase, puis cefe, suivi d’un point, puis cnrs, suivi d’un point et pour terminer fr.Tombé dedans quand j’étais petit. Obélix Roger et Astérix JD.","code":""},{"path":"crashcourse.html","id":"crashcourse","chapter":"1 Bayesian statistics & MCMC","heading":"1 Bayesian statistics & MCMC","text":"","code":""},{"path":"crashcourse.html","id":"introduction","chapter":"1 Bayesian statistics & MCMC","heading":"1.1 Introduction","text":"first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book.utiliser des références un peu plus (critique des bouquins de Kéry et Schaub), mais pas trop quand même","code":""},{"path":"crashcourse.html","id":"bayes-theorem","chapter":"1 Bayesian statistics & MCMC","heading":"1.2 Bayes’ theorem","text":"Ajouter quelque chose sur la démarche scientifique?Let’s wait longer jump . Bayesian statistics relies Bayes’ theorem named Reverend Bayes. expliquer avec des mots ce que fait ce théorème, puis donner la formule mathématique\nFigure 1.1: Cartoon Thomas Bayes Bayes’ theorem background. Source: James Kulich\nBayes’ theorem states events \\(\\) \\(B\\), :\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}\\]\nconditional probabilities, easy understand. conditional probabilities? Link towards nice videos.\nFigure 1.2: Bayes’ theorem spelt blue neon offices Autonomy Cambridge. Source: Wikipedia\ndon’t know , hard time messing letters around. easier remember Bayes’ theorem written like :\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]\nhypothesis want learn using data. capture-recapture models, hypothesis parameter like detection probability, regression parameters relationship survival probability covariate. Citer Taj Mahr comme source. Bayes’ theorem tells probability hypothesis given data. great think , science ? ’d like know plausible hypothesis given data? dire des trucs sur les termes de droite respect, Bayesian reasoning matches scientific reasoning. might ask , Bayesian statistics default statistics? Clearly, recently, practical problems implement Bayesian approach. Recent advances computational power coupled development new methodology led great increase application Bayesian methods within last three decades. Also, futile wars (male) statisticians, little progress made two centuries. en dire un peu plus sur ces guerres","code":""},{"path":"crashcourse.html","id":"what-is-the-bayesian-approach","chapter":"1 Bayesian statistics & MCMC","heading":"1.3 What is the Bayesian approach?","text":"Typical statistical problems involve estimating parameter(s) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed fixed unknown distribution – distribution parameter. qu’entend-par distribution?Bayesian approach based upon idea , experimenter, begin prior beliefs system. words, never start scratch. collect data update prior beliefs basis observations. observations might arise field lab work. updating process based upon Bayes’ theorem ’ve seen earlier:\\[\\Pr(\\mid B) = \\frac{\\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}\\]\nLoosely, let’s say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes’ theorem gives way estimate parameter \\(\\theta\\) given data . Indeed, formula becomes:\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\; \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet’s spend time going quantity formula.left-hand side, \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ’re , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. ’ll get back length.Last, \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) \\(N\\)-dimensional integral \\(\\theta = \\theta_1, \\ldots, \\theta_N\\). quantity difficult, impossible, calculate. one reasons Bayesian method wasn’t used recently. reason need simulation algorithms estimate posterior distributions. simulation ou stochastic algorithms? si stochastic, expliquer","code":""},{"path":"crashcourse.html","id":"approximating-posterior-distributions-via-numerical-integration","chapter":"1 Bayesian statistics & MCMC","heading":"1.4 Approximating posterior distributions via numerical integration","text":"Let’s take example. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive1. ’d like estimate winter survival \\(\\theta\\).Préciser quelque part qu’prend formalisme McElreath pour présenter les modèles. build model first. Assuming animals independent survival probability, number alive animals end winter binomial distribution:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]Bayesian approach, priors part model. parameters probabilities, often go uniform distribution \\(U(0,1)\\). vague prior (non-informative?), voir dans d’autres bouquins; expliquer equiprobabilité, et renvoyer à la section où en dit plus\\[\\begin{align*}\n\\theta &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes’ theorem. write function computes product likelihood times prior, numerator formula Bayes’ theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\; \\Pr(\\theta)\\)write another function calculates denominator, sometimes call averaged likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\; \\Pr(\\theta) d\\theta}\\)get posterior via numerical integration Figure 1.3.\nFigure 1.3: Numerical approximation winter survival posterior distribution.\n\nFigure 1.4: Comparison exact (dashed line) vs. numerical approximation (continuous line) winter survival posterior distribution.\nexample, single parameter estimate. means dealing one-dimensional integral pretty easy quadrature scheme R function integrate(). Now multiple parameters? example, let’s imagine ’d like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes’ theorem gives posterior distribution three parameters together:\\[ P(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\alpha, \\beta, p) \\, P(\\alpha, \\beta, p)}{\\iiint \\, P(\\text{data} \\mid \\alpha, \\beta, p) \\, P(\\alpha, \\beta, p) \\,d\\alpha \\,d\\beta \\,dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer dire pourquoi, et qu’rien dans R pour faire ça. Second, ’re interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters – two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply difficult calculate. next section, introduce powerful simulation methods circumvent issue.","code":"\ny <- 19 # nb of success\nn <- 57 # nb of attempts\nnumerator <- function(p) dbinom(y,n,p) * dbeta(p,a,b)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01)\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) \nnumerical_posterior %>%\n  ggplot() + \n  geom_line(aes(x = survival, y = posterior), \n            size = 1.5, \n            col = wes_palettes$Royal1[2], \n            alpha = 0.5)"},{"path":"crashcourse.html","id":"bayesian-computation-with-markov-chain-monte-carlo-mcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5 Bayesian computation with Markov chain Monte Carlo (MCMC)","text":"parler de réplicats d’une chaine de Markov plutôt que de plusieurs Markov chains?early 1990s, statisticians rediscovered work 1950’s physics. famous paper lay fundations modern Bayesian statistics (see Figure 1.5), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes’ theorem. simulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. simulation algorithm ou stochastic algorithms. Expliquer.\nFigure 1.5: MCMC article cover. Source: Journal Chemical Physics\nMCMC methods useful? Well understand , need better explain . MCMC stochastic algorithms produce sequence dependent random numbers Markov chain. Markov chain? Markov chain discrete sequence states, probability event depends state previous event. donner example de la météo? construction, Markov chain equilibrium (also know stationary) distribution. expliquer cool thing equilibrium distribution desired posterior distribution. Expliquer Monte Carlo avec exemple simple, idem pour Markov chain Yes, MCMC algorithms used construct Markov chain given stationary distribution set posterior distribution. summarizes core spirit MCMC algorithms.\ncool? plutôt que de simuler comme des dingues dans tous les snes, il suffit de tirer dans Markov chain, et eventuellement, converge vers distribution statitionnaire qui est l’posteriori! Also MCMC algorithm, posterior distribution needed known proportionality.several ways constructing chains: e.g., Metropolis-Hastings, Gibbs sampler. look https://github.com/chi-feng/mcmc-demo interactive gallery MCMC algorithms. illustrate Metropolis algorithm implement practice. Différence entre Metropolis et MHLet’s go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows: pour chaque étape, donner l’intuitionWe start possible value parameter estimated.start possible value parameter estimated.decide visit next, propose move away current value parameter – candidate value. , add current value random value (say) normal distribution variance.decide visit next, propose move away current value parameter – candidate value. , add current value random value (say) normal distribution variance.compute ratio probabilities candidate current locations \\(R = \\text{posterior(candidate)/posterior(current)}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, cancels need calculated.compute ratio probabilities candidate current locations \\(R = \\text{posterior(candidate)/posterior(current)}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, cancels need calculated.spin continuous spinner lands anywhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location.spin continuous spinner lands anywhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location.repeat 2-4 number times – steps (many steps).repeat 2-4 number times – steps (many steps).Enough theory, let’s implement Metropolis algorithm R. Let’s start setting scene.Now follow 5 steps ’ve just described. First, pick starting value, store (step 1).go next steps, ’ll need function propose candidate value. expliquer le away, s’en sert plus bas pour autocorrelation, called SDNow ’re ready steps 2, 3 4. Actually, write look take care step 5 well. Remember start initial value 0.5 run algorithm \\(100\\) iterations.get following values.\nFigure 1.6: Visualisation Markov chain, often called traceplot. Starting value 0.5.\n\nFigure 1.7: Visualisation two Markov chains starting values 0.2 (yellow) 0.5 (blue).\n\nFigure 1.8: Visualisation Markov chains 5000 iterations.\nalso add two straight lines, one yellow mean posterior distribution dire comment c’est calculé, red maximum likelihood estimate c’est quoi ici?. expliquer pourquoi, et noter que ça donne la même chose.find informative look animated version Figure 1.8, helps understanding iterative behavior algorithm, also realise chains converge stationary distribution, see Figure 1.9.\nFigure 1.9: Sampling values survival posterior distribution MCMC algorithm. Top panel: traceplot. Bottom panel: histogram.\nIntroduire l’idée de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l’idée de comment regarde la convergence discard realisations Markov chain convergence achieved. stationary distribution reached use stationary target limiting, can regard realisations chain (dependent) sample posterior distribution, obtain Monte Carlo estimates parameters. next section, consider several important implementation issues. coder Metropolis d’au-dessus dans Nimble","code":"\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\nmove <- function(x, away = .2){ \n  logitx <- log(x / (1 - x))\n  logit_candidate <- logitx + rnorm(1, 0, away)\n  candidate <- plogis(logit_candidate)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for prob of success (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  accept <- rbinom(1, 1, prob = min(R, 1))\n  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.4399 0.4399 0.4577 0.4577 0.4577\ntail(theta.post) # last values\n## [1] 0.4146 0.3772 0.3772 0.3861 0.3899 0.3624"},{"path":"crashcourse.html","id":"assessing-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6 Assessing convergence","text":"implementing MCMC, need determine long takes Markov chain converge target distribution, number iterations need achieving convergence get reasonable Monte Carlo estimates model parameters (numerical summaries). expliquer numerical summaries quelque part","code":""},{"path":"crashcourse.html","id":"burn-in","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.1 Burn-in","text":"practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.10 need least 500 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 750 even 1000 iterations burn-. préciser qu’il faut faire qqs runs préliminaires pour déterminer le burn-; ajouter des cas pathologiques ou faire des renvois aux sections suiantes, en particuier les minimal locaux ou par redundancy?\nFigure 1.10: Determining length burn-period.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check replicates achieve target distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values \\(1.2\\) indicate likely convergence. check 1.1 1.2Back example, run two replicates Markov chain starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.11, get value BGR statistic near 1 2500 iterations, suggests 2500 iterations burn-, evidence lack convergence.\nFigure 1.11: Brooks-Gelman-Rubin statistic.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .","code":""},{"path":"crashcourse.html","id":"chain-length","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.2 Chain length","text":"long chain needed produce stable parameter estimates? answer question, need keep mind successive steps Markov chain near , independent – usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let’s get back survival example. Figure (fig:tracechainlength) shows trace plots samples survival posterior distribution. Small big moves provide relatively high correlations successive observations Markov chain, whereas standard deviation 0.2 allows efficient exploration parameter space. movement around parameter space often referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.12: Trace plots different tuning acceptance rate. Left: SD 0.02, chain exhibits small moves mixing bad. Right: SD 2, chain exhibits big moves mixing bad. Middle: SD 0.2, chain exhibits adequate moves mixing good.\nBesides trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated \\(k\\) iterations, referred lag, (.e. \\(\\text{cor}(\\theta_t, \\theta_{t+k})\\)) increasing values \\(k\\). Figure (fig:acfchainlength)\nFigure 1.13: Autocorrelation function plots different tuning acceptance rate. Left: SD 0.02, autocorrelation strong, decreases slowly increasing lag mixing bad. Right: SD 2, autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: SD 0.2, autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. Obviously, n.eff less number MCMC iterations. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 100\\) independent steps get reasonable Monte Carlo estimates model parameters. calculer neff sur exemple","code":""},{"path":"crashcourse.html","id":"what-if-you-have-issues-of-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.3 What if you have issues of convergence?","text":"effective sample size small, just need increase burn-/sample . Using informative priors might also make Markov chain converge faster helping MCMC algorithm navigating efficiently parameter space. spirit, picking better initial values, good guess, starting chain harm. strategy consists using estimates simpler models.issues persist, problem probably profound, might ask whether something wrong model fork theorem Gelman?. bug code? typo somewhere? msitake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice always start seeing model data generating tool first place, simulate data using realistic values parameters, try recover parameters fitting model simulated data.also see strategies improve convergence chapter XX. Change sampler. Reparameterize (standardize covariates, plus non-centering: \\(\\alpha \\sim N(0,\\sigma)\\) becomes \\(\\alpha = z \\sigma\\) \\(z \\sim N(0,1)\\)).lisser cette partie","code":""},{"path":"crashcourse.html","id":"summary","chapter":"1 Bayesian statistics & MCMC","heading":"1.7 Summary","text":"idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ’re . practice, run Markov chain multiple times starting -dispersed initial values. discard iterations initial burn-phase achieve convergence replicates reach regime. , run chain long enough proceed calculating Monte Carlo estimates (numerical summaries) model parameters.Takes training; make sense next chapter, also put use case studies!","code":""},{"path":"crashcourse.html","id":"further-reading","chapter":"1 Bayesian statistics & MCMC","heading":"1.8 Further reading","text":"cette partie dans chaque chapitre c’est plutôt les trucs essentiels en lien avec le chapitre il semble non?Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.","code":""},{"path":"intronimble.html","id":"intronimble","chapter":"2 Introduction to Nimble","heading":"2 Introduction to Nimble","text":"","code":""},{"path":"intronimble.html","id":"what-is-nimble","chapter":"2 Introduction to Nimble","heading":"2.1 What is Nimble?","text":"\nFigure 2.1: (Meme created Todd Arnold’s wonderful students)\n\nFigure 2.2: (Meme created Todd Arnold’s wonderful students)\nNumerical Inference statistical Models using Bayesian Likelihood Estimation.Numerical Inference statistical Models using Bayesian Likelihood Estimation.framework hierarchical statistical models algorithms.framework hierarchical statistical models algorithms.Uses almost model code WinBUGS, OpenBUGS, JAGS.Uses almost model code WinBUGS, OpenBUGS, JAGS.extension BUGS language: additional syntax, custom functions distributions.extension BUGS language: additional syntax, custom functions distributions.configurable system MCMC.configurable system MCMC.library methods (SMC, MCEM).library methods (SMC, MCEM).Sequential Monte Carlo (particle filtering)Sequential Monte Carlo (particle filtering)Monte Carlo Expectation Maximization (maximum likelihood)Monte Carlo Expectation Maximization (maximum likelihood)model-generic programming system write new analysis methods.model-generic programming system write new analysis methods.","code":""},{"path":"intronimble.html","id":"load-nimble-package","chapter":"2 Introduction to Nimble","heading":"2.2 Load nimble package","text":"","code":"\nlibrary(nimble)"},{"path":"intronimble.html","id":"build-model-made-of-likelihood-and-priors","chapter":"2 Introduction to Nimble","heading":"2.3 Build model, made of likelihood and priors","text":"","code":"\nnaive.survival.model <- nimbleCode({\n  # prior\n  phi ~ dunif(0, 1)\n  # likelihood\n  y ~ dbinom(phi, n)\n})"},{"path":"intronimble.html","id":"syntax-whats-newbetterdifferent","chapter":"2 Introduction to Nimble","heading":"2.4 Syntax: what’s new/better/different?","text":"VectorizationMore flexible specification distributionsYour functions distributionsThe end empty indices& …","code":"\n# JAGS (& Nimble)\nfor(t in 1:Tmax){\n  x[t] <- Mu.x + epsilon[t]\n}\n\n# Nimble\nx[1:Tmax] <- Mu.x + epsilon[1:Tmax]\n# JAGS (& Nimble)\nfor(t in 1:Tmax){\n  epsilon[t] ~ dnorm(0, tau)\n}\ntau <- pow(sigma, -2)\nsigma ~ dunif(0, 5)\n\n# Nimble\nfor(t in 1:Tmax){\n  epsilon[t] ~ dnorm(0, sd = sigma)\n}\nsigma ~ dunif(0, 5)\nx[1:Tmax] <- myNimbleFunction(a = Mu.x, b = epsilon[1:Tmax])\nsigma ~ dCustomDistr(c = 0.5, z = 10)\n# JAGS\nsum.x <- sum(x[])\n\n# Nimble\nsum.x <- sum(x[1:Tmax])"},{"path":"intronimble.html","id":"read-in-data","chapter":"2 Introduction to Nimble","heading":"2.5 Read in data","text":"Back naive survival model:","code":"\nnaive.survival.model <- nimbleCode({\n  # prior\n  phi ~ dunif(0, 1)\n  # likelihood\n  y ~ dbinom(phi, n)\n})\nmy.data <- list(n = 57, y = 19)"},{"path":"intronimble.html","id":"distinguish-constants-and-data","chapter":"2 Introduction to Nimble","heading":"2.6 Distinguish constants and data","text":"Nimble, “data” data…Constants:\n+ Can never changed\n+ Must provided model defined (part model structure)\n+ E.g. vector known index values, variables used define -loops, etc.Nimble, “data” data…Data:\n+ Can changed without re-building model\n+ Can (re-)simulated within model\n+ E.g. stuff appears left “~”computational efficiency, better specify much possible constants.Nimble help !","code":"\nmy.constants <- list(n = 57)\nmy.data <- list(y = 19)\nmy.constants <- list(n = 57)\nmy.data <- list(y = 19)"},{"path":"intronimble.html","id":"specify-initial-values","chapter":"2 Introduction to Nimble","heading":"2.7 Specify initial values","text":"","code":"\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.2013"},{"path":"intronimble.html","id":"which-parameters-to-save","chapter":"2 Introduction to Nimble","heading":"2.8 Which parameters to save?","text":"","code":"\nparameters.to.save <- c(\"phi\")"},{"path":"intronimble.html","id":"mcmc-details","chapter":"2 Introduction to Nimble","heading":"2.9 MCMC details","text":"Number posterior samples per chain:\\[n.posterior = \\frac{n.iter - n.burnin}{n.thin}\\]","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nn.thin <- 1"},{"path":"intronimble.html","id":"run-model-tadaa","chapter":"2 Introduction to Nimble","heading":"2.10 Run model, tadaa!","text":"","code":"\nmcmc.output <- nimbleMCMC(code = naive.survival.model,     \n                          data = my.data,  \n                          constants = my.constants,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          thin = n.thin,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)"},{"path":"intronimble.html","id":"explore-mcmc-outputs","chapter":"2 Introduction to Nimble","heading":"2.11 Explore MCMC outputs","text":"","code":"\nstr(mcmc.output)\n## List of 2\n##  $ chain1: num [1:4000, 1] 0.387 0.226 0.226 0.226 0.346 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"phi\"\n##  $ chain2: num [1:4000, 1] 0.496 0.297 0.402 0.402 0.258 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"phi\"\nhead(mcmc.output$chain1)\n##         phi\n## [1,] 0.3872\n## [2,] 0.2265\n## [3,] 0.2265\n## [4,] 0.2265\n## [5,] 0.3461\n## [6,] 0.3461"},{"path":"intronimble.html","id":"numerical-summaries","chapter":"2 Introduction to Nimble","heading":"2.12 Numerical summaries","text":"","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.34 0.06 0.22 0.34  0.46    1  1747"},{"path":"intronimble.html","id":"trace-and-posterior-density","chapter":"2 Introduction to Nimble","heading":"2.13 Trace and posterior density","text":"","code":"\nMCMCtrace(mcmc.output,\n          pdf = FALSE) \nMCMCtrace(mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE,\n          n.eff = TRUE) "},{"path":"intronimble.html","id":"our-nimble-workflow-so-far","chapter":"2 Introduction to Nimble","heading":"2.14 Our nimble workflow so far","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow_sofar.png\")"},{"path":"intronimble.html","id":"but-nimble-gives-full-access-to-the-mcmc-engine","chapter":"2 Introduction to Nimble","heading":"2.15 But nimble gives full access to the MCMC engine","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow.png\")\nknitr::include_graphics(\"images/I1bIY06.gif\")"},{"path":"intronimble.html","id":"useful-resources","chapter":"2 Introduction to Nimble","heading":"2.16 Useful resources","text":"Official website https://r-nimble.orgOfficial website https://r-nimble.orgUser Manual https://r-nimble.org/html_manual/cha-welcome-nimble.html cheatsheet.User Manual https://r-nimble.org/html_manual/cha-welcome-nimble.html cheatsheet.Users mailing list https://groups.google.com/forum/#!forum/nimble-usersUsers mailing list https://groups.google.com/forum/#!forum/nimble-usersTraining material https://github.com/nimble-trainingTraining material https://github.com/nimble-trainingReference cite using nimble publication:Reference cite using nimble publication:de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, R. Bodik (2017). Programming Models: Writing Statistical Algorithms General Model Structures NIMBLE. Journal Computational Graphical Statistics 26 (2): 403–13.","code":""},{"path":"hmmcapturerecapture.html","id":"hmmcapturerecapture","chapter":"3 Hidden Markov models","heading":"3 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"back-to-our-survival-example","chapter":"3 Hidden Markov models","heading":"3.1 Back to our survival example","text":"\\(z\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\)\\(z\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\)Let’s get back survival example.Let’s get back survival example.model far:model far:\\[\\begin{align*}\n   z &\\sim \\text{Binomial}(n, \\phi) &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]model far combinationOur model far combinationOf binomial likelihoodOf binomial likelihoodAnd Beta prior param 1 1, uniform 0 1.Beta prior param 1 1, uniform 0 1.also:also:\\[\\begin{align*}\n   z_i &\\sim \\text{Bernoulli}(\\phi), \\; = 1, \\ldots, N &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]binomial just sum Bernoulli outcomesThe binomial just sum Bernoulli outcomesLike flipping coin individual get survivor prob phi.Like flipping coin individual get survivor prob phi.several winters? Say \\(T = 5\\) winters.several winters? Say \\(T = 5\\) winters.design, single winter.\nmany species, ’ll need collect data long term get representative estimate survival.design, single winter.\nmany species, ’ll need collect data long term get representative estimate survival.Therefore say big T five winters?Therefore say big T five winters?","code":""},{"path":"hmmcapturerecapture.html","id":"longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.2 Longitudinal data","text":"\\(z_{,t} = 1\\) individual \\(\\) alive winter \\(t\\), \\(z_{,t} = 2\\) dead.call longitudinal data.row individual , columns winters t, sampling occasions.z indexed t, takes value 1 ind alive winter t, 2 otherwise.","code":""},{"path":"hmmcapturerecapture.html","id":"a-model-for-longitudinal-survival-data","chapter":"3 Hidden Markov models","heading":"3.3 A model for longitudinal survival data","text":"model relies assumptions.model relies assumptions.Let’s think model data.Let’s think model data.objective remains , estimating survival.objective remains , estimating survival.build model, ’ll make assumptions.build model, ’ll make assumptions.state animal given winter, alive dead, dependent state winter .state animal given winter, alive dead, dependent state winter .First, assume state animal given winter, alive dead, dependent state winter .First, assume state animal given winter, alive dead, dependent state winter .future depends present, past: Markov process.future depends present, past: Markov process.others words, future depends present, pastIn others words, future depends present, pastThis Markov process.Markov process.animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.","code":""},{"path":"hmmcapturerecapture.html","id":"markov-process","chapter":"3 Hidden Markov models","heading":"3.4 Markov process","text":"markov process can represented way.state t+1 depends state t.model, going winter next driven survival mortality processes.probability going alive 1 alive 1 phi.alive 1 dead 2 1 - phi.probability remain dead 1, go state 2 dead state 2 dead.","code":""},{"path":"hmmcapturerecapture.html","id":"transition-matrix","chapter":"3 Hidden Markov models","heading":"3.5 Transition matrix","text":"core Markov process made transition probabilities.core Markov process made transition probabilities.engine Markov model transition matrix.engine Markov model transition matrix.matrix table gathers probabilities transition states one occasion next.matrix table gathers probabilities transition states one occasion next.example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\gamma_{1,1} & \\gamma_{1,2}\\\\ \n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=D \\\\ \\hdashline\n\\phi & 1-\\phi \\\\\n0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ Take time navigate matrix.\n+ rows, origin, columns, destination.\n+ example…","code":""},{"path":"hmmcapturerecapture.html","id":"initial-states","chapter":"3 Hidden Markov models","heading":"3.6 Initial states","text":"Markov process start somewhere.Markov process start somewhere.need probabilities initial states, .e. states \\(t = 1\\).need probabilities initial states, .e. states \\(t = 1\\).words, need probabilities initial statesIn words, need probabilities initial statesi.e. states \\(t = 1\\)..e. states \\(t = 1\\).use \\(\\mathbf{\\delta} = \\left(\\Pr(z_1 = 1), \\Pr(z_1 = 2)\\right)\\).use \\(\\mathbf{\\delta} = \\left(\\Pr(z_1 = 1), \\Pr(z_1 = 2)\\right)\\).denote delta vector.denote delta vector.gathers probability initial states.gathers probability initial states.alive 1 dead 2.alive 1 dead 2.assume animals alive first winter, .e. \\(\\Pr(z_1 = 1) = 1\\) \\(\\Pr(z_1 = 2) = 0\\).assume animals alive first winter, .e. \\(\\Pr(z_1 = 1) = 1\\) \\(\\Pr(z_1 = 2) = 0\\).individuals marked release first winter.individuals marked release first winter.Therefore alive first captured.Therefore alive first captured.means state 1 alive sure.means state 1 alive sure.","code":""},{"path":"hmmcapturerecapture.html","id":"likelihood","chapter":"3 Hidden Markov models","heading":"3.7 Likelihood","text":"\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)} \\\\\n\\end{align*}\\]OK now ’ve defined Markov model, need likelihood apply Bayes theorem.likelihood probability data, given model. data z.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]’re gonna work backward, starting last sampling occasion.Now likelihood can written product probability zT ie ’re alive last occasion given past history, states previous occasions, times prob past history, y definition cond prob.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]Markov model, ’re memory less, prob next state, zT, depends current state, zT-1, previous states.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]can apply reasoning T-1.First conditional prob.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]markovian property.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n\\end{align*}\\].\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n\\end{align*}\\]end expression likelihood.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}\\\\\n\\end{align*}\\]product cond probabilities. prob initial states Pr(z1).\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\\\\n\\end{align*}\\]recognize gammas defined earlier.transition probabilities.","code":""},{"path":"hmmcapturerecapture.html","id":"example","chapter":"3 Hidden Markov models","heading":"3.8 Example","text":"Let’s assume animal alive, alive dies.Let’s assume animal alive, alive dies.realise calculations bit difficult follow.realise calculations bit difficult follow.Let’s take example.Let’s take example.\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?Let’s apply formula just derived.Let’s apply formula just derived.\\[\\begin{align*}\n\\Pr(\\mathbf{z} = (1, 1, 2)) &= \\Pr(z_1 = 1) \\; \\gamma_{z_{1} = 1, z_{2} = 1} \\; \\gamma_{z_{2} = 1, z_{3} = 2}\\\\\n                            &= 1 \\; \\phi \\; (1 - \\phi).\n\\end{align*}\\]prob sequence alive, alive dead isThe prob sequence alive, alive dead isThe prob alive first, stay alive, die.prob alive first, stay alive, die.prob alive first occasion 1, contribution individual likelihood phi times 1 - phi.prob alive first occasion 1, contribution individual likelihood phi times 1 - phi.Remember:Remember:\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\gamma_{1,1} & \\gamma_{1,2}\\\\ \n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"our-model","chapter":"3 Hidden Markov models","heading":"3.9 Our model","text":"\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   \\color{white}{z_t | z_{t-1}} & \\color{white}{\\sim} \\color{white}{\\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}})} & \\color{white}{\\text{[likelihood, }t > 1 \\text{]}}\\\\\n  \\color{white}{\\phi} & \\color{white}{\\sim} \\color{white}{\\text{Beta}(1, 1)} & \\color{white}{\\text{[prior }\\phi \\text{]}} \\\\ \n\\end{align*}\\]OK let’s wrap .OK let’s wrap .model far one.model far one.Initial state multinomial one trial, probability delta.Initial state multinomial one trial, probability delta.dice two faces, coin, prob alive, 1 - prob dead. + course, want Markov chain start, ’d better say ’s alive delta just (1,0).dice two faces, coin, prob alive, 1 - prob dead. + course, want Markov chain start, ’d better say ’s alive delta just (1,0).","code":""},{"path":"hmmcapturerecapture.html","id":"our-model-1","chapter":"3 Hidden Markov models","heading":"3.10 Our model","text":"\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   \\color{white}{z_t | z_{t-1}} & \\color{white}{\\sim} \\color{white}{\\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}})} & \\color{white}{\\text{[likelihood, }t > 1 \\text{]}}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]also need prior survival.usual take uniform distribution 0 1, beta parameters 1 1.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]Now main part dynamic states.state t depends state t-1, multinomial random variable, one trial.probabilities given rows transition matrix.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\color{blue}{\\phi} & \\color{blue}{1 - \\phi}\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]\\[\\color{blue}{\\gamma_{z_{t-1} = 1,z_{t}} = (\\phi, 1-\\phi)}\\]z t-1 alive, first row, phi 1-phi.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n\\color{blue}{0} & \\color{blue}{1}\n\\end{array}\\right)\n\\end{align*}\\]\\[\\color{blue}{\\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}\\]Otherwise, z t-1 dead 2, second row gamma, 0 1.dead remain dead.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-implementation","chapter":"3 Hidden Markov models","heading":"3.11 Nimble implementation","text":"Nimble, use categorical distribution dcat().Nimble, use categorical distribution dcat().categorical distribution multinomial distribution single draw.categorical distribution multinomial distribution single draw.https://en.wikipedia.org/wiki/Categorical_distributionThe categorical distribution generalization Bernoulli distribution categorical random variable, .e. discrete variable two possible outcomes, roll dice. hand, categorical distribution special case multinomial distribution, gives probabilities potential outcomes single drawing rather multiple drawings.","code":"\nnimble::rcat(n = 20, prob = c(0.1, 0.3, 0.6))\n##  [1] 3 3 3 3 1 1 3 3 3 2 3 2 2 1 3 1 3 3 3 1\nnimble::rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))\n##  [1] 4 3 3 3 2 3 4 5 3 3 3 4 5 5 3 4 3 2 3 3"},{"path":"hmmcapturerecapture.html","id":"nimble-code","chapter":"3 Hidden Markov models","heading":"3.12 Nimble code","text":"]","code":"\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior #<<\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1) #<<\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) #<<\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1) #<<\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1) #<<\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1 #<<\n  delta[2] <- 0          # Pr(dead t = 1) = 0 #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){ #<<\n    z[i,1] ~ dcat(delta[1:2]) \n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    } \n  } #<<\n  })\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2]) #<<\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){ #<<\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    } #<<\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) #<<\n    }\n  }})"},{"path":"hmmcapturerecapture.html","id":"note","chapter":"3 Hidden Markov models","heading":"3.13 Note","text":"Vector \\(\\delta\\) used placeholder complex models come Class 7.Vector \\(\\delta\\) used placeholder complex models come Class 7., write z[,1] <- 1., write z[,1] <- 1.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-awesomness","chapter":"3 Hidden Markov models","heading":"3.14 Nimble awesomness","text":"able define vectors matrices like R.","code":"\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) #<<\n  delta[1:2] <- c(1, 0) #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})"},{"path":"hmmcapturerecapture.html","id":"converting-to-nimble-from-jags-openbugs-or-winbugs","chapter":"3 Hidden Markov models","heading":"3.15 Converting to Nimble from Jags, OpenBUGS or WinBUGS","text":"Main difference Nimble guess.Main difference Nimble guess.need specify dimensions vectors matrices.need specify dimensions vectors matrices.write x[] x[,]. Just provide index ranges x[1:n] x[,1:m].write x[] x[,]. Just provide index ranges x[1:n] x[,1:m].tips .tips .","code":""},{"path":"hmmcapturerecapture.html","id":"constants-and-data","chapter":"3 Hidden Markov models","heading":"3.16 Constants and data","text":"","code":"\nmy.constants <- list(N = 57, T = 5)\nmy.constants\n## $N\n## [1] 57\n## \n## $T\n## [1] 5\n\nmy.data <- list(z = z)"},{"path":"hmmcapturerecapture.html","id":"initial-values","chapter":"3 Hidden Markov models","heading":"3.17 Initial values","text":"","code":"\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.5453"},{"path":"hmmcapturerecapture.html","id":"parameters-to-monitor","chapter":"3 Hidden Markov models","heading":"3.18 Parameters to monitor","text":"","code":"\nparameters.to.save <- c(\"phi\")\nparameters.to.save\n## [1] \"phi\""},{"path":"hmmcapturerecapture.html","id":"mcmc-details-1","chapter":"3 Hidden Markov models","heading":"3.19 MCMC details","text":"","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2"},{"path":"hmmcapturerecapture.html","id":"run-nimble","chapter":"3 Hidden Markov models","heading":"3.20 Run Nimble","text":"","code":"\nmcmc.output <- nimbleMCMC(code = markov.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|"},{"path":"hmmcapturerecapture.html","id":"posterior-distribution-of-survival","chapter":"3 Hidden Markov models","heading":"3.21 Posterior distribution of survival","text":"Posterior mean median close \\(0.8\\).Posterior mean median close \\(0.8\\).Cool! data simulated, (true) survival \\(\\phi = 0.8\\).Cool! data simulated, (true) survival \\(\\phi = 0.8\\).","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.81 0.03 0.74 0.81  0.86    1  1878"},{"path":"hmmcapturerecapture.html","id":"unfortunately-this-is-the-data-we-wish-we-had.","chapter":"3 Hidden Markov models","heading":"3.22 Unfortunately, this is the data we wish we had.","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"in-real-life","chapter":"3 Hidden Markov models","heading":"3.23 In real life","text":"Animals monitored exhaustively, like humans medical trial.Animals monitored exhaustively, like humans medical trial.Animals captured, marked identified released alive.Animals captured, marked identified released alive., animals may detected , go undetected — capture-recaptureThen, animals may detected , go undetected — capture-recaptureWhenever animals go undetected, might alive missed, dead therefore detected — imperfect detection.Whenever animals go undetected, might alive missed, dead therefore detected — imperfect detection.https://www.youtube.com/embed/tyX79mPm2xYWhenever animals go undetected, might alive missed, dead therefore detected — imperfect detection.Whenever animals go undetected, might alive missed, dead therefore detected — imperfect detection.Markov process survival partially observed — hidden Markov models.Markov process survival partially observed — hidden Markov models.","code":""},{"path":"hmmcapturerecapture.html","id":"the-truth-is-in-z","chapter":"3 Hidden Markov models","heading":"3.24 The truth is in \\(z\\)","text":"Unfortunately, partial access \\(z\\).Unfortunately, partial access \\(z\\).observe \\(y\\) detections non-detections.observe \\(y\\) detections non-detections.\\(z\\) \\(y\\) connected?\\(z\\) \\(y\\) connected?","code":""},{"path":"hmmcapturerecapture.html","id":"dead-animals-go-undetected","chapter":"3 Hidden Markov models","heading":"3.25 Dead animals go undetected","text":"animal dead .e. \\(z = 2\\), detected, therefore \\(y = 0\\).","code":""},{"path":"hmmcapturerecapture.html","id":"alive-animals-may-be-detected-or-not","chapter":"3 Hidden Markov models","heading":"3.26 Alive animals may be detected or not","text":"animal alive \\(z = 1\\), detected \\(y = 1\\) w/ prob \\(p\\) \\(y = 0\\) w/ prob \\(1-p\\).animal alive \\(z = 1\\), detected \\(y = 1\\) w/ prob \\(p\\) \\(y = 0\\) w/ prob \\(1-p\\).first detection, know nothing, proceed conditional .first detection, know nothing, proceed conditional .Compare previous tableCompare previous tableSome 1s become 0s.1s become 0s.table \\(y\\) observe real life.table \\(y\\) observe real life.make connection observations, y, true states, zTo make connection observations, y, true states, zWe need describe observations made statesWe need describe observations made states","code":""},{"path":"hmmcapturerecapture.html","id":"observation-matrix","chapter":"3 Hidden Markov models","heading":"3.27 Observation matrix","text":"observation probabilities can packed observation matrix \\(\\mathbf{\\Omega}\\).observation probabilities can packed observation matrix \\(\\mathbf{\\Omega}\\).rows: states alive \\(z = 1\\) dead \\(z = 2\\).rows: states alive \\(z = 1\\) dead \\(z = 2\\).columns: observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively).columns: observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively).\\[\\begin{align*}\n\\mathbf{\\Omega} = \n\\left(\\begin{array}{cc} \n\\omega_{1,1} & \\omega_{1,2}\\\\ \n\\omega_{2,1} & \\omega_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n1 - p & p\\\\ \n1 & 0\n\\end{array}\\right)\n\\end{align*}\\]Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p & p\\\\ \n1 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"hmmcapturerecapture.html","id":"markov-model","chapter":"3 Hidden Markov models","heading":"3.28 Markov model","text":"States \\(z\\) gray.States \\(z\\) gray.Remember graphical repres Markov model.Remember graphical repres Markov model.","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model","chapter":"3 Hidden Markov models","heading":"3.29 Hidden Markov model","text":"States \\(z\\) gray.States \\(z\\) gray.Observations \\(y\\) white.Observations \\(y\\) white.hidden Markov model just two time series.hidden Markov model just two time series.One states Markovian property.One states Markovian property.observations generated states.observations generated states.Run parallel.Run parallel.","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model-for-survival","chapter":"3 Hidden Markov models","heading":"3.30 Hidden Markov model for survival","text":"states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedFor observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedNow add states alive dead, 1 2s.Now add states alive dead, 1 2s.observations, non-detected detected, 1 2s.observations, non-detected detected, 1 2s.parameters, phi transition 1 1.parameters, phi transition 1 1.p prob y 2 detected given z 1 alive.p prob y 2 detected given z 1 alive.","code":""},{"path":"hmmcapturerecapture.html","id":"hmm-likelihood","chapter":"3 Hidden Markov models","heading":"3.31 HMM likelihood","text":"Using formula total probability, likelihood Markov chain:\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\Pr(y_1, y_{2}, \\ldots, y_T)\\\\\n                &= \\sum_{z_1} \\cdots \\sum_{z_T} \\Pr(y_1, y_{2}, \\ldots, y_T | z_1, z_{2}, \\ldots, z_T) \\Pr(z_1, z_{2}, \\ldots, z_T)\\\\\n                &= \\sum_{z_1} \\cdots \\sum_{z_T} \\left(\\prod_{t=1}^T{\\omega_{z_{t}, y_t}}\\right) \\left(\\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\right)\\\\\n\\end{align*}\\]likelihood HMM.likelihood HMM.thing don’t know states.thing don’t know states.go possibilities, sum possible states.go possibilities, sum possible states.Hence sums .Hence sums .term likelihood Markov chain, saw .term likelihood Markov chain, saw .component elements observation matrix.component elements observation matrix.likelihood matrix formulation can useful.likelihood matrix formulation can useful.delta, initial states, observation, transitions, . vector ones end get sum terms.delta, initial states, observation, transitions, . vector ones end get sum terms.matrix formulation:\n\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\mathbf{\\delta} \\; \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\cdots \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\; \\mathbf{\\Omega} \\; \\mathbb{1}\n\\end{align*}\\]matrix formulation:\n\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\mathbf{\\delta} \\; \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\cdots \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\; \\mathbf{\\Omega} \\; \\mathbb{1}\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example-1","chapter":"3 Hidden Markov models","heading":"3.32 Example","text":"Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example-2","chapter":"3 Hidden Markov models","heading":"3.33 Example","text":"Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n\\end{align*}\\]Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1}\\delta_1 \\gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 2}\n\\end{align*}\\]Note: \\(\\Pr(z_1 = 1) = \\delta_1 = 1\\) \\(\\Pr(z_1 = 2) = 0\\).Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 2}\\\\\n&= (1 - p) \\phi + (1-\\phi)\n\\end{align*}\\]Note: \\(w_{z_1 = 1, y_1 = 2} = \\Pr(y_1 = 2 | z_1 = 1) = 1\\) condition first capture.","code":""},{"path":"hmmcapturerecapture.html","id":"estimating-the-latent-states-z-or-not","chapter":"3 Hidden Markov models","heading":"3.34 Estimating the latent states \\(z\\) or not?","text":"Next question , shall estimate latent states ?Next question , shall estimate latent states ?previous example, got rid states, likelihood function \\(\\phi\\) \\(p\\) . function maximize Frequentist approach.previous example, got rid states, likelihood function \\(\\phi\\) \\(p\\) . function maximize Frequentist approach.Bayesian approach MCMC methods allows treating latent states parameters, estimated .Bayesian approach MCMC methods allows treating latent states parameters, estimated .Infering latent states \\(z\\) can useful estimate prevalence, e.g. animal epidemiology prevalence disease, evolutionary ecology sex ratio conservation biology prevalence hybrids.Infering latent states \\(z\\) can useful estimate prevalence, e.g. animal epidemiology prevalence disease, evolutionary ecology sex ratio conservation biology prevalence hybrids.Estimating latent states costly though, required, marginalisation may speed computations. Actually, can estimate states afterwards (Viterbi).Estimating latent states costly though, required, marginalisation may speed computations. Actually, can estimate states afterwards (Viterbi).-called marginalisation Yackulic et al. (2020).-called marginalisation Yackulic et al. (2020).neat thing Nimble provides marginalised models nimbleEcology, ’ll get back Class 8.neat thing Nimble provides marginalised models nimbleEcology, ’ll get back Class 8.","code":""},{"path":"hmmcapturerecapture.html","id":"our-model-2","chapter":"3 Hidden Markov models","heading":"3.35 Our model","text":"\\[\\begin{align*}\n   z_{\\text{first}} &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood]}\\\\\n   y_t | z_{t} &\\sim \\text{Multinomial}(1, \\omega_{z_{t}}) &\\text{[likelihood]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n  p &\\sim \\text{Beta}(1, 1) &\\text{[prior }p \\text{]} \\\\ \n\\end{align*}\\]Now model observation layer ys, conditional z.need prior detection probability.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-implementation-1","chapter":"3 Hidden Markov models","heading":"3.36 Nimble implementation","text":"implement model Nimble?","code":""},{"path":"hmmcapturerecapture.html","id":"priors","chapter":"3 Hidden Markov models","heading":"3.37 Priors","text":"","code":"hmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n..."},{"path":"hmmcapturerecapture.html","id":"hmm-ingredients","chapter":"3 Hidden Markov models","heading":"3.38 HMM ingredients","text":"","code":"\n...\n  # parameters\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n..."},{"path":"hmmcapturerecapture.html","id":"likelihood-1","chapter":"3 Hidden Markov models","heading":"3.39 Likelihood","text":"","code":"...\n    # likelihood\n    for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"hmmcapturerecapture.html","id":"constants","chapter":"3 Hidden Markov models","heading":"3.40 Constants","text":"","code":"\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), T = 5, first = first)\nmy.constants\n## $N\n## [1] 53\n## \n## $T\n## [1] 5\n## \n## $first\n##  [1] 1 4 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 2\n## [29] 1 1 1 1 4 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 2 1"},{"path":"hmmcapturerecapture.html","id":"data","chapter":"3 Hidden Markov models","heading":"3.41 Data","text":"data made 0s non-detections 1s detections.data made 0s non-detections 1s detections.use categorical distribution, need code 1, 2, etc. Value 0 accepted.use categorical distribution, need code 1, 2, etc. Value 0 accepted.Add 1 get correct format \\(y=1\\) non-detection \\(y = 2\\) detection.Add 1 get correct format \\(y=1\\) non-detection \\(y = 2\\) detection.","code":"\nmy.data <- list(y = y + 1)"},{"path":"hmmcapturerecapture.html","id":"initial-values-1","chapter":"3 Hidden Markov models","heading":"3.42 Initial values","text":"","code":"\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)"},{"path":"hmmcapturerecapture.html","id":"parameters-to-monitor-1","chapter":"3 Hidden Markov models","heading":"3.43 Parameters to monitor","text":"","code":"\nparameters.to.save <- c(\"phi\", \"p\")\nparameters.to.save\n## [1] \"phi\" \"p\""},{"path":"hmmcapturerecapture.html","id":"mcmc-details-2","chapter":"3 Hidden Markov models","heading":"3.44 MCMC details","text":"","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2"},{"path":"hmmcapturerecapture.html","id":"run-nimble-1","chapter":"3 Hidden Markov models","heading":"3.45 Run Nimble","text":"","code":"\nmcmc.output <- nimbleMCMC(code = hmm.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nmcmc.output <- nimbleMCMC(code = hmm.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains,\n                          progressBar = FALSE)"},{"path":"hmmcapturerecapture.html","id":"posterior-distribution-of-survival-1","chapter":"3 Hidden Markov models","heading":"3.46 Posterior distribution of survival","text":"data simulated, true survival \\(\\phi = 0.8\\) detection \\(p = 0.6\\).","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.69 0.07 0.55 0.69  0.81 1.01   616\n## phi 0.73 0.05 0.64 0.73  0.82 1.01   927"},{"path":"hmmcapturerecapture.html","id":"further-reading-1","chapter":"3 Hidden Markov models","heading":"3.47 Further reading","text":"Zucchini, MacDonald Langrock (2016) Hidden Markov Models Time Series: Introduction Using R (2nd ed). Chapman Hall/CRC.Zucchini, MacDonald Langrock (2016) Hidden Markov Models Time Series: Introduction Using R (2nd ed). Chapman Hall/CRC.McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. Patterson, T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. Patterson, T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., Reid, J. .. (2020). need speed Bayesian population models: practical guide marginalizing recovering discrete latent states. Ecological Applications 30:e02112.Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., Reid, J. .. (2020). need speed Bayesian population models: practical guide marginalizing recovering discrete latent states. Ecological Applications 30:e02112.L. R. Rabiner (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.L. R. Rabiner (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.Heller Pogaru (2021)","code":""},{"path":"survival.html","id":"survival","chapter":"4 Survival","heading":"4 Survival","text":"","code":"\nknitr::include_graphics(\"images/lebreton.png\")"},{"path":"survival.html","id":"history-of-the-cormack-jolly-seber-cjs-model","chapter":"4 Survival","heading":"4.1 History of the Cormack-Jolly-Seber (CJS) model","text":"S.T. Buckland (2016). Conversation Richard M. Cormack. Statistical Science 31: 142-150.Bayesian uptake","code":""},{"path":"survival.html","id":"what-weve-seen-so-far","chapter":"4 Survival","heading":"4.2 What we’ve seen so far","text":"states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedFor observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detected","code":""},{"path":"survival.html","id":"in-the-cjs-model-survival-and-recapture-are-time-varying","chapter":"4 Survival","heading":"4.3 In the CJS model, survival and recapture are time-varying","text":"Survival probability \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\).Survival probability \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\).Recapture (detection) probability \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\).Recapture (detection) probability \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\).Accounts variation e.g. environmental conditions (survival) sampling effort (detection).Accounts variation e.g. environmental conditions (survival) sampling effort (detection).","code":""},{"path":"survival.html","id":"capture-mark-and-recapture","chapter":"4 Survival","heading":"4.4 Capture, mark and recapture","text":"Artificial marks","code":""},{"path":"survival.html","id":"capture-mark-and-recapture-1","chapter":"4 Survival","heading":"4.5 Capture, mark and recapture","text":"Natural marks","code":""},{"path":"survival.html","id":"the-famous-dipper-example","chapter":"4 Survival","heading":"4.6 The famous Dipper example","text":"\nFigure 4.1: White-throated Dipper (Cinclus cinclus)\n\nFigure 4.2: Gilbert Marzolin\n","code":""},{"path":"survival.html","id":"dippers-captured-and-recaptured-between-1981-and-1987-with-known-sex-and-wing-length","chapter":"4 Survival","heading":"4.7 294 dippers captured and recaptured between 1981 and 1987 with known sex and wing length","text":"","code":""},{"path":"survival.html","id":"back-to-nimble.","chapter":"4 Survival","heading":"4.8 Back to Nimble.","text":"","code":""},{"path":"survival.html","id":"our-model-so-far-phi-p","chapter":"4 Survival","heading":"4.8.1 Our model so far \\((\\phi, p)\\)","text":"","code":"\nhmm.phip <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"survival.html","id":"our-model-so-far-phi-p-1","chapter":"4 Survival","heading":"4.8.2 Our model so far \\((\\phi, p)\\)","text":"","code":"##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.56 0.03 0.52 0.56  0.62 1.00   500\n## p   0.89 0.03 0.83 0.89  0.94 1.13   273"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t","chapter":"4 Survival","heading":"4.8.3 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival #<<\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection #<<\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-1","chapter":"4 Survival","heading":"4.8.4 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){ #<<\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  } #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-2","chapter":"4 Survival","heading":"4.8.5 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1) #<<\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1) #<<\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1) #<<\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) #<<\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-3","chapter":"4 Survival","heading":"4.8.6 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) \n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t) #<<\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t) #<<\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t) #<<\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t) #<<\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-4","chapter":"4 Survival","heading":"4.8.7 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) \n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1]) #<<\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-5","chapter":"4 Survival","heading":"4.8.8 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199\n## phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410\n## phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506\n## phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415\n## phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365\n## phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38\n## p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344\n## p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249\n## p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307\n## p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333\n## p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224\n## p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37"},{"path":"survival.html","id":"time-varying-survival-phi_t-p","chapter":"4 Survival","heading":"4.8.9 Time-varying survival \\((\\phi_t, p)\\)","text":"]","code":"\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"survival.html","id":"time-varying-survival-phi_t-p-1","chapter":"4 Survival","heading":"4.8.10 Time-varying survival \\((\\phi_t, p)\\)","text":"","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564\n## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629\n## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610\n## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553\n## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568\n## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463\n## p      0.89 0.03 0.82 0.89  0.95 1.04   211"},{"path":"survival.html","id":"time-varying-detection-phi-p_t","chapter":"4 Survival","heading":"4.8.11 Time-varying detection \\((\\phi, p_t)\\)","text":"","code":"\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"time-varying-detection-phi-p_t-1","chapter":"4 Survival","heading":"4.8.12 Time-varying detection \\((\\phi, p_t)\\)","text":"","code":"##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.52 0.56  0.61 1.02   381\n## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452\n## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359\n## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412\n## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376\n## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111"},{"path":"survival.html","id":"how-to-select-a-best-model-model-selection","chapter":"4 Survival","heading":"4.9 How to select a best model? Model selection","text":"four models best supported data?four models best supported data?proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .idea penalize models many parameters.idea penalize models many parameters.","code":""},{"path":"survival.html","id":"akaike-information-criterion-aic","chapter":"4 Survival","heading":"4.10 Akaike information criterion (AIC)","text":"\\[AIC = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + 2 K\\]\\(L\\) likelihood \\(K\\) number parameters \\(\\theta_i\\).\\[\\text{AIC} = {\\color{purple}{- 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K))}} + 2 K\\]measure goodness--fit model data: parameters , smaller deviance (bigger likelihood ).\\[\\text{AIC} = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + {\\color{purple}{2 K}}\\]penalty: twice number parameters \\(K\\)AIC makes balance quality fit complexity model.AIC makes balance quality fit complexity model.Best model one lowest AIC value.Best model one lowest AIC value.Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).","code":""},{"path":"survival.html","id":"bayesian-version","chapter":"4 Survival","heading":"4.11 Bayesian version","text":"Watanabe-Akaike (Widely-Applicable) Information Criteria WAIC:\\[\\textrm{WAIC} = -2 \\sum_{= 1}^n \\log E[\\Pr(y_i \\mid \\theta)] + \n                  2 p_\\text{WAIC}\\]\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.","code":""},{"path":"survival.html","id":"how-to-compute-waic-in-nimble","chapter":"4 Survival","heading":"4.12 How to compute WAIC in Nimble?","text":"","code":"\nparameters.to.save <- c(\"phi\", \"p\")\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nparameters.to.save <- c(\"phi\", \"p\", \"z\") #<<\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains,\n                          WAIC = TRUE) #<<"},{"path":"survival.html","id":"dipper-example---continued","chapter":"4 Survival","heading":"4.13 Dipper example - continued","text":"","code":"##       model  WAIC\n## 1   (phi,p) 265.9\n## 2  (phit,p) 277.6\n## 3  (phi,pt) 270.2\n## 4 (phit,pt) 308.8"},{"path":"survival.html","id":"can-we-explain-time-variation-embrace-heterogeneity","chapter":"4 Survival","heading":"4.14 Can we explain time variation? Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\).Include temporal covariates, say \\(x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).Let’s investigate effect water flow dipper survival (Marzolin 2002).Let’s investigate effect water flow dipper survival (Marzolin 2002).]","code":"\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] #<<\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5) # prior intercept #<<\n  beta[2] ~ dnorm(0, 1.5) # prior slope #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\n# water flow in L/s\nwater_flow <- c(443, 1114, 529, 434, 627, 466) # 1981, 1982, ..., 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow) #<<\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first, \n                     flow = water_flow_st) #<<\n\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\n\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")"},{"path":"survival.html","id":"regression-intercept-and-slope","chapter":"4 Survival","heading":"4.14.1 Regression intercept and slope","text":"","code":""},{"path":"survival.html","id":"time-dependent-covariate-constrained-survival-probability-estimates","chapter":"4 Survival","heading":"4.14.2 Time-dependent (covariate constrained) survival probability estimates","text":"","code":""},{"path":"survival.html","id":"embrace-heterogeneity","chapter":"4 Survival","heading":"4.15 Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\)Include temporal covariates, say \\(x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)temporal variation fully explained covariates, add random effectsIf temporal variation fully explained covariates, add random effects\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)","code":"hmm.phiflowREp <- nimbleCode({\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] + eps[t] \n    eps[t] ~ dnorm(0, sd = sdeps) \n    ...  \n  }\n  sdeps ~ dunif(0,10) \n  ..."},{"path":"survival.html","id":"what-about-individual-heterogeneity","chapter":"4 Survival","heading":"4.16 What about individual heterogeneity?","text":"Discrete covariate like, e.g., sexDiscrete covariate like, e.g., sexContinuous covariate like, e.g., mass sizeContinuous covariate like, e.g., mass size","code":""},{"path":"survival.html","id":"sex-and-wing-length-in-dipper","chapter":"4 Survival","heading":"4.17 Sex and wing length in Dipper","text":"","code":""},{"path":"survival.html","id":"sex-effect","chapter":"4 Survival","heading":"4.18 Sex effect","text":"Let’s use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleLet’s use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleAnd write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)male survival isThen male survival \\[\\text{logit}(\\phi_i) = \\beta_1\\]female survival \\[\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2\\]","code":""},{"path":"survival.html","id":"nimble-implementation-with-sex-as-a-covariate","chapter":"4 Survival","heading":"4.18.1 Nimble implementation with sex as a covariate","text":"","code":"\nhmm.phisexp <- nimbleCode({\n...\n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * sex[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  } #<<\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) #<<\n  phi_male <- 1/(1+exp(-beta[1])) #<<\n  phi_female <- 1/(1+exp(-(beta[1]+beta[2]))) #<<\n...\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##             mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]     0.29 0.14  0.01  0.29  0.57 1.01   237\n## beta[2]    -0.09 0.19 -0.47 -0.10  0.29 1.01   241\n## p           0.90 0.03  0.83  0.90  0.95 1.02   253\n## phi_female  0.55 0.04  0.48  0.55  0.62 1.02   698\n## phi_male    0.57 0.03  0.50  0.57  0.64 1.01   237"},{"path":"survival.html","id":"nimble-implementation-with-nested-indexing","chapter":"4 Survival","heading":"4.18.2 Nimble implementation with nested indexing","text":"Let’s use covariate \\(\\text{sex}\\) contains 1s 2s, indicating sex individual: 1 male, 2 femaleE.g. individual \\(= 2\\), beta[sex[]] gives beta[sex[2]] beta[1] beta[2] depending whether sex[2] 1 2.","code":"\n...\nfor (i in 1:N){\n  phi[i] <- beta[sex[i]] #<<\n  gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n}\nbeta[1] ~ dunif(0,1) # male survival #<<\nbeta[2] ~ dunif(0,1) # female survival #<<\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## beta[1] 0.57 0.03 0.50 0.57  0.63 1.00   616\n## beta[2] 0.55 0.03 0.48 0.55  0.62 1.02   657\n## p       0.90 0.03 0.83 0.90  0.95 1.10   229"},{"path":"survival.html","id":"what-about-wing-length","chapter":"4 Survival","heading":"4.18.3 What about wing length?","text":"","code":"\n...  \n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # slope #<<\n..."},{"path":"survival.html","id":"wing-length","chapter":"4 Survival","heading":"4.18.4 Wing length","text":"may test effect sex wing length, see exercise Worksheets.","code":""},{"path":"survival.html","id":"what-if-covariates-vary-with-individual-and-time","chapter":"4 Survival","heading":"4.19 What if covariates vary with individual and time?","text":"Think age example (see exercises Worksheets); covariate nested indexing works fine.Think age example (see exercises Worksheets); covariate nested indexing works fine.Now, think body size across life.Now, think body size across life.Problem record size animal non-detected.Problem record size animal non-detected.Discretize small, medium large treat state — later.Discretize small, medium large treat state — later.Assume model covariate fill missing values (imputation).Assume model covariate fill missing values (imputation).","code":""},{"path":"survival.html","id":"why-bayes-incorporate-prior-information.","chapter":"4 Survival","heading":"4.20 Why Bayes? Incorporate prior information.","text":"","code":""},{"path":"survival.html","id":"vague-prior","chapter":"4 Survival","heading":"4.21 Vague prior","text":"far, assumed vague prior:\\[\\phi_{prior} \\sim \\text{Beta}(1,1) = \\text{Uniform}(0,1)\\]vague prior, mean posterior survival \\(\\phi_{posterior} = 0.56\\)vague prior, mean posterior survival \\(\\phi_{posterior} = 0.56\\)credible interval \\([0.52,0.62]\\)credible interval \\([0.52,0.62]\\)Posterior distribution survival color (two chains), prior gray dashed line.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information","chapter":"4 Survival","heading":"4.22 How to incorporate prior information?","text":"Using information body mass annual survival 27 European passerines, can predict survival European dippers using body mass.Using information body mass annual survival 27 European passerines, can predict survival European dippers using body mass.dippers, body mass 59.8g, therefore \\(\\phi = 0.57\\) \\(\\text{sd} = 0.073\\).dippers, body mass 59.8g, therefore \\(\\phi = 0.57\\) \\(\\text{sd} = 0.073\\).Assuming informative prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\).Assuming informative prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\).Mean posterior \\(\\phi_{posterior} = 0.56\\) credible interval \\([0.52, 0.61]\\).Mean posterior \\(\\phi_{posterior} = 0.56\\) credible interval \\([0.52, 0.61]\\).increase precision posterior inference.increase precision posterior inference.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information-1","chapter":"4 Survival","heading":"4.23 How to incorporate prior information?","text":"Now three first years data, happened?Now three first years data, happened?Width credible interval 0.53 (vague prior) vs. 0.24 (informative prior).Width credible interval 0.53 (vague prior) vs. 0.24 (informative prior).Huge increase precision posterior inference, \\(120\\%\\) gain!Huge increase precision posterior inference, \\(120\\%\\) gain!","code":""},{"path":"survival.html","id":"compare-survival-posterior-with-and-without-informative-prior","chapter":"4 Survival","heading":"4.23.1 Compare survival posterior with and without informative prior","text":"","code":""},{"path":"survival.html","id":"prior-elicitation-via-moment-matching","chapter":"4 Survival","heading":"4.24 Prior elicitation via moment matching","text":"prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\) entirely satisfyingThe prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\) entirely satisfyingRemember Beta distributionRemember Beta distributionRecall Beta distribution continuous distribution values 0 1. Useful modelling survival detection probabilities.Recall Beta distribution continuous distribution values 0 1. Useful modelling survival detection probabilities.\\(X \\sim Beta(\\alpha,\\beta)\\), first second moments \\(X\\) :\\(X \\sim Beta(\\alpha,\\beta)\\), first second moments \\(X\\) :\\[\\mu = \\text{E}(X) = \\frac{\\alpha}{\\alpha + \\beta}\\]\\[\\sigma^2 = \\text{Var}(X) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\]","code":""},{"path":"survival.html","id":"moment-matching","chapter":"4 Survival","heading":"4.25 Moment matching","text":"capture-recapture example, know priori mean probability ’re interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\).capture-recapture example, know priori mean probability ’re interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\).Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution.Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution.Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\).Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\).need another set equations:need another set equations:\\[\\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2\\]\\[\\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg)\\]model, means:Now use \\(\\phi_{prior} \\sim \\text{Beta}(\\alpha = 25.6,\\beta = 19.3)\\) instead \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\)","code":"\n(alpha <- ( (1 - 0.57)/(0.073*0.073) - (1/0.57) )*0.57^2)\n## [1] 25.65\n(beta <- alpha * ( (1/0.57) - 1))\n## [1] 19.35"},{"path":"survival.html","id":"prior-predictive-checks","chapter":"4 Survival","heading":"4.26 Prior predictive checks","text":"","code":""},{"path":"survival.html","id":"linear-regression","chapter":"4 Survival","heading":"4.27 Linear regression","text":"Unreasonable prior \\(\\beta \\sim N(0, 1000^2)\\)Reasonable prior \\(\\beta \\sim N(2, 0.5^2)\\)","code":""},{"path":"survival.html","id":"logistic-regression","chapter":"4 Survival","heading":"4.28 Logistic regression","text":"Unreasonable prior \\(\\text{logit}(\\phi) = \\beta \\sim N(0, 10^2)\\)Reasonable prior \\(\\text{logit}(\\phi) = \\beta \\sim N(0, 1.5^2)\\)","code":""},{"path":"survival.html","id":"capture-recapture-models-rely-on-assumptions","chapter":"4 Survival","heading":"4.29 Capture-recapture models rely on assumptions","text":"Design\nmark lost\nIdentity individuals recorded without error (false positives)\nCaptured individuals random sample\nmark lostIdentity individuals recorded without error (false positives)Captured individuals random sampleModel\nHomogeneity survival recapture probabilities\nIndependence individuals (overdispersion)\nHomogeneity survival recapture probabilitiesIndependence individuals (overdispersion)Test validity assumptions\nassumptions valid, whatever inferential framework\nUse goodness--fit tests — Pradel et al. (2005)\nR implementation package R2ucare\nPosterior predictive checks can also used (covered; Gelman et al. 2020)\nassumptions valid, whatever inferential frameworkUse goodness--fit tests — Pradel et al. (2005)R implementation package R2ucarePosterior predictive checks can also used (covered; Gelman et al. 2020)","code":""},{"path":"survival.html","id":"parameter-redundancy-issue","chapter":"4 Survival","heading":"4.29.1 Parameter-redundancy issue","text":"Last survival recapture probabilities estimated separately.Last survival recapture probabilities estimated separately.Poor mixing chains.Poor mixing chains.","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-phi_4-and-phi_6","chapter":"4 Survival","heading":"4.30 Prior-posterior overlap for \\(\\phi_4\\) and \\(\\phi_6\\)","text":"","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-p_3-and-p_7","chapter":"4 Survival","heading":"4.31 Prior-posterior overlap for \\(p_3\\) and \\(p_7\\)","text":"","code":""},{"path":"survival.html","id":"what-does-survival-actually-mean-in-capture-recapture","chapter":"4 Survival","heading":"4.32 What does survival actually mean in capture-recapture ?","text":"Survival refers study area.Survival refers study area.Mortality permanent emigration confounded.Mortality permanent emigration confounded.Therefore estimate apparent survival, true survival.Therefore estimate apparent survival, true survival.Apparent survival probability = true survival × study area fidelity.Apparent survival probability = true survival × study area fidelity.Consequently, apparent survival < true survival unless study area fidelity = 1.Consequently, apparent survival < true survival unless study area fidelity = 1.Use caution interpretation. possible, combine ring-recovery data, go spatial get closer true survival.Use caution interpretation. possible, combine ring-recovery data, go spatial get closer true survival.","code":""},{"path":"survival.html","id":"further-reading-2","chapter":"4 Survival","heading":"4.33 Further reading","text":"CJS state-space formulation Gimenez et al. (2007) Royle (2008).CJS state-space formulation Gimenez et al. (2007) Royle (2008).Work missing values Bonner et al. (2006) Langrock King (2013) Worthington et al. (2015).Work missing values Bonner et al. (2006) Langrock King (2013) Worthington et al. (2015).example incorporate prior information McCarthy Masters (2005).example incorporate prior information McCarthy Masters (2005).Combine live recapture w/ dead recoveries Lebreton et al. (1999) go spatial account emigration Gilroy et al. (2012) Schaub & Royle (2014).Combine live recapture w/ dead recoveries Lebreton et al. (1999) go spatial account emigration Gilroy et al. (2012) Schaub & Royle (2014).Non-identifiability Bayesian framework, see Gimenez et al. (2009) book Cole (2020).Non-identifiability Bayesian framework, see Gimenez et al. (2009) book Cole (2020).","code":""},{"path":"transition.html","id":"transition","chapter":"5 Transition","heading":"5 Transition","text":"Thank Canada!","code":"\nknitr::include_graphics(\"images/arnason1973.png\")\nknitr::include_graphics(\"images/schwarz1993.png\")\nknitr::include_graphics(\"images/deadpool.gif\")\nknitr::include_graphics(\"images/nichols.png\")"},{"path":"transition.html","id":"wintering-site-fidelity-in-canada-geese","chapter":"5 Transition","heading":"5.1 Wintering site fidelity in Canada Geese","text":"","code":""},{"path":"transition.html","id":"sites-carolinas-chesapeake-mid-atlantic","chapter":"5 Transition","heading":"5.1.1 3 sites Carolinas, Chesapeake, Mid-Atlantic,","text":"21277 banded geese, data kindly provided Jay Hestbeck (Hestbeck et al. 1991)(large areas along East coast US)","code":""},{"path":"transition.html","id":"biological-inference","chapter":"5 Transition","heading":"5.1.2 Biological inference","text":"Observations states closely related, entirely.","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.","chapter":"5 Transition","heading":"5.1.3 The model construction: How we should think.","text":"Generative model. States generate observations.","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-1","chapter":"5 Transition","heading":"5.1.4 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-2","chapter":"5 Transition","heading":"5.1.5 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-3","chapter":"5 Transition","heading":"5.1.6 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas","chapter":"5 Transition","heading":"5.1.7 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_{t}=& z_{t}=B & z_{t}=D \\\\ \\hdashline\n\\phi_A (1-\\psi_{AB}) & \\phi_A \\psi_{AB} & 1 - \\phi_A\\\\ \n\\phi_B \\psi_{BA} & \\phi_B (1-\\psi_{BA}) & 1 - \\phi_B\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-1","chapter":"5 Transition","heading":"5.1.8 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-2","chapter":"5 Transition","heading":"5.1.9 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: may code non-detections \\(y_t = 2\\), first column observation matrix go last.Quick answer -1 important issue coding states obs. purpose, folks think difference observations states (non-detection obs confused state dead). becomes even crucial get multievent models several observations may generated single state. get intuition argument perfectly, ’d like fight first, ’re comfortable difference, may code obs/states see fit. Let’s see goes. agree mention multistate lecture, spirit « ’re free code states jobs way like ». ’ll add something.","code":""},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b","chapter":"5 Transition","heading":"5.1.10 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiA: survival probability site A\n  # phiB: survival probability site B\n  # psiAB: movement probability from site A to site B\n  # psiBA: movement probability from site B to site A\n  # pA: recapture probability site A\n  # pB: recapture probability site B\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at A\n  # 2 alive at B\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen at A \n  # 3 seen at B\n  # -------------------------------------------------\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1","chapter":"5 Transition","heading":"5.1.11 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...\n  # Priors\n  phiA ~ dunif(0, 1)\n  phiB ~ dunif(0, 1)\n  psiAB ~ dunif(0, 1)\n  psiBA ~ dunif(0, 1)\n  pA ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2","chapter":"5 Transition","heading":"5.1.12 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"Actually, initial state known exactly. alive site initial capture, \\(\\pi_A\\) just proportion individuals first captured site , need estimate .Actually, initial state known exactly. alive site initial capture, \\(\\pi_A\\) just proportion individuals first captured site , need estimate .Instead z[,first[]] ~ dcat(delta[1:3]), use z[,first[]] <- y[,first[]]-1 instead likelihood.Instead z[,first[]] ~ dcat(delta[1:3]), use z[,first[]] <- y[,first[]]-1 instead likelihood.trick applies CJS models.trick applies CJS models.","code":"multisite <- nimbleCode({\n...  \n  # initial state probabilities\n  delta[1] <- piA          # Pr(alive in A t = 1)\n  delta[2] <- 1 - piA      # Pr(alive in B t = 1)\n  delta[3] <- 0            # Pr(dead t = 1) = 0\n...  "},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3","chapter":"5 Transition","heading":"5.1.13 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  # (read as gamma[z(t),z(t+1)] = gamma[fromState,toState])\n  \n  gamma[1,1] <- phiA * (1 - psiAB)\n  gamma[1,2] <- phiA * psiAB\n  gamma[1,3] <- 1 - phiA\n  gamma[2,1] <- phiB * psiBA\n  gamma[2,2] <- phiB * (1 - psiBA)\n  gamma[2,3] <- 1 - phiB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...  "},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4","chapter":"5 Transition","heading":"5.1.14 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  # (read as omega[y(t),z(t)] = omega[Observation,State])\n\n  omega[1,1] <- 1 - pA     # Pr(alive A t -> non-detected t)\n  omega[1,2] <- pA         # Pr(alive A t -> detected A t)\n  omega[1,3] <- 0          # Pr(alive A t -> detected B t)\n  omega[2,1] <- 1 - pB     # Pr(alive B t -> non-detected t)\n  omega[2,2] <- 0          # Pr(alive B t -> detected A t)\n  omega[2,3] <- pB         # Pr(alive B t -> detected B t)\n  omega[3,1] <- 1          # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0          # Pr(dead t -> detected A t)\n  omega[3,3] <- 0          # Pr(dead t -> detected B t)\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5","chapter":"5 Transition","heading":"5.1.15 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"\nmultisite <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA    0.53 0.09 0.36 0.52  0.73 1.04   122\n## pB    0.40 0.04 0.32 0.40  0.48 1.07   165\n## phiA  0.60 0.05 0.50 0.60  0.71 1.01   195\n## phiB  0.69 0.04 0.62 0.69  0.76 1.04   199\n## psiAB 0.27 0.06 0.16 0.26  0.40 1.04   244\n## psiBA 0.07 0.02 0.04 0.07  0.12 1.03   360"},{"path":"transition.html","id":"what-if-there-are-three-sites","chapter":"5 Transition","heading":"5.2 What if there are three sites?","text":"transition probabilities still need 0 1.transition probabilities still need 0 1.Another constraint sum three probabilities departure given site one.Another constraint sum three probabilities departure given site one.Two methods fulfill constraints.\nDirichlet prior\nMultinomial logit link\nTwo methods fulfill constraints.Dirichlet priorMultinomial logit linkDirichlet prior parameter alpha\nFigure 5.1: Dirichlet prior parameter alpha\n","code":""},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior","chapter":"5 Transition","heading":"5.2.1 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: Dirichlet priors\n  psiA[1:3] ~ ddirch(alpha[1:3]) # psiAA, psiAB, psiAC\n  psiB[1:3] ~ ddirch(alpha[1:3]) # psiBA, psiBB, psiCC\n  psiC[1:3] ~ ddirch(alpha[1:3]) # psiCA, psiCB, psiCC\n..."},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-1","chapter":"5 Transition","heading":"5.2.2 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.50 0.09 0.34 0.50  0.70 1.00   153\n## pB      0.47 0.05 0.38 0.46  0.58 1.01   152\n## pC      0.24 0.06 0.14 0.23  0.37 1.01   117\n## phiA    0.61 0.05 0.50 0.61  0.71 1.00   230\n## phiB    0.70 0.04 0.62 0.70  0.77 1.04   183\n## phiC    0.77 0.07 0.64 0.77  0.92 1.07   104\n## psiA[1] 0.75 0.05 0.63 0.75  0.84 1.01   463\n## psiA[2] 0.23 0.05 0.14 0.22  0.34 1.01   441\n## psiA[3] 0.02 0.02 0.00 0.02  0.08 1.03   201\n## psiB[1] 0.07 0.02 0.04 0.07  0.12 1.00   275\n## psiB[2] 0.83 0.04 0.72 0.83  0.90 1.04   129\n## psiB[3] 0.10 0.04 0.04 0.09  0.18 1.06   129\n## psiC[1] 0.02 0.01 0.00 0.02  0.06 1.00   624\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.02   420\n## psiC[3] 0.77 0.06 0.64 0.77  0.86 1.02   419"},{"path":"transition.html","id":"multinomial-logit","chapter":"5 Transition","heading":"5.2.3 Multinomial logit","text":"Say \\(P\\) sites states.Say \\(P\\) sites states.Specify normal prior distribution \\(P-1\\) transition parameters \\(\\alpha_j\\). probabilities multinomial logit scale, possibly function covariates.Specify normal prior distribution \\(P-1\\) transition parameters \\(\\alpha_j\\). probabilities multinomial logit scale, possibly function covariates.back-transform parameters, use:back-transform parameters, use:\\[\\beta_j = \\displaystyle{\\frac{\\exp(\\alpha_j)}{1+\\displaystyle{\\sum_{p=1}^P{\\exp(\\alpha_p)}}}}, j = 1,\\ldots,P-1\\]ensures \\(\\beta_j\\) 0 1, sum 1.ensures \\(\\beta_j\\) 0 1, sum 1.Last parameter calculated complement \\(\\beta_P = 1 - \\displaystyle{\\sum_{j=1}^{P-1}{\\exp(\\beta_j)}}\\)Last parameter calculated complement \\(\\beta_P = 1 - \\displaystyle{\\sum_{j=1}^{P-1}{\\exp(\\beta_j)}}\\)","code":""},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-2","chapter":"5 Transition","heading":"5.2.4 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: multinomial logit\n  # normal priors on logit of all but one transition probs\n  for (i in 1:2){\n    lpsiA[i] ~ dnorm(0, sd = 1000)\n    lpsiB[i] ~ dnorm(0, sd = 1000)\n    lpsiC[i] ~ dnorm(0, sd = 1000)\n  }\n  # constrain the transitions such that their sum is < 1\n  for (i in 1:2){\n    psiA[i] <- exp(lpsiA[i]) / (1 + exp(lpsiA[1]) + exp(lpsiA[2]))\n    psiB[i] <- exp(lpsiB[i]) / (1 + exp(lpsiB[1]) + exp(lpsiB[2]))\n    psiC[i] <- exp(lpsiC[i]) / (1 + exp(lpsiC[1]) + exp(lpsiC[2]))\n  }\n  # last transition probability\n  psiA[3] <- 1 - psiA[1] - psiA[2]\n  psiB[3] <- 1 - psiB[1] - psiB[2]\n  psiC[3] <- 1 - psiC[1] - psiC[2]\n..."},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-3","chapter":"5 Transition","heading":"5.2.5 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.52 0.08 0.36 0.52  0.69 1.02   154\n## pB      0.45 0.05 0.35 0.44  0.55 1.10   129\n## pC      0.26 0.06 0.15 0.25  0.39 1.01    94\n## phiA    0.60 0.05 0.50 0.60  0.71 1.01   244\n## phiB    0.70 0.04 0.63 0.70  0.77 1.11   168\n## phiC    0.76 0.07 0.63 0.76  0.88 1.03   126\n## psiA[1] 0.76 0.05 0.64 0.76  0.85 1.02   477\n## psiA[2] 0.24 0.05 0.15 0.24  0.36 1.01   486\n## psiA[3] 0.00 0.00 0.00 0.00  0.00 1.35    47\n## psiB[1] 0.07 0.02 0.04 0.06  0.11 1.03   394\n## psiB[2] 0.85 0.04 0.77 0.86  0.91 1.04   133\n## psiB[3] 0.08 0.03 0.04 0.08  0.16 1.01    79\n## psiC[1] 0.01 0.01 0.00 0.01  0.04 1.00   514\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.00   299\n## psiC[3] 0.78 0.06 0.65 0.78  0.88 1.00   270"},{"path":"transition.html","id":"sites-may-be-states.","chapter":"5 Transition","heading":"5.3 Sites may be states.","text":"","code":""},{"path":"transition.html","id":"examples-of-multistate-models","chapter":"5 Transition","heading":"5.4 Examples of multistate models","text":"Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Morphological states: small/medium/big, light/medium/heavy.Morphological states: small/medium/big, light/medium/heavy.Breeding states: e.g. breeder/non-breeder, failed breeder, first-time breeder.Breeding states: e.g. breeder/non-breeder, failed breeder, first-time breeder.Developmental life-history states: e.g. juvenile/subadult/adult.Developmental life-history states: e.g. juvenile/subadult/adult.Social states: e.g. solitary/group-living, subordinate/dominant.Social states: e.g. solitary/group-living, subordinate/dominant.Death states: e.g. alive, dead harvest, dead natural causes.Death states: e.g. alive, dead harvest, dead natural causes.States = individual, time-specific categorical covariates.","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"transition.html","id":"sooty-shearwater-david-boyle","chapter":"5 Transition","heading":"5.4.1 Sooty shearwater (David Boyle)","text":"","code":""},{"path":"transition.html","id":"sooty-shearwaters-and-life-history-tradeoffs","chapter":"5 Transition","heading":"5.5 Sooty shearwaters and life-history tradeoffs","text":"consider data collected 1940 1957 Lance Richdale Sooty shearwaters (aka titis).consider data collected 1940 1957 Lance Richdale Sooty shearwaters (aka titis).data reanalyzed multistate models Scofield et al. (2001) kindly provided us data.data reanalyzed multistate models Scofield et al. (2001) kindly provided us data.Following way data collected, four states originally considered:\nAlive breeder;\nAccompanied another bird burrow;\nAlone burrow;\nsurface;\nDead.\nFollowing way data collected, four states originally considered:Alive breeder;Accompanied another bird burrow;Alone burrow;surface;Dead.","code":""},{"path":"transition.html","id":"sooty-shearwaters-and-life-history-tradeoffs-1","chapter":"5 Transition","heading":"5.6 Sooty shearwaters and life-history tradeoffs","text":"numerical issues, pooled alive states breeder together non-breeder state (NB) includes:\nfailed breeders (birds bred previously – skip reproduction divorce) pre-breeders (birds yet breed).\nNote burrows checked hatching, birds category NB might already failed.\ntherefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.\nnumerical issues, pooled alive states breeder together non-breeder state (NB) includes:failed breeders (birds bred previously – skip reproduction divorce) pre-breeders (birds yet breed).failed breeders (birds bred previously – skip reproduction divorce) pre-breeders (birds yet breed).Note burrows checked hatching, birds category NB might already failed.Note burrows checked hatching, birds category NB might already failed.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.Observations non-detections, detections breeder non-breederObservations non-detections, detections breeder non-breederDoes breeding affect survival? breeding current year affect breeding next year?breeding affect survival? breeding current year affect breeding next year?","code":""},{"path":"transition.html","id":"hmm-model-for-transition-between-states","chapter":"5 Transition","heading":"5.6.1 HMM model for transition between states","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\ \n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Costs reproduction reflect future reproduction \\(\\psi_{BB} = 1 - \\psi_{BNB} < \\psi_{NBB}\\) survival \\(\\phi_B < \\phi_{NB}\\).","code":""},{"path":"transition.html","id":"hmm-model-for-transition-between-states-1","chapter":"5 Transition","heading":"5.6.2 HMM model for transition between states","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_B & p_B & 0\\\\ \n1 - p_{NB} & 0 & p_{NB}\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b","chapter":"5 Transition","heading":"5.6.3 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen as B \n  # 3 seen as NB\n  # -------------------------------------------------\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1","chapter":"5 Transition","heading":"5.6.4 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2","chapter":"5 Transition","heading":"5.6.5 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...  "},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3","chapter":"5 Transition","heading":"5.6.6 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB    # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB        # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0         # Pr(alive B t -> detected NB t)\n  omega[2,1] <- 1 - pNB   # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0         # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB       # Pr(alive NB t -> detected NB t)\n  omega[3,1] <- 1         # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0         # Pr(dead t -> detected N t)\n  omega[3,3] <- 0         # Pr(dead t -> detected NB t)\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4","chapter":"5 Transition","heading":"5.6.7 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"\nFigure 5.2: Dirichlet prior parameter alpha\n","code":"\nmultistate <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pB     0.60 0.03 0.54 0.59  0.66 1.00   202\n## pNB    0.57 0.03 0.51 0.57  0.62 1.01   281\n## phiB   0.80 0.02 0.77 0.80  0.83 1.01   313\n## phiNB  0.85 0.02 0.82 0.85  0.88 1.00   404\n## psiBNB 0.25 0.02 0.21 0.25  0.30 1.00   434\n## psiNBB 0.24 0.02 0.20 0.24  0.29 1.03   478"},{"path":"transition.html","id":"multistate-models-are-very-flexible","chapter":"5 Transition","heading":"5.7 Multistate models are very flexible","text":"Access reproductionAccess reproductionTemporary emigrationTemporary emigrationCombination life dead encountersCombination life dead encounters","code":""},{"path":"transition.html","id":"access-to-reproduction","chapter":"5 Transition","heading":"5.7.1 Access to reproduction","text":"Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=J & z_t=1yNB & z_t=2yNB & z_t=B & z_t=D \\\\ \\hdashline\n0 & \\phi_1 (1-\\alpha_1) & 0 & \\phi_1 \\alpha_1 & 1 - \\phi_1\\\\ \n0 & 0 & \\phi_2 (1-\\alpha_2) & \\phi_2 \\alpha_2 & 1 - \\phi_2\\\\ \n0 & 0 & 0 & \\phi_3 & 1 - \\phi_3\\\\ \n0 & 0 & 0 & \\phi_B & 1 - \\phi_B\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1} = J \\\\ z_{t-1} = 1yNB \\\\ z_{t-1} = 2yNB \\\\ z_{t-1} = B \\\\ z_{t-1} = D\n    \\end{matrix}\n\\end{matrix}\n\\]First-year second-year individuals breed probabilities \\(\\alpha_1\\) \\(\\alpha_2\\).First-year second-year individuals breed probabilities \\(\\alpha_1\\) \\(\\alpha_2\\)., everybody breeds age 3., everybody breeds age 3.","code":""},{"path":"transition.html","id":"access-to-reproduction-1","chapter":"5 Transition","heading":"5.7.2 Access to reproduction","text":"Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t = 0 & y_t = 1 & y_t = 2 & y_t = 3\\\\ \\hdashline\n1 & 0 & 0 & 0\\\\\n1 - p_1 & p_1 & 0 & 0\\\\ \n1 - p_2 & 0 & p_2 & 0\\\\ \n1 - p_3 & 0 & 0 & p_3\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t = J \\\\ z_t = 1yNB \\\\ z_t = 2yNB \\\\ z_t = B \\\\ z_t = D\n    \\end{matrix}\n\\end{matrix}\n\\]Juveniles never detected.","code":""},{"path":"transition.html","id":"temporary-emigration","chapter":"5 Transition","heading":"5.8 Temporary emigration","text":"Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=\\text{} & z_t=\\text{} & z_t=\\text{D} \\\\ \\hdashline\n\\phi (1-\\psi_{\\text{} \\rightarrow \\text{}}) & \\phi \\psi_{\\text{} \\rightarrow \\text{}} & 1 - \\phi\\\\ \n\\phi \\psi_{\\text{} \\rightarrow \\text{}} & \\phi (1-\\psi_{\\text{} \\rightarrow \\text{}}) & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\text{} \\\\ z_{t-1}=\\text{} \\\\ z_{t-1}=\\text{D}\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 \\\\ \\hdashline\n1 - p & p\\\\ \n1 & 0\\\\\n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\text{} \\\\ z_{t}=\\text{} \\\\ z_{t}=\\text{D}\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"combination-of-life-and-dead-encounters","chapter":"5 Transition","heading":"5.8.1 Combination of life and dead encounters","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=JD & z_t=D \\\\ \\hdashline\ns & 1-s & 0\\\\ \n0 & 0 & 1\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\text{alive} \\\\ z_{t-1}=\\text{just dead} \\\\ z_{t-1}=\\text{dead good}\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p & 0 & p\\\\ \n1 - r & r & 0\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=JD \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"issue-of-local-minima","chapter":"5 Transition","heading":"5.9 Issue of local minima","text":"Simulated data\n2 sites states, 7 occasions\nSurvival \\(\\phi = 1\\), detection \\(p = 0.6\\)\nTransition \\(\\psi_{12} = 0.6\\)\nTransition \\(\\psi_{21} = 0.85\\)\n2 sites states, 7 occasionsSurvival \\(\\phi = 1\\), detection \\(p = 0.6\\)Transition \\(\\psi_{12} = 0.6\\)Transition \\(\\psi_{21} = 0.85\\)Courtesy Jérôme Dupuis, used Gimenez et al. (2005).","code":""},{"path":"transition.html","id":"data-1","chapter":"5 Transition","heading":"5.9.1 Data","text":"","code":"\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_05.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_06.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_07.png\")"},{"path":"transition.html","id":"further-reading-3","chapter":"5 Transition","heading":"5.10 Further reading","text":"Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel J. . Spendelow (2009). Modeling Individual Animal Histories Multistate Capture–Recapture Models. Advances Ecological Research, 41:87-173.","code":""},{"path":"covariates.html","id":"covariates","chapter":"6 Covariates","heading":"6 Covariates","text":"","code":""},{"path":"uncertainty.html","id":"uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7 Uncertainty in state assignment","text":"Multievent models extend multistate models uncertainty state assignmentIn module, ’re going talk multievent models.module, ’re going talk multievent models.Multievent models extend multistate models uncertainty state assignment.Multievent models extend multistate models uncertainty state assignment.Let’s see examples fix ideas.Let’s see examples fix ideas.examples published papers used multievent models.examples published papers used multievent models.Breeding status female roe deer ascertained based fawn detectionBreeding status female roe deer ascertained based fawn detectionSex status ascertained based morphological criteria Audouin’s gullsSex status ascertained based morphological criteria Audouin’s gullsDisease status house finches ascertained based birds’ eyes examinationDisease status house finches ascertained based birds’ eyes examinationHybrid status wolves ascertained based geneticsHybrid status wolves ascertained based geneticsDominance status wolves ascertained based heterogeneity detectionDominance status wolves ascertained based heterogeneity detectionWe need explicitly consider state assignment modelThe common thing examples .need explicitly consider state assignment model.HMMs rescue!, ’ll use HMMs !","code":""},{"path":"uncertainty.html","id":"examples","chapter":"7 Uncertainty in state assignment","heading":"7.1 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionIn module, ’ll go 3 examples.module, ’ll go 3 examples.Testing life-history trade-offs accounting uncertainty breeding status.Testing life-history trade-offs accounting uncertainty breeding status.Quantifying disease dynamics accounting uncertainty disease status.Quantifying disease dynamics accounting uncertainty disease status.Estimating survival accounting individual heterogeneity detection.Estimating survival accounting individual heterogeneity detection.","code":""},{"path":"uncertainty.html","id":"examples-1","chapter":"7 Uncertainty in state assignment","heading":"7.2 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detection","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"uncertainty.html","id":"sooty-shearwater-david-boyle-1","chapter":"7 Uncertainty in state assignment","heading":"7.2.1 Sooty shearwater (David Boyle)","text":"","code":""},{"path":"uncertainty.html","id":"uncertainty-in-breeding-status","chapter":"7 Uncertainty in state assignment","heading":"7.3 Uncertainty in breeding status","text":"3 states\nbreeding (B)\nnon-breeding (NB)\ndead (D)\nbreeding (B)non-breeding (NB)dead (D)4 observations\nencountered (0)\nfound, ascertained breeder (1)\nfound, ascertained non-breeder (2)\nfound, status unknown (3)\nencountered (0)found, ascertained breeder (1)found, ascertained non-breeder (2)found, status unknown (3)still 3 states, breeding, non-breeding dead.regard observations, bird may encountered.may also encountered, contrast multistate CR data, don’t know state sure.may found ascertained classified breeder.may found ascertained classified non-breeder.may found unable determine whether ’s breeding non-breeding.","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations","chapter":"7 Uncertainty in state assignment","heading":"7.3.1 How states generate observations","text":"Now states generate observations?","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.2 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.3 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.4 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-4","chapter":"7 Uncertainty in state assignment","heading":"7.3.5 How states generate observations","text":"wrap live state can generate 3 observations.deterministic link dead state observation non-encountered.Cause ’re dead, detected sure.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7.3.6 HMM model for breeding states with uncertainty","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\pi_B & 1 - \\pi_{B} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\pi_B\\) probability newly encountered individual breeder\\(\\pi_{NB} = 1 - \\pi_B\\) probability newly encountered individual non-breeder\\(\\pi_{NB} = 1 - \\pi_B\\) probability newly encountered individual non-breederOK now let’s specify model.OK now let’s specify model.First thing need, ’s big difference multistate models, need initial state probabilities cause assign states individuals w/ certainty.First thing need, ’s big difference multistate models, need initial state probabilities cause assign states individuals w/ certainty.Let’s define pi_B prob newly encountered individual breeding individual.Let’s define pi_B prob newly encountered individual breeding individual.write prob state first encounter. pi_B, prob NB complementary. prob dead first encounter 0 course.write prob state first encounter. pi_B, prob NB complementary. prob dead first encounter 0 course.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.7 HMM model for breeding states with uncertainty","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\ \n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi_B\\) breeder survival, \\(\\phi_{NB}\\) non-breeders.\\(\\phi_B\\) breeder survival, \\(\\phi_{NB}\\) non-breeders.\\(\\psi_{BNB}\\) probability individual breeding year non-breeder next year.\\(\\psi_{BNB}\\) probability individual breeding year non-breeder next year.\\(\\psi_{NBB}\\) probability non-breeder individual breeder next year.\\(\\psi_{NBB}\\) probability non-breeder individual breeder next year.transition parameters matrix similar one used multistate models.transition parameters matrix similar one used multistate models.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.8 HMM model for breeding states with uncertainty","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n1 - p_B & p_B \\beta_B & 0 & p_B (1-\\beta_B) \\\\ \n1-p_{NB} & 0 & p_{NB} \\beta_{NB} & p_{NB} (1-\\beta_{NB})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\beta_B\\) probability assign individual state B state B.\\(\\beta_B\\) probability assign individual state B state B.\\(\\beta_{NB}\\) probability assign individual state NB state NB.\\(\\beta_{NB}\\) probability assign individual state NB state NB.\\(p_B\\) detection probability breeders, \\(p_{NB}\\) non-breeders.\\(p_B\\) detection probability breeders, \\(p_{NB}\\) non-breeders.main difference multistate multievent models , observation parameters.main difference multistate multievent models , observation parameters.introduce two new parameters.introduce two new parameters.deltaB: prob. correctly assign indiv. state B state BdeltaB: prob. correctly assign indiv. state B state BdeltaNB: prob. correctly assign indiv. state NB state NBdeltaNB: prob. correctly assign indiv. state NB state NBWe put everything matrix, usual. observation matrix.put everything matrix, usual. observation matrix.rows states, breeding, non-breeding dead.rows states, breeding, non-breeding dead.columns, occasion, observation, detected ascertained B,\ndetected ascertained NB, detected state unknown, detected.columns, occasion, observation, detected ascertained B,\ndetected ascertained NB, detected state unknown, detected.example, prob detected assigned state B, given ’re state B product detection prob B delta prob correctly assigning B individual state B.example, prob detected assigned state B, given ’re state B product detection prob B delta prob correctly assigning B individual state B.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.9 HMM model for breeding states with uncertainty","text":"animals captured, \\(p_B = p_{NB} = 1\\) first encounter:\\[\n\\begin{matrix}\n& \\\\\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n 0 & \\beta_B & 0 & (1-\\beta_B)\\\\ \n0 & 0 & \\beta_{NB} & (1-\\beta_{NB})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: Breeding assessment unaffected.first encounter, happens step 1 encounter degenerate individuals captured. Just set p’s 1 encounter matrix.first encounter, happens step 1 encounter degenerate individuals captured. Just set p’s 1 encounter matrix.breeding assessment matrix remains unchanged.breeding assessment matrix remains unchanged.","code":""},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi","chapter":"7 Uncertainty in state assignment","heading":"7.3.10 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # piB prob. of being in initial state breeder\n  # betaNB prob to ascertain the breeding status of an individual encountered as non-breeder\n  # betaB prob to ascertain the breeding status of an individual encountered as breeder\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):  \n  # 1 = non-detected\n  # 2 = seen and ascertained as breeder\n  # 3 = seen and ascertained as non-breeder\n  # 4 = not ascertained\n  # -------------------------------------------------\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.11 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"]","code":"multievent <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n  piB ~ dunif(0, 1)\n  betaNB ~ dunif(0, 1)\n  betaB ~ dunif(0, 1)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.12 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # vector of initial stats probs\n  delta[1] <- piB # prob. of being in initial state B\n  delta[2] <- 1 - piB # prob. of being in initial state NB\n  delta[3] <- 0 # prob. of being in initial state dead\n...  "},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.13 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-4","chapter":"7 Uncertainty in state assignment","heading":"7.3.14 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0                  # Pr(alive B t -> detected NB t)\n  omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t)\n  omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0                  # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t)\n  omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t)\n  omega[3,1] <- 1                  # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0                  # Pr(dead t -> detected N t)\n  omega[3,3] <- 0                  # Pr(dead t -> detected NB t)\n  omega[3,4] <- 0                  # Pr(dead t -> detected U t)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-5","chapter":"7 Uncertainty in state assignment","heading":"7.3.15 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of y(first) given z(first)\n  omega.init[1,1] <- 0          # Pr(alive B t = 1 -> non-detected t = 1)\n  omega.init[1,2] <- betaB      # Pr(alive B t = 1 -> detected B t = 1)\n  omega.init[1,3] <- 0          # Pr(alive B t = 1 -> detected NB t = 1)\n  omega.init[1,4] <- 1 - betaB  # Pr(alive B t = 1 -> detected U t = 1)\n  omega.init[2,1] <- 0          # Pr(alive NB t = 1 -> non-detected t = 1)\n  omega.init[2,2] <- 0          # Pr(alive NB t = 1 -> detected B t = 1)\n  omega.init[2,3] <- betaNB     # Pr(alive NB t = 1 -> detected NB t = 1)\n  omega.init[2,4] <- 1 - betaNB # Pr(alive NB t = 1 -> detected U t = 1)\n  omega.init[3,1] <- 1          # Pr(dead t = 1 -> non-detected t = 1)\n  omega.init[3,2] <- 0          # Pr(dead t = 1 -> detected N t = 1)\n  omega.init[3,3] <- 0          # Pr(dead t = 1 -> detected NB t = 1)\n  omega.init[3,4] <- 0          # Pr(dead t = 1 -> detected U t = 1)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-6","chapter":"7 Uncertainty in state assignment","heading":"7.3.16 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"\nmultievent <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] ~ dcat(delta[1:3])\n    y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4])\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:4])\n    }\n  }\n})"},{"path":"uncertainty.html","id":"results","chapter":"7 Uncertainty in state assignment","heading":"7.4 Results","text":"Breeders difficult assigned correct state.Non-breeders relatively well classified non-breeders.cost breeding, neither survival, future reproduction.","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaB  0.19 0.01 0.16 0.19  0.21 1.01   332\n## betaNB 0.76 0.05 0.66 0.76  0.86 1.01    65\n## pB     0.56 0.03 0.51 0.56  0.62 1.06   229\n## pNB    0.60 0.04 0.53 0.60  0.67 1.03   142\n## phiB   0.81 0.02 0.78 0.81  0.85 1.01   312\n## phiNB  0.84 0.02 0.80 0.84  0.87 1.00   354\n## piB    0.71 0.03 0.66 0.71  0.76 1.02   115\n## psiBNB 0.23 0.02 0.18 0.22  0.27 1.00   214\n## psiNBB 0.25 0.04 0.17 0.25  0.34 1.00    95"},{"path":"uncertainty.html","id":"examples-2","chapter":"7 Uncertainty in state assignment","heading":"7.5 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionLet’s look another example.Let’s look another example.similar previous example.similar previous example.","code":""},{"path":"uncertainty.html","id":"animal-epidemiology-with-uncertain-disease-states","chapter":"7 Uncertainty in state assignment","heading":"7.6 Animal epidemiology with uncertain disease states","text":"consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus Müller.","code":"\nknitr::include_graphics(\"images/infectedhousefinch.jpg\")"},{"path":"uncertainty.html","id":"a-house-finch-with-a-heavy-infection-jim-mondok.","chapter":"7 Uncertainty in state assignment","heading":"7.6.1 A house finch with a heavy infection (Jim Mondok).","text":"","code":""},{"path":"uncertainty.html","id":"animal-epidemiology-with-uncertain-disease-states-1","chapter":"7 Uncertainty in state assignment","heading":"7.7 Animal epidemiology with uncertain disease states","text":"consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus Müller.consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus Müller.Faustino et al. (2004) Conn & Cooch (2009) studied impact pathogen host demographic rates.Faustino et al. (2004) Conn & Cooch (2009) studied impact pathogen host demographic rates.Problem true disease state encountered individuals ambiguous seen distance.Problem true disease state encountered individuals ambiguous seen distance.context, study dynamics disease?context, study dynamics disease?","code":""},{"path":"uncertainty.html","id":"states-and-observations","chapter":"7 Uncertainty in state assignment","heading":"7.8 States and observations","text":"3 states\nhealthy (H)\nill ()\ndead (D)\nhealthy (H)ill ()dead (D)4 observations\nseen (0)\ncaptured healthy (1)\ncaptured ill (2)\nhealth status unknown, .e. seen distance (3)\nseen (0)captured healthy (1)captured ill (2)health status unknown, .e. seen distance (3)","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.","chapter":"7 Uncertainty in state assignment","heading":"7.8.1 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.2 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-2","chapter":"7 Uncertainty in state assignment","heading":"7.8.3 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-3","chapter":"7 Uncertainty in state assignment","heading":"7.8.4 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-4","chapter":"7 Uncertainty in state assignment","heading":"7.8.5 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7.8.6 HMM model for disease states with uncertainty","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\pi_H & 1 - \\pi_{H} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\pi_H\\) probability newly encountered individual healthy.\\(\\pi_H\\) probability newly encountered individual healthy.\\(\\pi_{} = 1 - \\pi_H\\) probability newly encountered individual ill.\\(\\pi_{} = 1 - \\pi_H\\) probability newly encountered individual ill.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.7 HMM model for disease states with uncertainty","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\phi_H (1-\\psi_{HI}) & \\phi_H \\psi_{HI} & 1 - \\phi_H\\\\ \n\\phi_{} \\psi_{IH} & \\phi_{} (1-\\psi_{IH}) & 1 - \\phi_{}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi_H\\) survival probability healthy individuals, \\(\\phi_I\\) ill individuals.\\(\\phi_H\\) survival probability healthy individuals, \\(\\phi_I\\) ill individuals.\\(\\psi_{HI}\\) probability getting sick, \\(\\psi_{IH}\\) recovering disease.\\(\\psi_{HI}\\) probability getting sick, \\(\\psi_{IH}\\) recovering disease.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-2","chapter":"7 Uncertainty in state assignment","heading":"7.8.8 HMM model for disease states with uncertainty","text":"Transition matrix, incurable disease\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\phi_H (1-\\psi_{HI}) & \\phi_H \\psi_{HI} & 1 - \\phi_H\\\\ \n0 & \\phi_{}  & 1 - \\phi_{}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]possibility recovering disease, \\(\\psi_{IH} = 0\\). get sick, remain sick \\(\\psi_{II} = 1 - \\psi_{IH} = 1\\).possibility recovering disease, \\(\\psi_{IH} = 0\\). get sick, remain sick \\(\\psi_{II} = 1 - \\psi_{IH} = 1\\).analysing house finch data, allow recovering disease, use transition matrix previous slide.analysing house finch data, allow recovering disease, use transition matrix previous slide.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-3","chapter":"7 Uncertainty in state assignment","heading":"7.8.9 HMM model for disease states with uncertainty","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n1-p_H & p_H \\beta_H & 0 & p_H (1-\\beta_H)\\\\ \n1-p_I & 0 & p_{} \\beta_{} & p_{} (1-\\beta_{})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=H \\\\ z_{t}=\\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\beta_H\\) probability assign healthy individual state H.\\(\\beta_H\\) probability assign healthy individual state H.\\(\\beta_{}\\) probability assign sick individual state .\\(\\beta_{}\\) probability assign sick individual state .\\(p_H\\) detection probability healthy individuals, \\(p_I\\) sick individuals.\\(p_H\\) detection probability healthy individuals, \\(p_I\\) sick individuals.","code":""},{"path":"uncertainty.html","id":"results-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.10 Results","text":"Healthy individuals correctly assigned, infected individuals difficult ascertain.Sounds like infected effect detection survival. Run models without effects compare WAIC formal testing.Infection rate 22%, recovery rate 46%.","code":"##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaH 0.99 0.01 0.97 0.99  1.00 1.01  1421\n## betaI 0.05 0.01 0.03 0.05  0.08 1.00  6477\n## pH    0.17 0.02 0.13 0.17  0.22 1.01   331\n## pI    0.58 0.10 0.41 0.57  0.80 1.04   220\n## phiH  0.88 0.02 0.84 0.88  0.92 1.01   360\n## phiI  0.99 0.01 0.96 0.99  1.00 1.00  1004\n## pi    0.96 0.01 0.93 0.96  0.98 1.00  4190\n## psiHI 0.22 0.04 0.16 0.22  0.32 1.02   311\n## psiIH 0.46 0.08 0.32 0.45  0.63 1.02   392"},{"path":"uncertainty.html","id":"examples-3","chapter":"7 Uncertainty in state assignment","heading":"7.9 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionOur last example individual heterogeneity account HMMs.last example individual heterogeneity account HMMs.","code":""},{"path":"uncertainty.html","id":"individual-heterogeneity-with-finite-mixtures.","chapter":"7 Uncertainty in state assignment","heading":"7.10 Individual heterogeneity with finite mixtures.","text":"Gray wolf social species hierarchy packs may reflect species demography.Gray wolf social species hierarchy packs may reflect species demography.example, ’ll work gray wolves.example, ’ll work gray wolves.","code":"\nknitr::include_graphics(\"images/wolfdominance.jpg\")"},{"path":"uncertainty.html","id":"individual-heterogeneity-with-finite-mixtures.-1","chapter":"7 Uncertainty in state assignment","heading":"7.11 Individual heterogeneity with finite mixtures.","text":"Gray wolf social species hierarchy packs may reflect demography.Gray wolf social species hierarchy packs may reflect demography.Shirley Pledger series papers developed heterogeneity models individuals assigned two classes class-specific survival/detection probabilities.Shirley Pledger series papers developed heterogeneity models individuals assigned two classes class-specific survival/detection probabilities.Cubaynes et al. (2010) used HMMs account heterogeneity detection process due social status, see also Pradel et al. (2009).Cubaynes et al. (2010) used HMMs account heterogeneity detection process due social status, see also Pradel et al. (2009).Dominant individuals tend use path often others, paths look scats.","code":""},{"path":"uncertainty.html","id":"individual-heterogeneity","chapter":"7 Uncertainty in state assignment","heading":"7.12 Individual heterogeneity","text":"3 states\nalive class 1 (A1)\nalive class 2 (A2)\ndead (D)\nalive class 1 (A1)alive class 2 (A2)dead (D)4 observations\ncaptured (0)\ncaptured (1)\ncaptured (0)captured (1)","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity","chapter":"7 Uncertainty in state assignment","heading":"7.12.1 HMM model for individual heterogeneity","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\pi & 1 - \\pi & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\pi\\) probability alive class 1.\\(\\pi\\) probability alive class 1.\\(1 - \\pi\\) probability class 2.\\(1 - \\pi\\) probability class 2.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-1","chapter":"7 Uncertainty in state assignment","heading":"7.12.2 HMM model for individual heterogeneity","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\phi  & 0 & 1 - \\phi\\\\ \n0 & \\phi & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi\\) survival probability, made heterogeneous.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-2","chapter":"7 Uncertainty in state assignment","heading":"7.12.3 HMM model for individual heterogeneity","text":"Transition matrix, change heterogeneity class\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\phi (1-\\psi_{12}) & \\phi \\psi_{12} & 1 - \\phi\\\\ \n\\phi \\psi_{21} & \\phi (1-\\psi_{21}) & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\psi_{12}\\) probability individual change class heterogeneity, 1 2.\\(\\psi_{12}\\) probability individual change class heterogeneity, 1 2.\\(\\psi_{21}\\) probability individual change class heterogeneity, 2 1.\\(\\psi_{21}\\) probability individual change class heterogeneity, 2 1.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-3","chapter":"7 Uncertainty in state assignment","heading":"7.12.4 HMM model for individual heterogeneity","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1\\\\ \\hdashline\n1 - p_1 & p_1\\\\ \n1 - p_2 & p_2\\\\ \n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=A1 \\\\ z_{t}=A2 \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(p_1\\) detection individuals class 1, \\(p_2\\) individuals class 2.","code":""},{"path":"uncertainty.html","id":"results-2","chapter":"7 Uncertainty in state assignment","heading":"7.13 Results","text":"lowly detectable individuals (class A1 \\(p_1\\)) proportion 62%.lowly detectable individuals (class A1 \\(p_1\\)) proportion 62%.highly () detectable individuals (class A2 \\(p_2\\)) proportion 38%.highly () detectable individuals (class A2 \\(p_2\\)) proportion 38%.Note interpretation classes made posteriori.Note interpretation classes made posteriori.Survival 81%.Survival 81%.","code":"##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1  0.38 0.09 0.23 0.38  0.56 1.04   210\n## p2  0.50 0.12 0.25 0.50  0.73 1.01   229\n## phi 0.81 0.05 0.71 0.81  0.91 1.04   317\n## pi  0.62 0.12 0.36 0.63  0.83 1.02   164"},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-4","chapter":"7 Uncertainty in state assignment","heading":"7.13.1 HMM model for individual heterogeneity","text":"may consider classes, select among models, see Cubaynes et al. (2012).may consider classes, select among models, see Cubaynes et al. (2012).may also go non-parametric approach let data tell many classes need. relatively easy Nimble, see Turek et al. (2021).may also go non-parametric approach let data tell many classes need. relatively easy Nimble, see Turek et al. (2021).individual heterogeneity Gimenez et al. (2018).individual heterogeneity Gimenez et al. (2018).","code":""},{"path":"uncertainty.html","id":"hmms-to-analyse-capture-recapture-data","chapter":"7 Uncertainty in state assignment","heading":"7.14 HMMs to analyse capture-recapture data","text":"data, ask questions, just consider different states.","code":""},{"path":"uncertainty.html","id":"how-to-make-our-models-remember","chapter":"7 Uncertainty in state assignment","heading":"7.14.1 How to make our models remember?","text":"far, dynamics states first-order Makovian.far, dynamics states first-order Makovian.site depends site , sites previously.site depends site , sites previously.relax assumption, go second-order Markovian?relax assumption, go second-order Markovian?Memory models initially proposed Hestbeck et al. (1991) Brownie et al. (1993), formulated HMMs Rouan et al. (2009). See also Cole et al. (2014).Memory models initially proposed Hestbeck et al. (1991) Brownie et al. (1993), formulated HMMs Rouan et al. (2009). See also Cole et al. (2014).","code":""},{"path":"uncertainty.html","id":"remember-hmm-model-for-dispersal-between-2-sites","chapter":"7 Uncertainty in state assignment","heading":"7.14.2 Remember HMM model for dispersal between 2 sites","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=B & z_t=D \\\\ \\hdashline\n\\phi_A (1-\\psi_{AB}) & \\phi_A \\psi_{AB} & 1 - \\phi_A\\\\ \n\\phi_B \\psi_{BA} & \\phi_B (1-\\psi_{BA}) & 1 - \\phi_B\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model","chapter":"7 Uncertainty in state assignment","heading":"7.15 HMM formulation of the memory model","text":"keep track sites previously visited, trick consider states pairs sites occupiedTo keep track sites previously visited, trick consider states pairs sites occupiedStates\nAA alive site \\(t\\) alive site \\(t-1\\)\nAB alive site \\(t\\) alive site B \\(t-1\\)\nBA alive site B \\(t\\) alive site \\(t-1\\)\nBB alive site B \\(t\\) alive site B \\(t-1\\)\nD dead\nStatesAA alive site \\(t\\) alive site \\(t-1\\)AB alive site \\(t\\) alive site B \\(t-1\\)BA alive site B \\(t\\) alive site \\(t-1\\)BB alive site B \\(t\\) alive site B \\(t-1\\)D deadObservations\n0 captured\n1 captured site \n2 captured site B\nObservations0 captured1 captured site A2 captured site B","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-1","chapter":"7 Uncertainty in state assignment","heading":"7.16 HMM formulation of the memory model","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\\\ \\hdashline\n\\pi_{AA} & \\pi_{AB} & \\pi_{BA} & \\pi_{BB} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\pi_{BB} = 1 - (\\pi_{AA} + \\pi_{AB} + \\pi_{BA})\\),\\(\\pi_{ij}\\) site \\(j\\) first captured \\(t\\) site \\(\\) \\(t - 1\\).","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-2","chapter":"7 Uncertainty in state assignment","heading":"7.17 HMM formulation of the memory model","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\ \\hdashline\n\\phi_{AAA} & \\phi_{AAB} & 0 & 0 & 1 - \\phi_{AAA} - \\phi_{AAB}\\\\ \n0 & 0 & \\phi_{ABA} & \\phi_{ABB} & 1 - \\phi_{ABA} - \\phi_{ABB}\\\\ \n\\phi_{BAA} & \\phi_{BAB} & 0 & 0 & 1 - \\phi_{BAA} - \\phi_{BAB}\\\\ \n0 & 0 & \\phi_{BBA} & \\phi_{BBB} & 1 - \\phi_{BBA} - \\phi_{BBB}\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\phi_{ijk}\\) probability site \\(k\\) time \\(t + 1\\) individual\npresent site \\(j\\) \\(t\\) site \\(\\) \\(t - 1\\)","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-3","chapter":"7 Uncertainty in state assignment","heading":"7.18 HMM formulation of the memory model","text":"Transition matrix, alternate parameterization\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\ \\hdashline\n\\phi \\psi_{AAA} & \\phi (1 - \\psi_{AAA}) & 0 & 0 & 1 - \\phi\\\\ \n0 & 0 & \\phi (1 - \\psi_{ABB}) & \\phi \\psi_{ABB} & 1 - \\phi\\\\ \n\\phi \\psi_{BAA} & \\phi (1 - \\psi_{BAA}) & 0 & 0 & 1 - \\phi\\\\ \n0 & 0 & \\phi (1-\\psi_{BBB}) & \\phi \\psi_{BBB} & 1 - \\phi\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\phi\\) probability surviving one occasion next.\\(\\psi_{ijj}\\) probability animal stays site \\(j\\) given site \\(\\) previous occasion.","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-4","chapter":"7 Uncertainty in state assignment","heading":"7.19 HMM formulation of the memory model","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"uncertainty.html","id":"further-reading-4","chapter":"7 Uncertainty in state assignment","heading":"7.20 Further reading","text":"Seminal paper Pradel (2005) Multievent: Extension Multistate Capture–Recapture Models Uncertain States. Biometrics, 61: 442-447.Seminal paper Pradel (2005) Multievent: Extension Multistate Capture–Recapture Models Uncertain States. Biometrics, 61: 442-447.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.See also review Gimenez et al. (2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.See also review Gimenez et al. (2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.","code":""},{"path":"abundance.html","id":"abundance","chapter":"8 Abundance","heading":"8 Abundance","text":"","code":""},{"path":"hsmm.html","id":"hsmm","chapter":"9 Hidden semi-Markov models","heading":"9 Hidden semi-Markov models","text":"","code":""},{"path":"states.html","id":"states","chapter":"10 Hidden states","heading":"10 Hidden states","text":"","code":""},{"path":"speed.html","id":"speed","chapter":"11 Speed up MCMC","heading":"11 Speed up MCMC","text":"","code":""},{"path":"speed.html","id":"our-nimble-workflow-so-far-1","chapter":"11 Speed up MCMC","heading":"11.1 Our nimble workflow so far","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow_sofar.png\")"},{"path":"speed.html","id":"but-nimble-gives-full-access-to-the-mcmc-engine-1","chapter":"11 Speed up MCMC","heading":"11.2 But nimble gives full access to the MCMC engine","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow.png\")"},{"path":"speed.html","id":"steps-to-use-nimble-at-full-capacity","chapter":"11 Speed up MCMC","heading":"11.3 Steps to use NIMBLE at full capacity","text":"Build model. R object.Build MCMC.Compile model MCMC.Run MCMC.Extract samples.nimbleMCMC .","code":""},{"path":"speed.html","id":"back-to-cjs-models-with-dipper-data.","chapter":"11 Speed up MCMC","heading":"11.4 Back to CJS models with Dipper data.","text":"","code":""},{"path":"speed.html","id":"define-model","chapter":"11 Speed up MCMC","heading":"11.4.1 Define model","text":"","code":"\nhmm.phip <- nimbleCode({\n  delta[1] <- 1              # Pr(alive t = 1) = 1\n  delta[2] <- 0              # Pr(dead t = 1) = 0\n    phi ~ dunif(0, 1)     # prior survival\n    gamma[1,1] <- phi        # Pr(alive t -> alive t+1)\n    gamma[1,2] <- 1 - phi    # Pr(alive t -> dead t+1)\n    gamma[2,1] <- 0          # Pr(dead t -> alive t+1)\n    gamma[2,2] <- 1          # Pr(dead t -> dead t+1)\n    p ~ dunif(0, 1)       # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"speed.html","id":"run-and-summarise","chapter":"11 Speed up MCMC","heading":"11.4.2 Run and summarise","text":"","code":"\nmcmc.phip <- nimbleMCMC(code = hmm.phip, \n                         constants = my.constants,\n                         data = my.data,              \n                         inits = initial.values,\n                         monitors = parameters.to.save,\n                         niter = n.iter,\n                         nburnin = n.burnin, \n                         nchains = n.chains)\n## defining model...\n## building model...\n## setting data and initial values...\n## running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n## checking model sizes and dimensions...\n## checking model calculations...\n## model building finished.\n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished.\n## running chain 1...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## running chain 2...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.phip, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.90 0.03 0.83 0.90  0.95    1   253\n## phi 0.56 0.03 0.51 0.56  0.61    1   528"},{"path":"speed.html","id":"detailed-nimble-workflow","chapter":"11 Speed up MCMC","heading":"11.5 Detailed Nimble workflow","text":"","code":""},{"path":"speed.html","id":"build-the-model-r-object","chapter":"11 Speed up MCMC","heading":"11.6 1. Build the model (R object)","text":"","code":"\nhmm.phip <- nimbleModel(code = hmm.phip,\n                        constants = my.constants,\n                        data = my.data,\n                        inits = initial.values())\n## defining model...\n## building model...\n## setting data and initial values...\n## running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n## checking model sizes and dimensions...\n## model building finished."},{"path":"speed.html","id":"build-the-mcmc","chapter":"11 Speed up MCMC","heading":"11.7 2. Build the MCMC","text":"","code":"\nphip.mcmc.configuration <- configureMCMC(hmm.phip)\n## ===== Monitors =====\n## thin = 1: phi, p, z\n## ===== Samplers =====\n## RW sampler (2)\n##   - phi\n##   - p\n## posterior_predictive sampler (39)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)\nphip.mcmc <- buildMCMC(phip.mcmc.configuration)"},{"path":"speed.html","id":"compile-the-model-and-mcmc","chapter":"11 Speed up MCMC","heading":"11.8 3. Compile the model and MCMC","text":"","code":"\nphip.model <- compileNimble(hmm.phip) \n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished.\nc.phip.mcmc <- compileNimble(phip.mcmc, project = phip.model)\n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished."},{"path":"speed.html","id":"run-the-mcmc","chapter":"11 Speed up MCMC","heading":"11.9 4. Run the MCMC","text":"","code":"\nsamples <- runMCMC(c.phip.mcmc, niter = 1000)\n## running chain 1...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# Alternative:\n# c.phip.mcmc$run(1000)\n# samples <- as.matrix(c.phip.mcmc$mvSamples)"},{"path":"speed.html","id":"look-at-results","chapter":"11 Speed up MCMC","heading":"11.10 5. Look at results","text":"","code":"\nsummary(samples[,\"phi\"])\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.380   0.552   0.565   0.572   0.589   0.780\nsummary(samples[,\"p\"])\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.146   0.874   0.885   0.864   0.902   0.946"},{"path":"speed.html","id":"why-is-it-useful","chapter":"11 Speed up MCMC","heading":"11.11 Why is it useful?","text":"","code":""},{"path":"speed.html","id":"use-and-debug-model-in-r","chapter":"11 Speed up MCMC","heading":"11.12 Use and debug model in R","text":"Makes life easier comes debuggingMakes life easier comes debuggingInspect variablesInspect variablesCalculate likelihood","code":"\nhmm.phip$gamma\n##        [,1]   [,2]\n## [1,] 0.3795 0.6205\n## [2,] 0.0000 1.0000\nhmm.phip$calculate()\n## [1] -2383"},{"path":"speed.html","id":"example-of-debugging-a-model-in-r","chapter":"11 Speed up MCMC","heading":"11.13 Example of debugging a model in R","text":"Pretend impossible state given inits, making dead bird alive .","code":"\nphip.model$calculate(\"z\")        # We can see there is a problem in z (states).\n## [1] -Inf\nc(phip.model$calculate(\"z[5,]\"), # Bird 5 is valid.\n  phip.model$calculate(\"z[6,]\")) # Bird 6 isn't.\n## [1] -3.327   -Inf\nphip.model$z[6,]                 # We have found the problem\n## [1] 1 1 2 1 2 2 2"},{"path":"speed.html","id":"open-the-hood-and-changemodifywrite-samplers","chapter":"11 Speed up MCMC","heading":"11.14 Open the hood, and change/modify/write samplers","text":"Slice samplers instead Metropolis-Hastings.Slice samplers instead Metropolis-Hastings.Samplers log scale, especially variance, standard deviation, precision parameter.Samplers log scale, especially variance, standard deviation, precision parameter.Blocking correlated parameters.Blocking correlated parameters.know samplers available Nimble, type help(samplers).know samplers available Nimble, type help(samplers).Source code samplers distributions R can copied modified.Source code samplers distributions R can copied modified.Use compareMCMCs package compare options (including Stan Jags!).Use compareMCMCs package compare options (including Stan Jags!).","code":""},{"path":"speed.html","id":"consider-a-model-with-wing-length-and-individual-random-effect-on-survival.","chapter":"11 Speed up MCMC","heading":"11.15 Consider a model with wing length and individual random effect on survival.","text":"","code":"\nhmm.phiwlrep <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i] #<<\n    eps[i] ~ dnorm(mean = 0, sd = sdeps) #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  sdeps ~ dunif(0, 10)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"speed.html","id":"trace-plot-for-standard-deviation-of-the-random-effect-default-sampler","chapter":"11 Speed up MCMC","heading":"11.16 Trace plot for standard deviation of the random effect (default sampler)","text":"","code":""},{"path":"speed.html","id":"change-samplers","chapter":"11 Speed up MCMC","heading":"11.17 Change samplers","text":"Good sampling strategies depend model data. samplers used default?","code":"\nmcmcConf <- configureMCMC(hmm.phiwlrep.m)\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## RW sampler (259)\n##   - p\n##   - beta[]  (2 elements)\n##   - sdeps\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)"},{"path":"speed.html","id":"remove-default-sampler-and-use-slice-sampler","chapter":"11 Speed up MCMC","heading":"11.18 Remove default sampler, and use slice sampler","text":"","code":"\nmcmcConf$removeSamplers('sdeps')\nmcmcConf$addSampler(target = 'sdeps',\n                    type = \"slice\") #<<\nmcmcConf\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## slice sampler (1)\n##   - sdeps\n## RW sampler (258)\n##   - p\n##   - beta[]  (2 elements)\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|"},{"path":"speed.html","id":"trace-plot-for-standard-deviation-of-the-random-effect-slice-sampler","chapter":"11 Speed up MCMC","heading":"11.19 Trace plot for standard deviation of the random effect (slice sampler)","text":"","code":""},{"path":"speed.html","id":"which-is-better","chapter":"11 Speed up MCMC","heading":"11.20 Which is better?","text":"MCMC efficiency depends mixing computation time.MCMC efficiency depends mixing computation time.MCMC efficiency = Effective Sample Size (ESS) / computation time.MCMC efficiency = Effective Sample Size (ESS) / computation time.MCMC efficiency number effectively independent posterior samples generated per second.MCMC efficiency number effectively independent posterior samples generated per second.ESS different parameter. (Computation time parameter.)ESS different parameter. (Computation time parameter.)ESS can estimated packages coda mcmcse. give statistical estimates, different runs give different estimates.ESS can estimated packages coda mcmcse. give statistical estimates, different runs give different estimates.Efficiency default sampler = 25.7 / 21.53 = 1.19.Efficiency default sampler = 25.7 / 21.53 = 1.19.Efficiency slice sampler = 19.14 / 23.3 = 0.82.Efficiency slice sampler = 19.14 / 23.3 = 0.82.","code":""},{"path":"speed.html","id":"block-sampling","chapter":"11 Speed up MCMC","heading":"11.21 Block sampling","text":"High correlation (regression) parameters may make independent samplers inefficient.Block sampling (propose candidate values multivariate distribution) might help.","code":""},{"path":"speed.html","id":"block-sampling-1","chapter":"11 Speed up MCMC","heading":"11.22 Block sampling","text":"Remove replace independent RW samples block sampling. proceed usual.","code":"\nmcmcConf$removeSamplers(c('beta[1]','beta[2]'))\nmcmcConf$addSampler(target = c('beta[1]','beta[2]'),\n                    type = \"RW_block\") #<<"},{"path":"speed.html","id":"block-sampling-2","chapter":"11 Speed up MCMC","heading":"11.23 Block sampling","text":"","code":"\nmcmcConf\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## slice sampler (1)\n##   - sdeps\n## RW_block sampler (1)\n##   - beta[1], beta[2] \n## RW sampler (256)\n##   - p\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)"},{"path":"speed.html","id":"summary-of-strategies-for-improving-mcmc","chapter":"11 Speed up MCMC","heading":"11.24 Summary of strategies for improving MCMC","text":"Choose better initial values.Choose better initial values.Customize sampler choice (Chapter 7 User’s manual).Customize sampler choice (Chapter 7 User’s manual).Reparameterize, e.g. standardize covariates, deal parameter redundancy.Reparameterize, e.g. standardize covariates, deal parameter redundancy.Rewrite model.\nVectorize improve computational efficiency (covered).\nAvoid long chains deterministic dependencies.\nMarginalize remove parameters\nUse new functions new distributions written nimbleFunctions.\nRewrite model.Vectorize improve computational efficiency (covered).Avoid long chains deterministic dependencies.Marginalize remove parametersUse new functions new distributions written nimbleFunctions.Write new samplers take advantage particular model structures (covered).Write new samplers take advantage particular model structures (covered).Using multiple cores parallelization: see -https://r-nimble.org/nimbleExamples/parallelizing_NIMBLE.htmlUsing multiple cores parallelization: see -https://r-nimble.org/nimbleExamples/parallelizing_NIMBLE.html","code":""},{"path":"speed.html","id":"marginalization","chapter":"11 Speed up MCMC","heading":"11.25 Marginalization","text":"User-defined distributions another neat feature Nimble.User-defined distributions another neat feature Nimble.Integrate latent states focus ecological inference (marginalization).Integrate latent states focus ecological inference (marginalization).Marginalization often (always) improves MCMC. See Ponisio et al. 2020 examples.Marginalization often (always) improves MCMC. See Ponisio et al. 2020 examples.nimbleEcology package implements capture-recapture models HMMs marginalization.nimbleEcology package implements capture-recapture models HMMs marginalization.","code":""},{"path":"speed.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-6","chapter":"11 Speed up MCMC","heading":"11.25.1 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"\nmultisite <- nimbleCode({\n...\n  # Likelihood \n  for (i in 1:N){\n    # Define latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # State process: draw S(t) given S(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # Observation process: draw O(t) given S(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})"},{"path":"speed.html","id":"same-model-with-nimbleecology","chapter":"11 Speed up MCMC","heading":"11.25.2 Same model with nimbleEcology","text":"runs twice fast standard formulation explicit latent states.runs twice fast standard formulation explicit latent states.Marginalizing typically gives better mixing.Marginalizing typically gives better mixing.","code":"multisite <- nimbleCode({\n...\n# initial state probs\nfor(i in 1:N) {\n  init[i, 1:4] <- gamma[ y[i, first[i] ] - 1, 1:4 ] # first state propagation\n}\n    \n# likelihood \nfor (i in 1:N){\n  y[i,(first[i]+1):K] ~ dHMM(init = init[i,1:4],           # count data from first[i] + 1\n                             probObs = omega[1:4,1:4],     # observation matrix\n                             probTrans = gamma[1:4,1:4],   # transition matrix\n                             len = K - first[i],           # nb of occasions\n                             checkRowSums = 0)             # do not check whether elements in a row sum tp 1\n}\n..."},{"path":"speed.html","id":"reducing-redundant-calculations","chapter":"11 Speed up MCMC","heading":"11.25.3 Reducing redundant calculations","text":"far, row dataset individual. However, several individuals may share encounter history.far, row dataset individual. However, several individuals may share encounter history.contribution \\(M\\) individuals encounter history likelihood particular encounter history raised power \\(M\\).contribution \\(M\\) individuals encounter history likelihood particular encounter history raised power \\(M\\).Using -called weighted likelihood greatly decreases computational burden.Using -called weighted likelihood greatly decreases computational burden.idea used computer programs implement maximum likelihood. Bayesian framework, idea proposed Turek et al. (2016).idea used computer programs implement maximum likelihood. Bayesian framework, idea proposed Turek et al. (2016).done Jags. Can done nimble thanks nimble functions!done Jags. Can done nimble thanks nimble functions!run much faster. Also allows fitting models big datasets. details dedicated Worksheet.run much faster. Also allows fitting models big datasets. details dedicated Worksheet.","code":""},{"path":"speed.html","id":"no-live-demo-but-there-is-a-worksheet.","chapter":"11 Speed up MCMC","heading":"11.26 No live demo, but there is a worksheet.","text":"","code":""},{"path":"speed.html","id":"future-directions-for-nimble","chapter":"11 Speed up MCMC","heading":"11.27 Future directions for NIMBLE","text":"NIMBLE active development. Contributors welcome, including want get involved don’t know .NIMBLE active development. Contributors welcome, including want get involved don’t know .Faster building models algorithms. Ability save re-load compiled work.Faster building models algorithms. Ability save re-load compiled work.Automatic differentiation model calculations, enabling Hamiltonian Monte Carlo, sampling strategies, Laplace approximation.Automatic differentiation model calculations, enabling Hamiltonian Monte Carlo, sampling strategies, Laplace approximation.Tools building packages use NIMBLE “hood.”Tools building packages use NIMBLE “hood.”","code":""},{"path":"speed.html","id":"further-reading-5","chapter":"11 Speed up MCMC","heading":"11.28 Further reading","text":"Turek, D., de Valpine, P. & Paciorek, C.J. Efficient Markov chain Monte Carlo sampling hierarchical hidden Markov models Environ Ecol Stat 23: 549–564 (2016).Turek, D., de Valpine, P. & Paciorek, C.J. Efficient Markov chain Monte Carlo sampling hierarchical hidden Markov models Environ Ecol Stat 23: 549–564 (2016).Ponisio, L.C., de Valpine, P., Michaud, N., Turek, D. One size fit : Customizing MCMC methods hierarchical models using NIMBLE Ecol Evol. 10: 2385–2416 (2020).Ponisio, L.C., de Valpine, P., Michaud, N., Turek, D. One size fit : Customizing MCMC methods hierarchical models using NIMBLE Ecol Evol. 10: 2385–2416 (2020).Nimble workshop come 26-28 May, check .Nimble workshop come 26-28 May, check .Nimble workshop material online available .Nimble workshop material online available .Nimble manual cheatsheet.Nimble manual cheatsheet.","code":""},{"path":"conclusions.html","id":"conclusions","chapter":"12 Conclusions","heading":"12 Conclusions","text":"","code":""},{"path":"conclusions.html","id":"take-home-messages-and-recommendations","chapter":"12 Conclusions","heading":"12.1 Take-home messages and recommendations","text":"’ll wrap workshop take-home messagesAnd recommendations conducting analyses.","code":""},{"path":"conclusions.html","id":"make-the-best-of-your-data-with-hmms","chapter":"12 Conclusions","heading":"12.2 Make the best of your data with HMMs","text":"searchable list HMM analyses capture-recapture data.searchable list HMM analyses capture-recapture data.hope provided useful overview use hidden Markov models analyze capture-recapture data.hope provided useful overview use hidden Markov models analyze capture-recapture data.scratched surface can models.scratched surface can models.assembled searchable list HMM analyses capture-recapture data get inspiration.assembled searchable list HMM analyses capture-recapture data get inspiration.list exhaustive, please get touch us ’d like add reference.list exhaustive, please get touch us ’d like add reference.exhaustive, ’ll continue updating . Feel free suggest papers add list.exhaustive, ’ll continue updating . Feel free suggest papers add list.","code":""},{"path":"conclusions.html","id":"bayesian-capture-recapture-analysis-with-hmms","chapter":"12 Conclusions","heading":"12.3 Bayesian capture-recapture analysis with HMMs","text":"leave, ’d like give pieces advice.leave, ’d like give pieces advice.rocket science.rocket science.Just things based experience Bayesian capture-recapture analysis HMMS.Just things based experience Bayesian capture-recapture analysis HMMS.Make ecological question explicit.Make ecological question explicit.First things first. Make sure ’ve spent time make ecological question explicit.First things first. Make sure ’ve spent time make ecological question explicit.step help stay course, make right choices.step help stay course, make right choices.example, ’s ok use subsets data address different questions.example, ’s ok use subsets data address different questions.Think observations states first.Think observations states first.Now terms modeling. Don’t jump keyboard right away.Now terms modeling. Don’t jump keyboard right away.Spend time thinking model pen paper.Spend time thinking model pen paper.particular make sure observations states HMM.particular make sure observations states HMM.write observation transition matrices paper.write observation transition matrices paper.write transition matrix. may act imperfect detection. really ’re , ecological process (survival, dispersal, etc).write transition matrix. may act imperfect detection. really ’re , ecological process (survival, dispersal, etc).Proceed observation matrix.Proceed observation matrix.Start simple, parameters constant example. Make sure convergence reached.Start simple, parameters constant example. Make sure convergence reached.comes model fitting Nimble, start simple.comes model fitting Nimble, start simple.Consider parameters constant.Consider parameters constant.Make sure convergence reached.Make sure convergence reached.Add complexity one step time.Add complexity one step time.add complexity. Time effect example. random effects.add complexity. Time effect example. random effects.uncertainty assignment states.uncertainty assignment states.","code":""},{"path":"conclusions.html","id":"bayesian-capture-recapture-analysis-with-hmms-1","chapter":"12 Conclusions","heading":"12.4 Bayesian capture-recapture analysis with HMMs","text":"Use simulations better understand model.Use simulations better understand model.Nimble models can used simulate data, check tutorial.Nimble models can used simulate data, check tutorial.comes model building, consider simulating data better understand model.comes model building, consider simulating data better understand model.always learn something model seeing engine generate data, instead estimating parameters.always learn something model seeing engine generate data, instead estimating parameters.cool thing nimble can models simulate data. tutorial .cool thing nimble can models simulate data. tutorial .try optimize code. Make work first, think optimization.try optimize code. Make work first, think optimization.“Premature optimization root evil” - Donald Knuth (creator TeX author “Art Computer Programming”)Another advice, quite general programming, try optimize codeAnother advice, quite general programming, try optimize codeOr try make elegant right away. Make work first.try make elegant right away. Make work first.think optimization.think optimization.Read Bayesian workflow Gelman et al. (2021).Read Bayesian workflow Gelman et al. (2021).recommendations Bayesian analyses recent paper Gelman collaborations.recommendations Bayesian analyses recent paper Gelman collaborations.offer workflow bayesian analyses.offer workflow bayesian analyses.discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.","code":""},{"path":"conclusions.html","id":"till-next-time","chapter":"12 Conclusions","heading":"12.5 Till next time","text":"Slack space remain time. Happy answer questions might related workshop.Slack space remain time. Happy answer questions might related workshop.Slack space remain time.Slack space remain time.’ll happy answer questions might related workshop.’ll happy answer questions might related workshop.Website updated \nvideo recordings\nfeedbacks\nFAQ section based questions\nWebsite updated withvideo recordingsyour feedbacksa FAQ section based questionsWe update workshop website coming weeks.update workshop website coming weeks.video recordings course.video recordings course.feedback might . Please get touch , great.feedback might . Please get touch , great.plan also gather exchanges Frequently Asked Questions section website.plan also gather exchanges Frequently Asked Questions section website.book way. 2022 hopefully.book way. 2022 hopefully.last, book way. Based material used workshop stuff.last, book way. Based material used workshop stuff.Also half book case studies reproducing analysis published papers.Also half book case studies reproducing analysis published papers.2022 hopefully.2022 hopefully.","code":""},{"path":"conclusions.html","id":"lets-see-if-i-can-put-to-use-my-own-pieces-of-advice---case-studies","chapter":"12 Conclusions","heading":"12.6 Let’s see if I can put to use my own pieces of advice - case studies","text":"","code":""},{"path":"senescence.html","id":"senescence","chapter":"13 Actuarial senescence","heading":"13 Actuarial senescence","text":"Choquet et al. (2011), Péron et al. (2016)","code":""},{"path":"heterogeneity.html","id":"heterogeneity","chapter":"14 Individual heterogeneity","heading":"14 Individual heterogeneity","text":"Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)","code":""},{"path":"tradeoffs.html","id":"tradeoffs","chapter":"15 Life-history tradeoffs","heading":"15 Life-history tradeoffs","text":"Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)","code":""},{"path":"breeding.html","id":"breeding","chapter":"16 Breeding dynamics","heading":"16 Breeding dynamics","text":"Pradel, Choquet, Béchet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)","code":""},{"path":"rd.html","id":"rd","chapter":"17 Robust design","heading":"17 Robust design","text":"Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)","code":""},{"path":"stopover.html","id":"stopover","chapter":"18 Stopover duration","heading":"18 Stopover duration","text":"Guérin et al. (2017)","code":""},{"path":"disease.html","id":"disease","chapter":"19 Disease dynamics","heading":"19 Disease dynamics","text":"Marescot et al. (2018) Santoro et al. (2014)","code":""},{"path":"sex.html","id":"sex","chapter":"20 Sex uncertainty","heading":"20 Sex uncertainty","text":"Pradel et al. (2008) Genovart, Pradel, Oro (2012)","code":""},{"path":"dependence.html","id":"dependence","chapter":"21 Dependence among individuals","heading":"21 Dependence among individuals","text":"Culina et al. (2013) Cubaynes et al. (2021)","code":""},{"path":"covariateselection.html","id":"covariateselection","chapter":"22 Individual and temporal variability","heading":"22 Individual and temporal variability","text":"Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), Bonner, Morgan, King (2010)","code":""},{"path":"mortalities.html","id":"mortalities","chapter":"23 Cause-specific mortalities","heading":"23 Cause-specific mortalities","text":"Fernández-Chacón et al. (2016) Ruette et al. (2015)","code":""},{"path":"prevalence.html","id":"prevalence","chapter":"24 Prevalence","heading":"24 Prevalence","text":"(Santostasi et al. 2019)","code":""},{"path":"faq.html","id":"faq","chapter":"FAQ","heading":"FAQ","text":"complete list frequently asked questions (FAQ). Yes, one question . Personally like FAQs. often mean surprises, surprises good software users.Q: bookdown features X, Y, Z?\n: short answer , asked three times “really need ” answer still “yes,” please feel free file feature request https://github.com/rstudio/bookdown/issues.\nUsers asking features often come LaTeX world. case , answer question yes, Pandoc’s Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.Q: bookdown features X, Y, Z?: short answer , asked three times “really need ” answer still “yes,” please feel free file feature request https://github.com/rstudio/bookdown/issues.Users asking features often come LaTeX world. case , answer question yes, Pandoc’s Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.challenging thing world learn fancy technologies, control wild heart.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
