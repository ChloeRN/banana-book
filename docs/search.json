[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models – Theory Case Studies R. ’m currently writing book, welcome feedback via email.\nMany thanks!Olivier Gimenez, Montpellier, FranceLast updated: September 15, 2021","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology. parallel, Bayesian statistics relatively well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book propose full Bayesian treatment HMMs applied capture-recapture data. use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data.cover theory HMMs capture-recapture data, applications models empower practitioners fit models confidence. important part book consists case studies presented tutorial style abide “learning ” philosophy.\nonline version book licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. ","code":""},{"path":"preface.html","id":"software-information","chapter":"Preface","heading":"Software information","text":"book uses primarily R package NIMBLE, need least install R NIMBLE package.R session information compiling book shown :","code":"## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Catalina 10.15.7\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/C/fr_FR.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## other attached packages:\n##  [1] wesanderson_0.3.6 pdftools_3.0.1   \n##  [3] magick_2.7.3      MCMCvis_0.15.3   \n##  [5] nimble_0.11.1     forcats_0.5.1    \n##  [7] stringr_1.4.0     dplyr_1.0.7      \n##  [9] purrr_0.3.4.9000  readr_2.0.0      \n## [11] tidyr_1.1.3       tibble_3.1.3     \n## [13] ggplot2_3.3.5     tidyverse_1.3.1"},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the Author","heading":"About the Author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France. struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email.","code":""},{"path":"crashcourse.html","id":"crashcourse","chapter":"1 Bayesian statistics & MCMC","heading":"1 Bayesian statistics & MCMC","text":"","code":""},{"path":"crashcourse.html","id":"introduction","chapter":"1 Bayesian statistics & MCMC","heading":"1.1 Introduction","text":"first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book.","code":""},{"path":"crashcourse.html","id":"bayes-theorem","chapter":"1 Bayesian statistics & MCMC","heading":"1.2 Bayes’ theorem","text":"Let’s wait longer jump . Bayesian statistics relies Bayes’ theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes’ death thanks friend’s efforts Richard Price, independently rediscovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes’ theorem background. Source: James Kulich\nsee minute, Bayes’ theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B definitely occurred.1 order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes’ theorem (Figure 1.2) gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]\nOriginally, Bayes theorem seen mean infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unkown disease B symptoms, doctor knows P(symptoms|disease) wants derive P(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‘inverse probability.’\nFigure 1.2: Bayes’ theorem spelt blue neon offices Autonomy Cambridge. Source: Wikipedia\ndon’t know , need think twice messing letters around. find easier remember Bayes’ theorem written like this2:\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]\nhypothesis working assumption want learn using data. capture-recapture analyses, hypothesis might parameter like detection probability, regression parameters relationship survival probability covariate. Bayes’ theorem tells us obtain probability hypothesis given data . great think , exactly scientific method ! ’d like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains feel like Bayesian framework intuitive understanding statistics.might ask , Bayesian statistics default statistics? Clearly, futile wars male statisticians (including Ronald Fisher, Jerzy Neyman Egon Sharpe Pearson among others), little progress made two centuries. Also, recently, practical problems implement Bayesian approach. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades.","code":""},{"path":"crashcourse.html","id":"what-is-the-bayesian-approach","chapter":"1 Bayesian statistics & MCMC","heading":"1.3 What is the Bayesian approach?","text":"Typical statistical problems involve estimating parameter(s) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed fixed unknown distribution3 – distribution parameter.Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work lab work. updating process based upon Bayes’ theorem ’ve seen earlier. Loosely, let’s say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes’ theorem gives way estimate parameter \\(\\theta\\) given data . Bayes’ theorem becomes:\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet’s spend time going quantity formula.left-hand side \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ’re , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don’t know anything \\(\\theta\\). Usually however, never start scratch, ’d like prior informed information . ’ll get back length later .Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood. likelihood averaged prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates sums one posterior distribution. average likelihood \\(N\\)-dimensional integral \\(N\\) parameters estimate \\(\\theta = \\theta_1, \\ldots, \\theta_N\\). quantity difficult, impossible, calculate. one reasons Bayesian method wasn’t used recently, need algorithms estimate posterior distributions illustrate next section.","code":""},{"path":"crashcourse.html","id":"numerical-approx","chapter":"1 Bayesian statistics & MCMC","heading":"1.4 Approximating posterior distributions via numerical integration","text":"Let’s take example. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive4. ’d like estimate winter survival \\(\\theta\\).build model first. Assuming animals independent survival probability, number alive animals end winter binomial distribution5:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]Bayesian approach, priors part model. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes’ theorem. write R function computes product likelihood times prior, numerator formula Bayes’ theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\Pr(\\theta) d\\theta}\\)get posterior via numerical integration Figure 1.3.\nFigure 1.3: Numerical approximation winter survival posterior distribution.\n\nFigure 1.4: beta distribution various parameters.\n\nFigure 1.5: Comparison exact (dashed line) vs. numerical approximation (continuous line) winter survival posterior distribution.\nposterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean median posterior distribution. can simply calculated R:posterior distribution rather symetric, mean median similar necessarily case. may also check mean calculate empirically matches expectation beta distribution7:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. can obtained R :example, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature scheme R function integrate(). Now multiple parameters? example, let’s imagine ’d like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes’ theorem gives posterior distribution three parameters together:\\[ P(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\alpha, \\beta, p) \\times P(\\alpha, \\beta, p)}{\\iiint \\, P(\\text{data} \\mid \\alpha, \\beta, p) P(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ’re interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters – two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue.","code":"\ny <- 19 # nb of success\nn <- 57 # nb of attempts\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # a grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) \nnumerical_posterior %>%\n  ggplot() + \n  geom_line(aes(x = survival, y = posterior), \n            size = 1.5)\nsample_from_posterior <- rbeta(n = 1000, 1 + 19, 1 + 57 - 19) # draw 1000 values from posterior distribution of survival beta(20,39)\nmean(sample_from_posterior) # compute mean\n## [1] 0.3398\nmedian(sample_from_posterior) # compute median\n## [1] 0.3377\nmean(sample_from_posterior) # compute mean\n## [1] 0.3398\n20/(20+39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2242 0.4636"},{"path":"crashcourse.html","id":"bayesian-computation-with-markov-chain-monte-carlo-mcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5 Bayesian computation with Markov chain Monte Carlo (MCMC)","text":"early 1990s, statisticians rediscovered work 1950’s physics. famous paper lay fundations modern Bayesian statistics (see Figure 1.6), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes’ theorem. simulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo. Let’s try make sense terms.\nFigure 1.6: MCMC article cover. Source: Journal Chemical Physics\nNow Monte Carlo stand ? actually already met method Section 1.4 calculated numerical summaries survival posterior distribution. Monte Carlo integration simulation technique estimate integrals involving function parameter \\(\\theta\\), draw samples posterior distribution, calculate sample mean values applied function. prendre la SD comme exemple?Now Markov chain? Markov chain random sequence numbers, number depends previous number. example Markov chain weather home town Southern France, sunny day likely followed another sunny day. certain conditions8, Markov chain converge unique stationary distribution. cool thing can build Markov chains given stationary distribution set desired posterior distribution. donner un exemple de Markov chain et stationary distributionMCMC therefore allows us construct sequence values whose distribution\nconverges posterior distribution interest (chain run\nlong enough). chain converged stationary distribution,\ncan use sequence values taken chain order obtain\nempirical (Monte Carlo) estimates posterior summaries interest, \nposterior means. Note need ensure Markov chain \nreached stationary distribution can use realisations obtain\nMonte Carlo estimates posterior distributions interest. \nmeans need discard realisations start chain \nuse observations chain converged. initial period \nchain referred burn-. return issue determining \nlength burn-Section 5.4.2, described general\nMCMC methods. emphasise beauty MCMC updating\nprocedure remains relatively simple, matter complex posterior\ndistribution interest. Thus can required integration sampling\nposterior distribution, can sample posterior generating\nMarkov chain. construct Markov chain using appropriate\nupdating scheme, updates? several standard\napproaches.summarizes core spirit MCMC algorithms.several ways constructing chains: e.g., Metropolis-Hastings, Gibbs sampler. look https://github.com/chi-feng/mcmc-demo interactive gallery MCMC algorithms. illustrate Metropolis algorithm implement practice. Différence entre Metropolis et MHLet’s go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows: pour chaque étape, donner l’intuitionWe start possible value parameter estimated.start possible value parameter estimated.decide visit next, propose move away current value parameter – candidate value. , add current value random value (say) normal distribution variance.decide visit next, propose move away current value parameter – candidate value. , add current value random value (say) normal distribution variance.compute ratio probabilities candidate current locations \\(R = \\text{posterior(candidate)/posterior(current)}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, cancels need calculated.compute ratio probabilities candidate current locations \\(R = \\text{posterior(candidate)/posterior(current)}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, cancels need calculated.spin continuous spinner lands anywhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location.spin continuous spinner lands anywhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location.repeat 2-4 number times – steps (many steps).repeat 2-4 number times – steps (many steps).Enough theory, let’s implement Metropolis algorithm R. Let’s start setting scene.Now follow 5 steps ’ve just described. First, pick starting value, store (step 1).go next steps, ’ll need function propose candidate value. expliquer le away, s’en sert plus bas pour autocorrelation, called SDNow ’re ready steps 2, 3 4. Actually, write look take care step 5 well. Remember start initial value 0.5 run algorithm \\(100\\) iterations.get following values.\nFigure 1.7: Visualisation Markov chain, often called traceplot. Starting value 0.5.\n\nFigure 1.8: Visualisation two Markov chains starting values 0.2 (yellow) 0.5 (blue).\n\nFigure 1.9: Visualisation Markov chains 5000 iterations.\nalso add two straight lines, one yellow mean posterior distribution dire comment c’est calculé, red maximum likelihood estimate c’est quoi ici?. expliquer pourquoi, et noter que ça donne la même chose.find informative look animated version Figure 1.9, helps understanding iterative behavior algorithm, also realise chains converge stationary distribution, see Figure 1.10.\nFigure 1.10: Sampling values survival posterior distribution MCMC algorithm. Top panel: traceplot. Bottom panel: histogram.\nIntroduire l’idée de grass, note de bas de page vers Steve Brooks comm pers, et transition vers next section avec l’idée de comment regarde la convergence discard realisations Markov chain convergence achieved. stationary distribution reached use stationary target limiting, can regard realisations chain (dependent) sample posterior distribution, obtain Monte Carlo estimates parameters. next section, consider several important implementation issues. coder Metropolis d’au-dessus dans Nimble","code":"\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\nmove <- function(x, away = .2){ \n  logitx <- log(x / (1 - x))\n  logit_candidate <- logitx + rnorm(1, 0, away)\n  candidate <- plogis(logit_candidate)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for prob of success (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  accept <- rbinom(1, 1, prob = min(R, 1))\n  theta.post[t] <- ifelse(accept == 1, theta_star, theta.post[t-1])\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.4399 0.4399 0.4577 0.4577 0.4577\ntail(theta.post) # last values\n## [1] 0.4146 0.3772 0.3772 0.3861 0.3899 0.3624"},{"path":"crashcourse.html","id":"assessing-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6 Assessing convergence","text":"implementing MCMC, need determine long takes Markov chain converge target distribution, number iterations need achieving convergence get reasonable Monte Carlo estimates model parameters (numerical summaries). expliquer numerical summaries quelque part","code":""},{"path":"crashcourse.html","id":"burn-in","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.1 Burn-in","text":"practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.11 need least 500 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 750 even 1000 iterations burn-. préciser qu’il faut faire qqs runs préliminaires pour déterminer le burn-; ajouter des cas pathologiques ou faire des renvois aux sections suiantes, en particuier les minimal locaux ou par redundancy?\nFigure 1.11: Determining length burn-period.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check replicates achieve target distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values \\(1.2\\) indicate likely convergence. check 1.1 1.2Back example, run two replicates Markov chain starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.12, get value BGR statistic near 1 2500 iterations, suggests 2500 iterations burn-, evidence lack convergence.\nFigure 1.12: Brooks-Gelman-Rubin statistic.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .","code":""},{"path":"crashcourse.html","id":"chain-length","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.2 Chain length","text":"long chain needed produce stable parameter estimates? answer question, need keep mind successive steps Markov chain near , independent – usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let’s get back survival example. Figure (fig:tracechainlength) shows trace plots samples survival posterior distribution. Small big moves provide relatively high correlations successive observations Markov chain, whereas standard deviation 0.2 allows efficient exploration parameter space. movement around parameter space often referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.13: Trace plots different tuning acceptance rate. Left: SD 0.02, chain exhibits small moves mixing bad. Right: SD 2, chain exhibits big moves mixing bad. Middle: SD 0.2, chain exhibits adequate moves mixing good.\nBesides trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated \\(k\\) iterations, referred lag, (.e. \\(\\text{cor}(\\theta_t, \\theta_{t+k})\\)) increasing values \\(k\\). Figure (fig:acfchainlength)\nFigure 1.14: Autocorrelation function plots different tuning acceptance rate. Left: SD 0.02, autocorrelation strong, decreases slowly increasing lag mixing bad. Right: SD 2, autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: SD 0.2, autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. Obviously, n.eff less number MCMC iterations. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 100\\) independent steps get reasonable Monte Carlo estimates model parameters. calculer neff sur exemple","code":""},{"path":"crashcourse.html","id":"what-if-you-have-issues-of-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.3 What if you have issues of convergence?","text":"effective sample size small, just need increase burn-/sample . Using informative priors might also make Markov chain converge faster helping MCMC algorithm navigating efficiently parameter space. spirit, picking better initial values, good guess, starting chain harm. strategy consists using estimates simpler models.issues persist, problem probably profound, might ask whether something wrong model fork theorem Gelman?. bug code? typo somewhere? msitake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice always start seeing model data generating tool first place, simulate data using realistic values parameters, try recover parameters fitting model simulated data.also see strategies improve convergence chapter XX. Change sampler. Reparameterize (standardize covariates, plus non-centering: \\(\\alpha \\sim N(0,\\sigma)\\) becomes \\(\\alpha = z \\sigma\\) \\(z \\sim N(0,1)\\)).lisser cette partie","code":""},{"path":"crashcourse.html","id":"summary","chapter":"1 Bayesian statistics & MCMC","heading":"1.7 Summary","text":"Bayes’ theorem, may update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): \\(\\text{posterior} \\propto \\text{likelihood} \\times \\text{prior}\\)Bayes’ theorem, may update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): \\(\\text{posterior} \\propto \\text{likelihood} \\times \\text{prior}\\)idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ’re .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ’re .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence replicates reach regime.discard iterations initial burn-phase achieve convergence replicates reach regime., run chain long enough proceed calculating Monte Carlo estimates (numerical summaries) model parameters., run chain long enough proceed calculating Monte Carlo estimates (numerical summaries) model parameters.Takes training; make sense next chapter, also put use case studies!","code":""},{"path":"crashcourse.html","id":"further-reading","chapter":"1 Bayesian statistics & MCMC","heading":"1.8 Further reading","text":"cette partie dans chaque chapitre c’est plutôt les trucs essentiels en lien avec le chapitre il semble non?Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.","code":""}]
