[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models ‚Äì Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide ‚Äúlearning ‚Äù philosophy.‚Äôm currently writing book, welcome feedback üòá raising issue , amending directly R Markdown file generated page ‚Äôre reading clicking ‚ÄòEdit page‚Äô icon right panel, simply via email. Many thanks!Olivier Gimenez, Montpellier, France\nLast updated: September 19, 2021","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-this-book","chapter":"Preface","heading":"Why this book?","text":"capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance endangered species conservation. Bayes? Also three ‚Äì capture-recapture, HMM Bayes statistics ‚Äì fav research ingredients, nice cocktail together, . completed.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"book aimed beginners ‚Äôre comfortable using R write basic code (including loops), well connoisseurs capture-recapture ‚Äôd like tap power Bayesian side statistics. audiences, thinking HMM framework help building models make capture-recapture data.","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided two parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models capture-recapture models open populations. provide reproducible R code ease learning process. second part provides real-world case studies published scientific literature can reproduce using material first part. problems can used deepen understanding methods models coved first part, adapted purpose, serve teaching projects.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won‚Äôt you learn?","text":"hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine.","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:","code":"\ninstall.packages(c(\n  \"magick\", \"MCMCvis\", \"nimble\", \"pdftools\", \n  \"tidyverse\", \"wesanderson\" \n))"},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"completed.","code":""},{"path":"preface.html","id":"how-this-book-was-written","chapter":"Preface","heading":"How this book was written","text":"writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ‚Äôre reading built R version 4.1.0 (2021-05-18) following packages:","code":""},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the Author","heading":"About the Author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France. struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email.","code":""},{"path":"crashcourse.html","id":"crashcourse","chapter":"1 Bayesian statistics & MCMC","heading":"1 Bayesian statistics & MCMC","text":"","code":""},{"path":"crashcourse.html","id":"introduction","chapter":"1 Bayesian statistics & MCMC","heading":"1.1 Introduction","text":"first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book.","code":""},{"path":"crashcourse.html","id":"bayes-theorem","chapter":"1 Bayesian statistics & MCMC","heading":"1.2 Bayes‚Äô theorem","text":"Let‚Äôs wait longer jump . Bayesian statistics relies Bayes‚Äô theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes‚Äô death thanks friend‚Äôs efforts Richard Price, independently discovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes‚Äô theorem background. Source: James Kulich\nsee minute, Bayes‚Äô theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B definitely occurred.2 order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes‚Äô theorem (Figure 1.2) gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]\nOriginally, Bayes‚Äô theorem seen way infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unkown disease B symptoms, doctor knows P(symptoms|disease) wants derive P(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‚Äòinverse probability.‚Äô\nFigure 1.2: Bayes‚Äô theorem spelt blue neon offices Autonomy Cambridge. Source: Wikipedia\ndon‚Äôt know , need think twice messing letters around. find easier remember Bayes‚Äô theorem written like this3:\\[ \\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})} \\]\nhypothesis working assumption want learn using data. capture-recapture analyses, hypothesis might parameter like detection probability, regression parameters relationship survival probability covariate. Bayes‚Äô theorem tells us obtain probability hypothesis given data . great think , exactly scientific method ! ‚Äôd like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains Bayesian framework natural understanding statistics.might ask , Bayesian statistics default statistics? Clearly, futile wars male statisticians (including Ronald Fisher, Jerzy Neyman Egon Sharpe Pearson among others), little progress made two centuries. Also, recently, practical problems implement Bayes‚Äô theorem. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades.","code":""},{"path":"crashcourse.html","id":"what-is-the-bayesian-approach","chapter":"1 Bayesian statistics & MCMC","heading":"1.3 What is the Bayesian approach?","text":"Typical statistical problems involve estimating parameter (several parameters) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed fixed unknown distribution4 ‚Äì distribution parameter.Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work, lab work expertise esteemed colleagues. updating process based upon Bayes‚Äô theorem ‚Äôve seen earlier. Loosely, let‚Äôs say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes‚Äô theorem gives way estimate parameter \\(\\theta\\) given data :\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet‚Äôs spend time going quantity formula.left-hand side \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ‚Äôre , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. Yes, Bayesian frequentist approaches likelihood core, mostly explains results often differ much. likelihood captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don‚Äôt know anything \\(\\theta\\). Usually however, never start scratch, ‚Äôd like prior reflect information .Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood obtained integrating likelihood respect prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates one posterior distribution. average likelihood integral dimension number parameters \\(\\theta\\) need estimate. quantity difficult, impossible, calculate general. one reasons Bayesian method wasn‚Äôt used recently, need algorithms estimate posterior distributions illustrate next section.","code":""},{"path":"crashcourse.html","id":"numerical-approx","chapter":"1 Bayesian statistics & MCMC","heading":"1.4 Approximating posteriors via numerical integration","text":"Let‚Äôs take example illustrate Bayes‚Äô theorem. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive5. ‚Äôd like estimate winter survival \\(\\theta\\).build model first. Assuming animals independent survival probability, \\(y\\) number alive animals end winter binomial distribution6 \\(n\\) trials \\(\\theta\\) probability success:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]likelihood can visualised R:\nFigure 1.3: Binomial likelihood \\(n = 57\\) released animals \\(y = 19\\) survivors winter. value survival (x-axis) corresponds maximum likelihood function (y-axis) MLE, proportion success example, close 0.33.\nBesides likelihood, priors another component model Bayesian approach. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes‚Äô theorem. write R function computes product likelihood times prior, numerator Bayes‚Äô theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\Pr(\\theta) d\\theta}\\)use R function integrate calculate integral denominator, implements quadrature techniques divide little squares area underneath curve delimited function integrate (numerator), count .get numerical approximation posterior Figure 1.4 applying Bayes‚Äô theorem.\nFigure 1.4: Winter survival posterior distribution obtained numerical integration.\ngood numerical approximation survival posterior distribution? Ideally, want compare approximation true posterior distribution. Although closed-form expression posterior distribution general intractable, combine binomial likelihood together beta distribution prior, posterior distribution also beta distribution, makes amenable sorts exact calculations7. beta distribution continuous 0 1, extends uniform distribution situations outcomes equally likely. two parameters \\(\\) \\(b\\) control shape (Figure 1.5).\nFigure 1.5: distribution beta(\\(\\),\\(b\\)) different values \\(\\) \\(b\\). Note \\(= b = 1\\), get uniform distribution 0 1, see top left panel. \\(\\) \\(b\\) equal, distribution symmetric, bigger \\(\\) \\(b\\), peaked distribution smaller variance.\n\nFigure 1.6: Comparison exact (dashed line) vs.¬†numerical approximation (continuous line) winter survival posterior distribution.\nexample, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature techniques R function integrate(). Now multiple parameters? example, let‚Äôs imagine ‚Äôd like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes‚Äô theorem gives posterior distribution three parameters together:\\[ \\Pr(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\times \\Pr(\\alpha, \\beta, p)}{\\iiint \\, \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\Pr(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ‚Äôre interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters ‚Äì two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue.","code":"\ny <- 19 # nb of success\nn <- 57 # nb of attempts\ngrid <- seq(0, 1, 0.01) # grid of values for survival\nlikelihood <- dbinom(y, n, grid) # compute binomial likelihood\ndf <- data.frame(survival = grid, likelihood = likelihood) \ndf %>%\n  ggplot() + \n  aes(x = survival, y = likelihood) + \n  geom_line(size = 1.5)\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) # Bayes' theorem\nnumerical_posterior %>%\n  ggplot() +\n  aes(x = survival, y = posterior) + \n  geom_line(size = 1.5)"},{"path":"crashcourse.html","id":"markov-chain-monte-carlo-mcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5 Markov chain Monte Carlo (MCMC)","text":"early 1990s, statisticians rediscovered work 1950‚Äôs physics. famous paper lay fundations modern Bayesian statistics (see Figure 1.7), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes‚Äô theorem.\nFigure 1.7: MCMC article cover. Source: Journal Chemical Physics\nsimulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo, let‚Äôs try make sense terms.","code":""},{"path":"crashcourse.html","id":"monte-carlo-integration","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.1 Monte Carlo integration","text":"Monte Carlo stand ? Monte Carlo integration simulation technique calculate integrals function \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\), say \\(\\int f(X) \\Pr(X)dX\\). draw values \\(X_1,\\ldots,X_k\\) \\(\\Pr(X)\\) distribution \\(X\\), apply function \\(f\\) values, calculate mean new values \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) approximate integral. Monte Carlo integration used Bayesian context? posterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean posterior distribution, \\(E(\\theta) = \\int \\theta \\Pr(\\theta|\\text{data})\\), \\(X\\) \\(\\theta\\) now \\(f\\) identity function, can calculated Monte Carlo integration:may check mean just calculated matches expectation beta distribution9:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. Finding bounds credible interval requires calculating quantiles, turn involves integrals use Monte Carlo integration. 95\\(\\%\\) credible interval winter survival can obtained R :","code":"\nsample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)\nmean(sample_from_posterior) # compute mean with Monte Carlo integration\n## [1] 0.3391\n20/(20+39) # expectation of beta(20,39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2289 0.4582"},{"path":"crashcourse.html","id":"markov-chains","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.2 Markov chains","text":"Markov chain? Markov chain random sequence numbers, number depends previous number. example weather home town Southern France, Montpellier, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamic Markov chain captured transition matrix \\(\\mathbf{\\Gamma}\\):\n\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    \\text{sunny tomorrow} & \\text{rainy tomorrow} \\\\ \n0.8 & 0.2 \\\\ \n0.9 & 0.1 \\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\text{sunny today} \\\\ \\text{rainy today}\n    \\end{matrix}\n\\end{matrix}\n\\]\ncertain conditions10, Markov chain converge unique stationary distribution. weather example, let‚Äôs run Markov chain 20 steps:row transition matrix converges distribution \\((0.82, 0.18)\\) number steps increases. Convergence happens matter state start , always probability 0.82 day sunny 0.18 day rainy. Back MCMC, neat idea can build Markov chain given stationary distribution set desired posterior distribution.Putting Monte Carlo Markov chains together, MCMC allows us generate sample values whose distribution converges posterior distribution (Markov chain), can use sample values calculate posterior summaries (Monte Carlo), posterior means credible intervals.","code":"\nweather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\nsteps <- 20\nfor (i in 1:steps){\n  weather <- weather %*% weather # matrix multiplication\n}\nround(weather, 2) # matrix product after 20 steps\n##      [,1] [,2]\n## [1,] 0.82 0.18\n## [2,] 0.82 0.18"},{"path":"crashcourse.html","id":"metropolis-algorithm","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.3 Metropolis algorithm","text":"several ways constructing Markov chains Bayesian inference11. illustrate Metropolis algorithm implement practice12.Let‚Äôs go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows:pick value parameter estimated. start Markov chain ‚Äì starting value.pick value parameter estimated. start Markov chain ‚Äì starting value.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\) ‚Äì Hastings ratio. magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\) ‚Äì Hastings ratio. magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.repeat 2-4 number times ‚Äì steps.repeat 2-4 number times ‚Äì steps.Enough theory, let‚Äôs implement Metropolis algorithm R. Let‚Äôs start setting scene.Now follow 5 steps ‚Äôve just described. First, pick starting value, store (step 1)., need function propose candidate value. add value taken normal distribution mean zero standard deviation call away. work logit scale make sure candidate value survival lies 0 1.Now ‚Äôre ready steps 2, 3 4. write loop take care step 5. Remember start initial value 0.5 run algorithm 100 steps iterations.get following values.\nFigure 1.8: Visualisation Markov chain starting value 0.5, steps iterations x-axis, generated values y-axis. graphical representation called trace plot.\nacceptance probability 0.44 almost satisfying.\nFigure 1.9: Trace plot survival two chains starting 0.2 (yellow) 0.5 (blue) run 100 steps.\n\nFigure 1.10: Trace plot survival chains starting 0.5 1000 steps.\n‚Äôre , trace plot looks like beautiful lawn, see Section 1.6. find informative look animated version Figure 1.10, helps understanding stochastic behavior algorithm, also realise chains converge stationary distribution, see Figure 1.11.\nFigure 1.11: Animated trace plot survival three chains starting 0.2, 0.5 0.7 run 1000 steps.\nstationary distribution reached, may regard realisations Markov chain sample posterior distribution, obtain numerical summaries. next section, consider several important implementation issues.","code":"\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\naccept <- rep(NA, steps) # keep track of accept/reject\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\naccept[1] <- 1\nmove <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1\n  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value\n  candidate <- plogis(logit_candidate) # back-transform (0,1)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for survival (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev # likelihod and prior are on the log scale\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  X <- runif(1, 0, 1) # spin continuous spinner\n  if (X < R){\n    theta.post[t] <- theta_star # accept candidate value\n    accept[t] <- 1 # reject\n  }\n  else{\n    theta.post[t] <- theta.post[t-1] # keep current value\n    accept[t] <- 0 # reject\n  }\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980\ntail(theta.post) # last values\n## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862"},{"path":"crashcourse.html","id":"convergence-diag","chapter":"1 Bayesian statistics & MCMC","heading":"1.6 Assessing convergence","text":"implementing MCMC, need determine long takes Markov chain converge target distribution, number iterations need achieving convergence get reasonable Monte Carlo estimates numerical summaries (posterior means credible intervals).","code":""},{"path":"crashcourse.html","id":"burn-in","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.1 Burn-in","text":"practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.12 need least 500 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 750 even 1000 iterations burn-. length burn-period can determined performing preliminary MCMC short runs.\nFigure 1.12: Determining length burn-period. chain starts value 0.99 rapidly stabilises, values bouncing back forth around 0.3 500th iteration onwards. may choose shaded area burn-, discard corresponding values.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check replicates achieve target distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values 1.1 indicate likely convergence.Back example, run two Markov chains starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.13, get value BGR statistic near 1 2000 iterations, suggests 2000 iterations burn-, evidence lack convergence.\nFigure 1.13: Brooks-Gelman-Rubin statistic function number iterations.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .13","code":""},{"path":"crashcourse.html","id":"chain-length","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.2 Chain length","text":"long chain needed produce reliable parameter estimates? answer question, need keep mind successive steps Markov chain near , independent ‚Äì usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let‚Äôs get back survival example. Figure 1.14 shows trace plots different values standard deviation (parameter away) (normal) proposal distribution use propose candidate value (Section 1.5.3). Small big moves provide high correlations successive observations Markov chain, whereas standard deviation 1 allows efficient exploration parameter space. movement around parameter space referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.14: Trace plots different values standard deviation (SD) proposal distribution. Left: chain exhibits small moves mixing bad. Right: chain exhibits big moves mixing bad. Middle: chain exhibits adequate moves mixing good. thousand last iterations shown.\naddition trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated \\(k\\) iterations, lag, increasing values \\(k\\) (Figure 1.15).\nFigure 1.15: Autocorrelation function plots different values standard deviation (SD) proposal distribution. Left right: Autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: Autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 1000\\) independent steps get reasonable Monte Carlo estimates model parameters. animal survival example, n.eff can calculated R coda::effectiveSize() function:expected, n.eff less number MCMC iterations autocorrelation. standard deviation proposal distribution 1 mixing good (Figures 1.14 1.15) get satisfying effective sample size.","code":""},{"path":"crashcourse.html","id":"what-if-you-have-issues-of-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.3 What if you have issues of convergence?","text":"diagnosing MCMC convergence, () often run troubles. section provide tips learnt experience.mixing bad effective sample size small, may just need increase burn-/sample . Using informative priors might also make Markov chains converge faster helping MCMC sampler (e.g.¬†Metropolis algorithm) navigating efficiently parameter space. spirit, picking better initial values starting chain harm. , strategy consists using estimates simpler model MCMC chains converge.convergence issues persist, often problem model14. bug code? typo somewhere? mistake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice see model data generating tool first place, simulate data using realistic values parameters, try recover parameter values fitting model simulated data. Simulating model help understanding works, , data need get reasonable estimates.see strategies improve convergence next chapters.15","code":""},{"path":"crashcourse.html","id":"summary","chapter":"1 Bayesian statistics & MCMC","heading":"1.7 Summary","text":"Bayes‚Äô theorem, may update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): \\(\\text{posterior} \\propto \\text{likelihood} \\times \\text{prior}\\)Bayes‚Äô theorem, may update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): \\(\\text{posterior} \\propto \\text{likelihood} \\times \\text{prior}\\)idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence replicates reach regime.discard iterations initial burn-phase achieve convergence replicates reach regime., run chain long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters., run chain long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters.","code":""},{"path":"crashcourse.html","id":"suggested-reading","chapter":"1 Bayesian statistics & MCMC","heading":"1.8 Suggested reading","text":"Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.","code":""},{"path":"intronimble.html","id":"intronimble","chapter":"2 Introduction to Nimble","heading":"2 Introduction to Nimble","text":"coder Metropolis d‚Äôau-dessus dans Nimble","code":""},{"path":"intronimble.html","id":"what-is-nimble","chapter":"2 Introduction to Nimble","heading":"2.1 What is Nimble?","text":"\nFigure 2.1: (Meme created Todd Arnold‚Äôs wonderful students)\n\nFigure 2.2: (Meme created Todd Arnold‚Äôs wonderful students)\nNumerical Inference statistical Models using Bayesian Likelihood Estimation.Numerical Inference statistical Models using Bayesian Likelihood Estimation.framework hierarchical statistical models algorithms.framework hierarchical statistical models algorithms.Uses almost model code WinBUGS, OpenBUGS, JAGS.Uses almost model code WinBUGS, OpenBUGS, JAGS.extension BUGS language: additional syntax, custom functions distributions.extension BUGS language: additional syntax, custom functions distributions.configurable system MCMC.configurable system MCMC.library methods (SMC, MCEM).library methods (SMC, MCEM).Sequential Monte Carlo (particle filtering)Sequential Monte Carlo (particle filtering)Monte Carlo Expectation Maximization (maximum likelihood)Monte Carlo Expectation Maximization (maximum likelihood)model-generic programming system write new analysis methods.model-generic programming system write new analysis methods.extends BUGS language writing new functions distributions,extends BUGS language writing new functions distributions,provides samplers can deal discrete latent statesand provides samplers can deal discrete latent states","code":""},{"path":"intronimble.html","id":"load-nimble-package","chapter":"2 Introduction to Nimble","heading":"2.2 Load nimble package","text":"","code":"\nlibrary(nimble)"},{"path":"intronimble.html","id":"build-model-made-of-likelihood-and-priors","chapter":"2 Introduction to Nimble","heading":"2.3 Build model, made of likelihood and priors","text":"","code":"\nnaive.survival.model <- nimbleCode({\n  # prior\n  phi ~ dunif(0, 1)\n  # likelihood\n  y ~ dbinom(phi, n)\n})"},{"path":"intronimble.html","id":"syntax-whats-newbetterdifferent","chapter":"2 Introduction to Nimble","heading":"2.4 Syntax: what‚Äôs new/better/different?","text":"VectorizationMore flexible specification distributionsYour functions distributionsThe end empty indices& ‚Ä¶","code":"\n# JAGS (& Nimble)\nfor(t in 1:Tmax){\n  x[t] <- Mu.x + epsilon[t]\n}\n\n# Nimble\nx[1:Tmax] <- Mu.x + epsilon[1:Tmax]\n# JAGS (& Nimble)\nfor(t in 1:Tmax){\n  epsilon[t] ~ dnorm(0, tau)\n}\ntau <- pow(sigma, -2)\nsigma ~ dunif(0, 5)\n\n# Nimble\nfor(t in 1:Tmax){\n  epsilon[t] ~ dnorm(0, sd = sigma)\n}\nsigma ~ dunif(0, 5)\nx[1:Tmax] <- myNimbleFunction(a = Mu.x, b = epsilon[1:Tmax])\nsigma ~ dCustomDistr(c = 0.5, z = 10)\n# JAGS\nsum.x <- sum(x[])\n\n# Nimble\nsum.x <- sum(x[1:Tmax])"},{"path":"intronimble.html","id":"read-in-data","chapter":"2 Introduction to Nimble","heading":"2.5 Read in data","text":"Back naive survival model:","code":"\nnaive.survival.model <- nimbleCode({\n  # prior\n  phi ~ dunif(0, 1)\n  # likelihood\n  y ~ dbinom(phi, n)\n})\nmy.data <- list(n = 57, y = 19)"},{"path":"intronimble.html","id":"distinguish-constants-and-data","chapter":"2 Introduction to Nimble","heading":"2.6 Distinguish constants and data","text":"Nimble, ‚Äúdata‚Äù data‚Ä¶Constants:\n+ Can never changed\n+ Must provided model defined (part model structure)\n+ E.g. vector known index values, variables used define -loops, etc.Nimble, ‚Äúdata‚Äù data‚Ä¶Data:\n+ Can changed without re-building model\n+ Can (re-)simulated within model\n+ E.g. stuff appears left ‚Äú~‚Äùcomputational efficiency, better specify much possible constants.Nimble help !","code":"\nmy.constants <- list(n = 57)\nmy.data <- list(y = 19)\nmy.constants <- list(n = 57)\nmy.data <- list(y = 19)"},{"path":"intronimble.html","id":"specify-initial-values","chapter":"2 Introduction to Nimble","heading":"2.7 Specify initial values","text":"","code":"\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.2046"},{"path":"intronimble.html","id":"which-parameters-to-save","chapter":"2 Introduction to Nimble","heading":"2.8 Which parameters to save?","text":"","code":"\nparameters.to.save <- c(\"phi\")"},{"path":"intronimble.html","id":"mcmc-details","chapter":"2 Introduction to Nimble","heading":"2.9 MCMC details","text":"Number posterior samples per chain:\\[n.posterior = \\frac{n.iter - n.burnin}{n.thin}\\]","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nn.thin <- 1"},{"path":"intronimble.html","id":"run-model-tadaa","chapter":"2 Introduction to Nimble","heading":"2.10 Run model, tadaa!","text":"","code":"\nmcmc.output <- nimbleMCMC(code = naive.survival.model,     \n                          data = my.data,  \n                          constants = my.constants,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          thin = n.thin,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)"},{"path":"intronimble.html","id":"explore-mcmc-outputs","chapter":"2 Introduction to Nimble","heading":"2.11 Explore MCMC outputs","text":"","code":"\nstr(mcmc.output)\n## List of 2\n##  $ chain1: num [1:4000, 1] 0.36 0.432 0.374 0.374 0.412 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"phi\"\n##  $ chain2: num [1:4000, 1] 0.325 0.325 0.384 0.384 0.475 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"phi\"\nhead(mcmc.output$chain1)\n##         phi\n## [1,] 0.3604\n## [2,] 0.4323\n## [3,] 0.3739\n## [4,] 0.3739\n## [5,] 0.4125\n## [6,] 0.4125"},{"path":"intronimble.html","id":"numerical-summaries","chapter":"2 Introduction to Nimble","heading":"2.12 Numerical summaries","text":"","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.34 0.06 0.23 0.34  0.46    1  1926"},{"path":"intronimble.html","id":"trace-and-posterior-density","chapter":"2 Introduction to Nimble","heading":"2.13 Trace and posterior density","text":"","code":"\nMCMCtrace(mcmc.output,\n          pdf = FALSE) \nMCMCtrace(mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE,\n          n.eff = TRUE) "},{"path":"intronimble.html","id":"our-nimble-workflow-so-far","chapter":"2 Introduction to Nimble","heading":"2.14 Our nimble workflow so far","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow_sofar.png\")"},{"path":"intronimble.html","id":"but-nimble-gives-full-access-to-the-mcmc-engine","chapter":"2 Introduction to Nimble","heading":"2.15 But nimble gives full access to the MCMC engine","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow.png\")\nknitr::include_graphics(\"images/I1bIY06.gif\")"},{"path":"intronimble.html","id":"useful-resources","chapter":"2 Introduction to Nimble","heading":"2.16 Useful resources","text":"Official website https://r-nimble.orgOfficial website https://r-nimble.orgUser Manual https://r-nimble.org/html_manual/cha-welcome-nimble.html cheatsheet.User Manual https://r-nimble.org/html_manual/cha-welcome-nimble.html cheatsheet.Users mailing list https://groups.google.com/forum/#!forum/nimble-usersUsers mailing list https://groups.google.com/forum/#!forum/nimble-usersTraining material https://github.com/nimble-trainingTraining material https://github.com/nimble-trainingReference cite using nimble publication:Reference cite using nimble publication:de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, R. Bodik (2017). Programming Models: Writing Statistical Algorithms General Model Structures NIMBLE. Journal Computational Graphical Statistics 26 (2): 403‚Äì13.","code":""},{"path":"hmmcapturerecapture.html","id":"hmmcapturerecapture","chapter":"3 Hidden Markov models","heading":"3 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"back-to-our-survival-example","chapter":"3 Hidden Markov models","heading":"3.1 Back to our survival example","text":"\\(z\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\)\\(z\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\)Let‚Äôs get back survival example.Let‚Äôs get back survival example.model far:model far:\\[\\begin{align*}\n   z &\\sim \\text{Binomial}(n, \\phi) &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]model far combinationOur model far combinationOf binomial likelihoodOf binomial likelihoodAnd Beta prior param 1 1, uniform 0 1.Beta prior param 1 1, uniform 0 1.also:also:\\[\\begin{align*}\n   z_i &\\sim \\text{Bernoulli}(\\phi), \\; = 1, \\ldots, N &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]binomial just sum Bernoulli outcomesThe binomial just sum Bernoulli outcomesLike flipping coin individual get survivor prob phi.Like flipping coin individual get survivor prob phi.several winters? Say \\(T = 5\\) winters.several winters? Say \\(T = 5\\) winters.design, single winter.\nmany species, ‚Äôll need collect data long term get representative estimate survival.design, single winter.\nmany species, ‚Äôll need collect data long term get representative estimate survival.Therefore say big T five winters?Therefore say big T five winters?","code":""},{"path":"hmmcapturerecapture.html","id":"longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.2 Longitudinal data","text":"\\(z_{,t} = 1\\) individual \\(\\) alive winter \\(t\\), \\(z_{,t} = 2\\) dead.call longitudinal data.row individual , columns winters t, sampling occasions.z indexed t, takes value 1 ind alive winter t, 2 otherwise.","code":""},{"path":"hmmcapturerecapture.html","id":"a-model-for-longitudinal-survival-data","chapter":"3 Hidden Markov models","heading":"3.3 A model for longitudinal survival data","text":"model relies assumptions.model relies assumptions.Let‚Äôs think model data.Let‚Äôs think model data.objective remains , estimating survival.objective remains , estimating survival.build model, ‚Äôll make assumptions.build model, ‚Äôll make assumptions.state animal given winter, alive dead, dependent state winter .state animal given winter, alive dead, dependent state winter .First, assume state animal given winter, alive dead, dependent state winter .First, assume state animal given winter, alive dead, dependent state winter .future depends present, past: Markov process.future depends present, past: Markov process.others words, future depends present, pastIn others words, future depends present, pastThis Markov process.Markov process.animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).animal alive given winter, probability survives next winter \\(\\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).probability dies \\(1 - \\phi\\).animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.animal dead winter, remains dead, unless believe zombies.","code":""},{"path":"hmmcapturerecapture.html","id":"markov-process","chapter":"3 Hidden Markov models","heading":"3.4 Markov process","text":"markov process can represented way.state t+1 depends state t.model, going winter next driven survival mortality processes.probability going alive 1 alive 1 phi.alive 1 dead 2 1 - phi.probability remain dead 1, go state 2 dead state 2 dead.","code":""},{"path":"hmmcapturerecapture.html","id":"transition-matrix","chapter":"3 Hidden Markov models","heading":"3.5 Transition matrix","text":"core Markov process made transition probabilities.core Markov process made transition probabilities.engine Markov model transition matrix.engine Markov model transition matrix.matrix table gathers probabilities transition states one occasion next.matrix table gathers probabilities transition states one occasion next.example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_t = 1 | z_{t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).probability dying interval \\((t-1, t)\\) \\(\\Pr(z_t = 2 | z_{t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_t = 2 | z_{t-1} = 2) = 1\\).probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\gamma_{1,1} & \\gamma_{1,2}\\\\ \n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]probabilities can packed transition matrix \\(\\mathbf{\\Gamma}\\):Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=D \\\\ \\hdashline\n\\phi & 1-\\phi \\\\\n0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ Take time navigate matrix.\n+ rows, origin, columns, destination.\n+ example‚Ä¶","code":""},{"path":"hmmcapturerecapture.html","id":"initial-states","chapter":"3 Hidden Markov models","heading":"3.6 Initial states","text":"Markov process start somewhere.Markov process start somewhere.need probabilities initial states, .e.¬†states \\(t = 1\\).need probabilities initial states, .e.¬†states \\(t = 1\\).words, need probabilities initial statesIn words, need probabilities initial statesi.e.¬†states \\(t = 1\\)..e.¬†states \\(t = 1\\).use \\(\\mathbf{\\delta} = \\left(\\Pr(z_1 = 1), \\Pr(z_1 = 2)\\right)\\).use \\(\\mathbf{\\delta} = \\left(\\Pr(z_1 = 1), \\Pr(z_1 = 2)\\right)\\).denote delta vector.denote delta vector.gathers probability initial states.gathers probability initial states.alive 1 dead 2.alive 1 dead 2.assume animals alive first winter, .e.¬†\\(\\Pr(z_1 = 1) = 1\\) \\(\\Pr(z_1 = 2) = 0\\).assume animals alive first winter, .e.¬†\\(\\Pr(z_1 = 1) = 1\\) \\(\\Pr(z_1 = 2) = 0\\).individuals marked release first winter.individuals marked release first winter.Therefore alive first captured.Therefore alive first captured.means state 1 alive sure.means state 1 alive sure.","code":""},{"path":"hmmcapturerecapture.html","id":"likelihood","chapter":"3 Hidden Markov models","heading":"3.7 Likelihood","text":"\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)} \\\\\n\\end{align*}\\]OK now ‚Äôve defined Markov model, need likelihood apply Bayes theorem.likelihood probability data, given model. data z.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]‚Äôre gonna work backward, starting last sampling occasion.Now likelihood can written product probability zT ie ‚Äôre alive last occasion given past history, states previous occasions, times prob past history, y definition cond prob.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]Markov model, ‚Äôre memory less, prob next state, zT, depends current state, zT-1, previous states.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]can apply reasoning T-1.First conditional prob.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]markovian property.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n\\end{align*}\\].\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n\\end{align*}\\]end expression likelihood.\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}\\\\\n\\end{align*}\\]product cond probabilities. prob initial states Pr(z1).\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\\\\n\\end{align*}\\]recognize gammas defined earlier.transition probabilities.","code":""},{"path":"hmmcapturerecapture.html","id":"example","chapter":"3 Hidden Markov models","heading":"3.8 Example","text":"Let‚Äôs assume animal alive, alive dies.Let‚Äôs assume animal alive, alive dies.realise calculations bit difficult follow.realise calculations bit difficult follow.Let‚Äôs take example.Let‚Äôs take example.\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?\\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood?Let‚Äôs apply formula just derived.Let‚Äôs apply formula just derived.\\[\\begin{align*}\n\\Pr(\\mathbf{z} = (1, 1, 2)) &= \\Pr(z_1 = 1) \\; \\gamma_{z_{1} = 1, z_{2} = 1} \\; \\gamma_{z_{2} = 1, z_{3} = 2}\\\\\n                            &= 1 \\; \\phi \\; (1 - \\phi).\n\\end{align*}\\]prob sequence alive, alive dead isThe prob sequence alive, alive dead isThe prob alive first, stay alive, die.prob alive first, stay alive, die.prob alive first occasion 1, contribution individual likelihood phi times 1 - phi.prob alive first occasion 1, contribution individual likelihood phi times 1 - phi.Remember:Remember:\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\gamma_{1,1} & \\gamma_{1,2}\\\\ \n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"our-model","chapter":"3 Hidden Markov models","heading":"3.9 Our model","text":"\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   \\color{white}{z_t | z_{t-1}} & \\color{white}{\\sim} \\color{white}{\\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}})} & \\color{white}{\\text{[likelihood, }t > 1 \\text{]}}\\\\\n  \\color{white}{\\phi} & \\color{white}{\\sim} \\color{white}{\\text{Beta}(1, 1)} & \\color{white}{\\text{[prior }\\phi \\text{]}} \\\\ \n\\end{align*}\\]OK let‚Äôs wrap .OK let‚Äôs wrap .model far one.model far one.Initial state multinomial one trial, probability delta.Initial state multinomial one trial, probability delta.dice two faces, coin, prob alive, 1 - prob dead. + course, want Markov chain start, ‚Äôd better say ‚Äôs alive delta just (1,0).dice two faces, coin, prob alive, 1 - prob dead. + course, want Markov chain start, ‚Äôd better say ‚Äôs alive delta just (1,0).","code":""},{"path":"hmmcapturerecapture.html","id":"our-model-1","chapter":"3 Hidden Markov models","heading":"3.10 Our model","text":"\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   \\color{white}{z_t | z_{t-1}} & \\color{white}{\\sim} \\color{white}{\\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}})} & \\color{white}{\\text{[likelihood, }t > 1 \\text{]}}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]also need prior survival.usual take uniform distribution 0 1, beta parameters 1 1.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]Now main part dynamic states.state t depends state t-1, multinomial random variable, one trial.probabilities given rows transition matrix.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\color{blue}{\\phi} & \\color{blue}{1 - \\phi}\\\\ \n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]\\[\\color{blue}{\\gamma_{z_{t-1} = 1,z_{t}} = (\\phi, 1-\\phi)}\\]z t-1 alive, first row, phi 1-phi.\\[\\begin{align*}\n   z_1 &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n\\end{align*}\\]\\[\\begin{align*}\n\\mathbf{\\Gamma} = \n\\left(\\begin{array}{cc} \n\\phi & 1 - \\phi\\\\ \n\\color{blue}{0} & \\color{blue}{1}\n\\end{array}\\right)\n\\end{align*}\\]\\[\\color{blue}{\\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}\\]Otherwise, z t-1 dead 2, second row gamma, 0 1.dead remain dead.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-implementation","chapter":"3 Hidden Markov models","heading":"3.11 Nimble implementation","text":"Nimble, use categorical distribution dcat().Nimble, use categorical distribution dcat().categorical distribution multinomial distribution single draw.categorical distribution multinomial distribution single draw.https://en.wikipedia.org/wiki/Categorical_distributionThe categorical distribution generalization Bernoulli distribution categorical random variable, .e.¬†discrete variable two possible outcomes, roll dice. hand, categorical distribution special case multinomial distribution, gives probabilities potential outcomes single drawing rather multiple drawings.","code":"\nnimble::rcat(n = 20, prob = c(0.1, 0.3, 0.6))\n##  [1] 3 2 1 2 3 3 3 3 2 2 3 2 3 3 1 3 3 1 2 3\nnimble::rcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))\n##  [1] 1 3 3 4 3 3 3 3 3 4 3 3 5 3 4 3 5 3 3 3"},{"path":"hmmcapturerecapture.html","id":"nimble-code","chapter":"3 Hidden Markov models","heading":"3.12 Nimble code","text":"]","code":"\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior #<<\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1) #<<\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1) #<<\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1) #<<\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1) #<<\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1 #<<\n  delta[2] <- 0          # Pr(dead t = 1) = 0 #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){ #<<\n    z[i,1] ~ dcat(delta[1:2]) \n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    } \n  } #<<\n  })\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2]) #<<\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){ #<<\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    } #<<\n  }})\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) #<<\n    }\n  }})"},{"path":"hmmcapturerecapture.html","id":"note","chapter":"3 Hidden Markov models","heading":"3.13 Note","text":"Vector \\(\\delta\\) used placeholder complex models come Class 7.Vector \\(\\delta\\) used placeholder complex models come Class 7., write z[,1] <- 1., write z[,1] <- 1.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-awesomness","chapter":"3 Hidden Markov models","heading":"3.14 Nimble awesomness","text":"able define vectors matrices like R.","code":"\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) #<<\n  delta[1:2] <- c(1, 0) #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n    }\n  }})"},{"path":"hmmcapturerecapture.html","id":"converting-to-nimble-from-jags-openbugs-or-winbugs","chapter":"3 Hidden Markov models","heading":"3.15 Converting to Nimble from Jags, OpenBUGS or WinBUGS","text":"Main difference Nimble guess.Main difference Nimble guess.need specify dimensions vectors matrices.need specify dimensions vectors matrices.write x[] x[,]. Just provide index ranges x[1:n] x[,1:m].write x[] x[,]. Just provide index ranges x[1:n] x[,1:m].tips .tips .","code":""},{"path":"hmmcapturerecapture.html","id":"constants-and-data","chapter":"3 Hidden Markov models","heading":"3.16 Constants and data","text":"","code":"\nmy.constants <- list(N = 57, T = 5)\nmy.constants\n## $N\n## [1] 57\n## \n## $T\n## [1] 5\n\nmy.data <- list(z = z)"},{"path":"hmmcapturerecapture.html","id":"initial-values","chapter":"3 Hidden Markov models","heading":"3.17 Initial values","text":"","code":"\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.6377"},{"path":"hmmcapturerecapture.html","id":"parameters-to-monitor","chapter":"3 Hidden Markov models","heading":"3.18 Parameters to monitor","text":"","code":"\nparameters.to.save <- c(\"phi\")\nparameters.to.save\n## [1] \"phi\""},{"path":"hmmcapturerecapture.html","id":"mcmc-details-1","chapter":"3 Hidden Markov models","heading":"3.19 MCMC details","text":"","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2"},{"path":"hmmcapturerecapture.html","id":"run-nimble","chapter":"3 Hidden Markov models","heading":"3.20 Run Nimble","text":"","code":"\nmcmc.output <- nimbleMCMC(code = markov.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|"},{"path":"hmmcapturerecapture.html","id":"posterior-distribution-of-survival","chapter":"3 Hidden Markov models","heading":"3.21 Posterior distribution of survival","text":"Posterior mean median close \\(0.8\\).Posterior mean median close \\(0.8\\).Cool! data simulated, (true) survival \\(\\phi = 0.8\\).Cool! data simulated, (true) survival \\(\\phi = 0.8\\).","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.78 0.03 0.71 0.78  0.84    1  1699"},{"path":"hmmcapturerecapture.html","id":"unfortunately-this-is-the-data-we-wish-we-had.","chapter":"3 Hidden Markov models","heading":"3.22 Unfortunately, this is the data we wish we had.","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"in-real-life","chapter":"3 Hidden Markov models","heading":"3.23 In real life","text":"Animals monitored exhaustively, like humans medical trial.Animals monitored exhaustively, like humans medical trial.Animals captured, marked identified released alive.Animals captured, marked identified released alive., animals may detected , go undetected ‚Äî capture-recaptureThen, animals may detected , go undetected ‚Äî capture-recaptureWhenever animals go undetected, might alive missed, dead therefore detected ‚Äî imperfect detection.Whenever animals go undetected, might alive missed, dead therefore detected ‚Äî imperfect detection.https://www.youtube.com/embed/tyX79mPm2xYWhenever animals go undetected, might alive missed, dead therefore detected ‚Äî imperfect detection.Whenever animals go undetected, might alive missed, dead therefore detected ‚Äî imperfect detection.Markov process survival partially observed ‚Äî hidden Markov models.Markov process survival partially observed ‚Äî hidden Markov models.","code":""},{"path":"hmmcapturerecapture.html","id":"the-truth-is-in-z","chapter":"3 Hidden Markov models","heading":"3.24 The truth is in \\(z\\)","text":"Unfortunately, partial access \\(z\\).Unfortunately, partial access \\(z\\).observe \\(y\\) detections non-detections.observe \\(y\\) detections non-detections.\\(z\\) \\(y\\) connected?\\(z\\) \\(y\\) connected?","code":""},{"path":"hmmcapturerecapture.html","id":"dead-animals-go-undetected","chapter":"3 Hidden Markov models","heading":"3.25 Dead animals go undetected","text":"animal dead .e.¬†\\(z = 2\\), detected, therefore \\(y = 0\\).","code":""},{"path":"hmmcapturerecapture.html","id":"alive-animals-may-be-detected-or-not","chapter":"3 Hidden Markov models","heading":"3.26 Alive animals may be detected or not","text":"animal alive \\(z = 1\\), detected \\(y = 1\\) w/ prob \\(p\\) \\(y = 0\\) w/ prob \\(1-p\\).animal alive \\(z = 1\\), detected \\(y = 1\\) w/ prob \\(p\\) \\(y = 0\\) w/ prob \\(1-p\\).first detection, know nothing, proceed conditional .first detection, know nothing, proceed conditional .Compare previous tableCompare previous tableSome 1s become 0s.1s become 0s.table \\(y\\) observe real life.table \\(y\\) observe real life.make connection observations, y, true states, zTo make connection observations, y, true states, zWe need describe observations made statesWe need describe observations made states","code":""},{"path":"hmmcapturerecapture.html","id":"observation-matrix","chapter":"3 Hidden Markov models","heading":"3.27 Observation matrix","text":"observation probabilities can packed observation matrix \\(\\mathbf{\\Omega}\\).observation probabilities can packed observation matrix \\(\\mathbf{\\Omega}\\).rows: states alive \\(z = 1\\) dead \\(z = 2\\).rows: states alive \\(z = 1\\) dead \\(z = 2\\).columns: observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively).columns: observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively).\\[\\begin{align*}\n\\mathbf{\\Omega} = \n\\left(\\begin{array}{cc} \n\\omega_{1,1} & \\omega_{1,2}\\\\ \n\\omega_{2,1} & \\omega_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc} \n1 - p & p\\\\ \n1 & 0\n\\end{array}\\right)\n\\end{align*}\\]Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p & p\\\\ \n1 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"hmmcapturerecapture.html","id":"markov-model","chapter":"3 Hidden Markov models","heading":"3.28 Markov model","text":"States \\(z\\) gray.States \\(z\\) gray.Remember graphical repres Markov model.Remember graphical repres Markov model.","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model","chapter":"3 Hidden Markov models","heading":"3.29 Hidden Markov model","text":"States \\(z\\) gray.States \\(z\\) gray.Observations \\(y\\) white.Observations \\(y\\) white.hidden Markov model just two time series.hidden Markov model just two time series.One states Markovian property.One states Markovian property.observations generated states.observations generated states.Run parallel.Run parallel.","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model-for-survival","chapter":"3 Hidden Markov models","heading":"3.30 Hidden Markov model for survival","text":"states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedFor observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedNow add states alive dead, 1 2s.Now add states alive dead, 1 2s.observations, non-detected detected, 1 2s.observations, non-detected detected, 1 2s.parameters, phi transition 1 1.parameters, phi transition 1 1.p prob y 2 detected given z 1 alive.p prob y 2 detected given z 1 alive.","code":""},{"path":"hmmcapturerecapture.html","id":"hmm-likelihood","chapter":"3 Hidden Markov models","heading":"3.31 HMM likelihood","text":"Using formula total probability, likelihood Markov chain:\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\Pr(y_1, y_{2}, \\ldots, y_T)\\\\\n                &= \\sum_{z_1} \\cdots \\sum_{z_T} \\Pr(y_1, y_{2}, \\ldots, y_T | z_1, z_{2}, \\ldots, z_T) \\Pr(z_1, z_{2}, \\ldots, z_T)\\\\\n                &= \\sum_{z_1} \\cdots \\sum_{z_T} \\left(\\prod_{t=1}^T{\\omega_{z_{t}, y_t}}\\right) \\left(\\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\right)\\\\\n\\end{align*}\\]likelihood HMM.likelihood HMM.thing don‚Äôt know states.thing don‚Äôt know states.go possibilities, sum possible states.go possibilities, sum possible states.Hence sums .Hence sums .term likelihood Markov chain, saw .term likelihood Markov chain, saw .component elements observation matrix.component elements observation matrix.likelihood matrix formulation can useful.likelihood matrix formulation can useful.delta, initial states, observation, transitions, . vector ones end get sum terms.delta, initial states, observation, transitions, . vector ones end get sum terms.matrix formulation:\n\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\mathbf{\\delta} \\; \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\cdots \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\; \\mathbf{\\Omega} \\; \\mathbb{1}\n\\end{align*}\\]matrix formulation:\n\\[\\begin{align*}\n\\Pr(\\mathbf{y}) &= \\mathbf{\\delta} \\; \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\cdots \\mathbf{\\Omega} \\; \\mathbf{\\Gamma} \\; \\mathbf{\\Omega} \\; \\mathbb{1}\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example-1","chapter":"3 Hidden Markov models","heading":"3.32 Example","text":"Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example-2","chapter":"3 Hidden Markov models","heading":"3.33 Example","text":"Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n\\end{align*}\\]Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1}\\delta_1 \\gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 2}\n\\end{align*}\\]Note: \\(\\Pr(z_1 = 1) = \\delta_1 = 1\\) \\(\\Pr(z_1 = 2) = 0\\).Let assume animal detected, missed.Let assume animal detected, missed.\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\(\\mathbf{y} = (2, 1)\\). contribution animal likelihood?\\[\\begin{align*}\n\\Pr(\\mathbf{y} = (2, 1)) &= \\sum_{z_1 = 1}^2 \\; \\sum_{z_2 = 1}^2 w_{z_1, y_1 = 2} w_{z_2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2} \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1, z_1, z_1, z_1)}\\\\\n&= \\sum_{z_1 = 1}^2 \\left( w_{z_1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 1} + w_{z_1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\Pr(z_1) \\gamma_{z_1, z_2 = 2} \\right) \\\\\n&= w_{z_1 = 1, y_1 = 2} w_{z_2 = 1, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 1} + w_{z_1 = 1, y_1 = 2} w_{z_2 = 2, y_2 = 1} \\delta_1 \\gamma_{z_1 = 1, z_2 = 2}\\\\\n&= (1 - p) \\phi + (1-\\phi)\n\\end{align*}\\]Note: \\(w_{z_1 = 1, y_1 = 2} = \\Pr(y_1 = 2 | z_1 = 1) = 1\\) condition first capture.","code":""},{"path":"hmmcapturerecapture.html","id":"estimating-the-latent-states-z-or-not","chapter":"3 Hidden Markov models","heading":"3.34 Estimating the latent states \\(z\\) or not?","text":"Next question , shall estimate latent states ?Next question , shall estimate latent states ?previous example, got rid states, likelihood function \\(\\phi\\) \\(p\\) . function maximize Frequentist approach.previous example, got rid states, likelihood function \\(\\phi\\) \\(p\\) . function maximize Frequentist approach.Bayesian approach MCMC methods allows treating latent states parameters, estimated .Bayesian approach MCMC methods allows treating latent states parameters, estimated .Infering latent states \\(z\\) can useful estimate prevalence, e.g.¬†animal epidemiology prevalence disease, evolutionary ecology sex ratio conservation biology prevalence hybrids.Infering latent states \\(z\\) can useful estimate prevalence, e.g.¬†animal epidemiology prevalence disease, evolutionary ecology sex ratio conservation biology prevalence hybrids.Estimating latent states costly though, required, marginalisation may speed computations. Actually, can estimate states afterwards (Viterbi).Estimating latent states costly though, required, marginalisation may speed computations. Actually, can estimate states afterwards (Viterbi).-called marginalisation Yackulic et al.¬†(2020).-called marginalisation Yackulic et al.¬†(2020).neat thing Nimble provides marginalised models nimbleEcology, ‚Äôll get back Class 8.neat thing Nimble provides marginalised models nimbleEcology, ‚Äôll get back Class 8.","code":""},{"path":"hmmcapturerecapture.html","id":"our-model-2","chapter":"3 Hidden Markov models","heading":"3.35 Our model","text":"\\[\\begin{align*}\n   z_{\\text{first}} &\\sim \\text{Multinomial}(1, \\delta) &\\text{[likelihood]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Multinomial}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood]}\\\\\n   y_t | z_{t} &\\sim \\text{Multinomial}(1, \\omega_{z_{t}}) &\\text{[likelihood]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\ \n  p &\\sim \\text{Beta}(1, 1) &\\text{[prior }p \\text{]} \\\\ \n\\end{align*}\\]Now model observation layer ys, conditional z.need prior detection probability.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-implementation-1","chapter":"3 Hidden Markov models","heading":"3.36 Nimble implementation","text":"implement model Nimble?","code":""},{"path":"hmmcapturerecapture.html","id":"priors","chapter":"3 Hidden Markov models","heading":"3.37 Priors","text":"","code":"hmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n..."},{"path":"hmmcapturerecapture.html","id":"hmm-ingredients","chapter":"3 Hidden Markov models","heading":"3.38 HMM ingredients","text":"","code":"\n...\n  # parameters\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n..."},{"path":"hmmcapturerecapture.html","id":"likelihood-1","chapter":"3 Hidden Markov models","heading":"3.39 Likelihood","text":"","code":"...\n    # likelihood\n    for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"hmmcapturerecapture.html","id":"constants","chapter":"3 Hidden Markov models","heading":"3.40 Constants","text":"","code":"\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), T = 5, first = first)\nmy.constants\n## $N\n## [1] 49\n## \n## $T\n## [1] 5\n## \n## $first\n##  [1] 2 1 2 1 1 2 2 2 1 1 1 2 1 2 2 1 2 1 2 1 2 2 4 1 1 1 1 1\n## [29] 1 1 1 2 1 3 1 5 2 1 1 2 1 3 1 3 2 1 1 1 2"},{"path":"hmmcapturerecapture.html","id":"data","chapter":"3 Hidden Markov models","heading":"3.41 Data","text":"data made 0s non-detections 1s detections.data made 0s non-detections 1s detections.use categorical distribution, need code 1, 2, etc. Value 0 accepted.use categorical distribution, need code 1, 2, etc. Value 0 accepted.Add 1 get correct format \\(y=1\\) non-detection \\(y = 2\\) detection.Add 1 get correct format \\(y=1\\) non-detection \\(y = 2\\) detection.","code":"\nmy.data <- list(y = y + 1)"},{"path":"hmmcapturerecapture.html","id":"initial-values-1","chapter":"3 Hidden Markov models","heading":"3.42 Initial values","text":"","code":"\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)"},{"path":"hmmcapturerecapture.html","id":"parameters-to-monitor-1","chapter":"3 Hidden Markov models","heading":"3.43 Parameters to monitor","text":"","code":"\nparameters.to.save <- c(\"phi\", \"p\")\nparameters.to.save\n## [1] \"phi\" \"p\""},{"path":"hmmcapturerecapture.html","id":"mcmc-details-2","chapter":"3 Hidden Markov models","heading":"3.44 MCMC details","text":"","code":"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2"},{"path":"hmmcapturerecapture.html","id":"run-nimble-1","chapter":"3 Hidden Markov models","heading":"3.45 Run Nimble","text":"","code":"\nmcmc.output <- nimbleMCMC(code = hmm.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nmcmc.output <- nimbleMCMC(code = hmm.survival, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter, \n                          nburnin = n.burnin, \n                          nchains = n.chains,\n                          progressBar = FALSE)"},{"path":"hmmcapturerecapture.html","id":"posterior-distribution-of-survival-1","chapter":"3 Hidden Markov models","heading":"3.46 Posterior distribution of survival","text":"data simulated, true survival \\(\\phi = 0.8\\) detection \\(p = 0.6\\).","code":"\nlibrary(MCMCvis)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.52 0.07 0.39 0.52  0.66    1   447\n## phi 0.78 0.06 0.67 0.78  0.89    1   368"},{"path":"hmmcapturerecapture.html","id":"further-reading","chapter":"3 Hidden Markov models","heading":"3.47 Further reading","text":"Zucchini, MacDonald Langrock (2016) Hidden Markov Models Time Series: Introduction Using R (2nd ed). Chapman Hall/CRC.Zucchini, MacDonald Langrock (2016) Hidden Markov Models Time Series: Introduction Using R (2nd ed). Chapman Hall/CRC.McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. Patterson, T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.McClintock, B.T., Langrock, R., Gimenez, O., Cam, E., Borchers, D.L., Glennie, R. Patterson, T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., Reid, J. .. (2020). need speed Bayesian population models: practical guide marginalizing recovering discrete latent states. Ecological Applications 30:e02112.Yackulic, C. B. Dodrill, M., Dzul, M., Sanderlin, J. S., Reid, J. .. (2020). need speed Bayesian population models: practical guide marginalizing recovering discrete latent states. Ecological Applications 30:e02112.L. R. Rabiner (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.L. R. Rabiner (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.Heller Pogaru (2021)","code":""},{"path":"survival.html","id":"survival","chapter":"4 Survival","heading":"4 Survival","text":"","code":"\nknitr::include_graphics(\"images/lebreton.png\")"},{"path":"survival.html","id":"history-of-the-cormack-jolly-seber-cjs-model","chapter":"4 Survival","heading":"4.1 History of the Cormack-Jolly-Seber (CJS) model","text":"S.T. Buckland (2016). Conversation Richard M. Cormack. Statistical Science 31: 142-150.Bayesian uptake","code":""},{"path":"survival.html","id":"what-weve-seen-so-far","chapter":"4 Survival","heading":"4.2 What we‚Äôve seen so far","text":"states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detectedFor observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detected","code":""},{"path":"survival.html","id":"in-the-cjs-model-survival-and-recapture-are-time-varying","chapter":"4 Survival","heading":"4.3 In the CJS model, survival and recapture are time-varying","text":"Survival probability \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\).Survival probability \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\).Recapture (detection) probability \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\).Recapture (detection) probability \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\).Accounts variation e.g.¬†environmental conditions (survival) sampling effort (detection).Accounts variation e.g.¬†environmental conditions (survival) sampling effort (detection).","code":""},{"path":"survival.html","id":"capture-mark-and-recapture","chapter":"4 Survival","heading":"4.4 Capture, mark and recapture","text":"Artificial marks","code":""},{"path":"survival.html","id":"capture-mark-and-recapture-1","chapter":"4 Survival","heading":"4.5 Capture, mark and recapture","text":"Natural marks","code":""},{"path":"survival.html","id":"the-famous-dipper-example","chapter":"4 Survival","heading":"4.6 The famous Dipper example","text":"\nFigure 4.1: White-throated Dipper (Cinclus cinclus)\n\nFigure 4.2: Gilbert Marzolin\n","code":""},{"path":"survival.html","id":"dippers-captured-and-recaptured-between-1981-and-1987-with-known-sex-and-wing-length","chapter":"4 Survival","heading":"4.7 294 dippers captured and recaptured between 1981 and 1987 with known sex and wing length","text":"","code":""},{"path":"survival.html","id":"back-to-nimble.","chapter":"4 Survival","heading":"4.8 Back to Nimble.","text":"","code":""},{"path":"survival.html","id":"our-model-so-far-phi-p","chapter":"4 Survival","heading":"4.8.1 Our model so far \\((\\phi, p)\\)","text":"","code":"\nhmm.phip <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"survival.html","id":"our-model-so-far-phi-p-1","chapter":"4 Survival","heading":"4.8.2 Our model so far \\((\\phi, p)\\)","text":"","code":"##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.56 0.03 0.52 0.56  0.62 1.00   500\n## p   0.89 0.03 0.83 0.89  0.94 1.13   273"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t","chapter":"4 Survival","heading":"4.8.3 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival #<<\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection #<<\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-1","chapter":"4 Survival","heading":"4.8.4 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){ #<<\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  } #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-2","chapter":"4 Survival","heading":"4.8.5 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1) #<<\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1) #<<\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1) #<<\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) #<<\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-3","chapter":"4 Survival","heading":"4.8.6 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) \n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t) #<<\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t) #<<\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t) #<<\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t) #<<\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-4","chapter":"4 Survival","heading":"4.8.7 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1) \n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1]) #<<\n    }\n  }\n})"},{"path":"survival.html","id":"the-cjs-model-phi_t-p_t-5","chapter":"4 Survival","heading":"4.8.8 The CJS model \\((\\phi_t, p_t)\\)","text":"","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199\n## phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410\n## phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506\n## phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415\n## phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365\n## phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38\n## p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344\n## p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249\n## p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307\n## p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333\n## p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224\n## p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37"},{"path":"survival.html","id":"time-varying-survival-phi_t-p","chapter":"4 Survival","heading":"4.8.9 Time-varying survival \\((\\phi_t, p)\\)","text":"]","code":"\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"survival.html","id":"time-varying-survival-phi_t-p-1","chapter":"4 Survival","heading":"4.8.10 Time-varying survival \\((\\phi_t, p)\\)","text":"","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564\n## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629\n## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610\n## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553\n## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568\n## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463\n## p      0.89 0.03 0.82 0.89  0.95 1.04   211"},{"path":"survival.html","id":"time-varying-detection-phi-p_t","chapter":"4 Survival","heading":"4.8.11 Time-varying detection \\((\\phi, p_t)\\)","text":"","code":"\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})"},{"path":"survival.html","id":"time-varying-detection-phi-p_t-1","chapter":"4 Survival","heading":"4.8.12 Time-varying detection \\((\\phi, p_t)\\)","text":"","code":"##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.52 0.56  0.61 1.02   381\n## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452\n## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359\n## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412\n## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376\n## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111"},{"path":"survival.html","id":"how-to-select-a-best-model-model-selection","chapter":"4 Survival","heading":"4.9 How to select a best model? Model selection","text":"four models best supported data?four models best supported data?proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .idea penalize models many parameters.idea penalize models many parameters.","code":""},{"path":"survival.html","id":"akaike-information-criterion-aic","chapter":"4 Survival","heading":"4.10 Akaike information criterion (AIC)","text":"\\[AIC = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + 2 K\\]\\(L\\) likelihood \\(K\\) number parameters \\(\\theta_i\\).\\[\\text{AIC} = {\\color{purple}{- 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K))}} + 2 K\\]measure goodness--fit model data: parameters , smaller deviance (bigger likelihood ).\\[\\text{AIC} = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + {\\color{purple}{2 K}}\\]penalty: twice number parameters \\(K\\)AIC makes balance quality fit complexity model.AIC makes balance quality fit complexity model.Best model one lowest AIC value.Best model one lowest AIC value.Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).","code":""},{"path":"survival.html","id":"bayesian-version","chapter":"4 Survival","heading":"4.11 Bayesian version","text":"Watanabe-Akaike (Widely-Applicable) Information Criteria WAIC:\\[\\textrm{WAIC} = -2 \\sum_{= 1}^n \\log E[\\Pr(y_i \\mid \\theta)] + \n                  2 p_\\text{WAIC}\\]\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.","code":""},{"path":"survival.html","id":"how-to-compute-waic-in-nimble","chapter":"4 Survival","heading":"4.12 How to compute WAIC in Nimble?","text":"","code":"\nparameters.to.save <- c(\"phi\", \"p\")\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nparameters.to.save <- c(\"phi\", \"p\", \"z\") #<<\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains,\n                          WAIC = TRUE) #<<"},{"path":"survival.html","id":"dipper-example---continued","chapter":"4 Survival","heading":"4.13 Dipper example - continued","text":"","code":"##       model  WAIC\n## 1   (phi,p) 265.9\n## 2  (phit,p) 277.6\n## 3  (phi,pt) 270.2\n## 4 (phit,pt) 308.8"},{"path":"survival.html","id":"can-we-explain-time-variation-embrace-heterogeneity","chapter":"4 Survival","heading":"4.14 Can we explain time variation? Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\).Include temporal covariates, say \\(x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).Let‚Äôs investigate effect water flow dipper survival (Marzolin 2002).Let‚Äôs investigate effect water flow dipper survival (Marzolin 2002).]","code":"\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] #<<\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5) # prior intercept #<<\n  beta[2] ~ dnorm(0, 1.5) # prior slope #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\n# water flow in L/s\nwater_flow <- c(443, 1114, 529, 434, 627, 466) # 1981, 1982, ..., 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow) #<<\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first, \n                     flow = water_flow_st) #<<\n\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\n\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")"},{"path":"survival.html","id":"regression-intercept-and-slope","chapter":"4 Survival","heading":"4.14.1 Regression intercept and slope","text":"","code":""},{"path":"survival.html","id":"time-dependent-covariate-constrained-survival-probability-estimates","chapter":"4 Survival","heading":"4.14.2 Time-dependent (covariate constrained) survival probability estimates","text":"","code":""},{"path":"survival.html","id":"embrace-heterogeneity","chapter":"4 Survival","heading":"4.15 Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\)Include temporal covariates, say \\(x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)temporal variation fully explained covariates, add random effectsIf temporal variation fully explained covariates, add random effects\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)","code":"hmm.phiflowREp <- nimbleCode({\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] + eps[t] \n    eps[t] ~ dnorm(0, sd = sdeps) \n    ...  \n  }\n  sdeps ~ dunif(0,10) \n  ..."},{"path":"survival.html","id":"what-about-individual-heterogeneity","chapter":"4 Survival","heading":"4.16 What about individual heterogeneity?","text":"Discrete covariate like, e.g., sexDiscrete covariate like, e.g., sexContinuous covariate like, e.g., mass sizeContinuous covariate like, e.g., mass size","code":""},{"path":"survival.html","id":"sex-and-wing-length-in-dipper","chapter":"4 Survival","heading":"4.17 Sex and wing length in Dipper","text":"","code":""},{"path":"survival.html","id":"sex-effect","chapter":"4 Survival","heading":"4.18 Sex effect","text":"Let‚Äôs use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleLet‚Äôs use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleAnd write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)male survival isThen male survival \\[\\text{logit}(\\phi_i) = \\beta_1\\]female survival \\[\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2\\]","code":""},{"path":"survival.html","id":"nimble-implementation-with-sex-as-a-covariate","chapter":"4 Survival","heading":"4.18.1 Nimble implementation with sex as a covariate","text":"","code":"\nhmm.phisexp <- nimbleCode({\n...\n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * sex[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  } #<<\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) #<<\n  phi_male <- 1/(1+exp(-beta[1])) #<<\n  phi_female <- 1/(1+exp(-(beta[1]+beta[2]))) #<<\n...\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##             mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]     0.29 0.14  0.01  0.29  0.57 1.01   237\n## beta[2]    -0.09 0.19 -0.47 -0.10  0.29 1.01   241\n## p           0.90 0.03  0.83  0.90  0.95 1.02   253\n## phi_female  0.55 0.04  0.48  0.55  0.62 1.02   698\n## phi_male    0.57 0.03  0.50  0.57  0.64 1.01   237"},{"path":"survival.html","id":"nimble-implementation-with-nested-indexing","chapter":"4 Survival","heading":"4.18.2 Nimble implementation with nested indexing","text":"Let‚Äôs use covariate \\(\\text{sex}\\) contains 1s 2s, indicating sex individual: 1 male, 2 femaleE.g. individual \\(= 2\\), beta[sex[]] gives beta[sex[2]] beta[1] beta[2] depending whether sex[2] 1 2.","code":"\n...\nfor (i in 1:N){\n  phi[i] <- beta[sex[i]] #<<\n  gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n}\nbeta[1] ~ dunif(0,1) # male survival #<<\nbeta[2] ~ dunif(0,1) # female survival #<<\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## beta[1] 0.57 0.03 0.50 0.57  0.63 1.00   616\n## beta[2] 0.55 0.03 0.48 0.55  0.62 1.02   657\n## p       0.90 0.03 0.83 0.90  0.95 1.10   229"},{"path":"survival.html","id":"what-about-wing-length","chapter":"4 Survival","heading":"4.18.3 What about wing length?","text":"","code":"\n...  \n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # slope #<<\n..."},{"path":"survival.html","id":"wing-length","chapter":"4 Survival","heading":"4.18.4 Wing length","text":"may test effect sex wing length, see exercise Worksheets.","code":""},{"path":"survival.html","id":"what-if-covariates-vary-with-individual-and-time","chapter":"4 Survival","heading":"4.19 What if covariates vary with individual and time?","text":"Think age example (see exercises Worksheets); covariate nested indexing works fine.Think age example (see exercises Worksheets); covariate nested indexing works fine.Now, think body size across life.Now, think body size across life.Problem record size animal non-detected.Problem record size animal non-detected.Discretize small, medium large treat state ‚Äî later.Discretize small, medium large treat state ‚Äî later.Assume model covariate fill missing values (imputation).Assume model covariate fill missing values (imputation).","code":""},{"path":"survival.html","id":"why-bayes-incorporate-prior-information.","chapter":"4 Survival","heading":"4.20 Why Bayes? Incorporate prior information.","text":"","code":""},{"path":"survival.html","id":"vague-prior","chapter":"4 Survival","heading":"4.21 Vague prior","text":"far, assumed vague prior:\\[\\phi_{prior} \\sim \\text{Beta}(1,1) = \\text{Uniform}(0,1)\\]vague prior, mean posterior survival \\(\\phi_{posterior} = 0.56\\)vague prior, mean posterior survival \\(\\phi_{posterior} = 0.56\\)credible interval \\([0.52,0.62]\\)credible interval \\([0.52,0.62]\\)Posterior distribution survival color (two chains), prior gray dashed line.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information","chapter":"4 Survival","heading":"4.22 How to incorporate prior information?","text":"Using information body mass annual survival 27 European passerines, can predict survival European dippers using body mass.Using information body mass annual survival 27 European passerines, can predict survival European dippers using body mass.dippers, body mass 59.8g, therefore \\(\\phi = 0.57\\) \\(\\text{sd} = 0.073\\).dippers, body mass 59.8g, therefore \\(\\phi = 0.57\\) \\(\\text{sd} = 0.073\\).Assuming informative prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\).Assuming informative prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\).Mean posterior \\(\\phi_{posterior} = 0.56\\) credible interval \\([0.52, 0.61]\\).Mean posterior \\(\\phi_{posterior} = 0.56\\) credible interval \\([0.52, 0.61]\\).increase precision posterior inference.increase precision posterior inference.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information-1","chapter":"4 Survival","heading":"4.23 How to incorporate prior information?","text":"Now three first years data, happened?Now three first years data, happened?Width credible interval 0.53 (vague prior) vs.¬†0.24 (informative prior).Width credible interval 0.53 (vague prior) vs.¬†0.24 (informative prior).Huge increase precision posterior inference, \\(120\\%\\) gain!Huge increase precision posterior inference, \\(120\\%\\) gain!","code":""},{"path":"survival.html","id":"compare-survival-posterior-with-and-without-informative-prior","chapter":"4 Survival","heading":"4.23.1 Compare survival posterior with and without informative prior","text":"","code":""},{"path":"survival.html","id":"prior-elicitation-via-moment-matching","chapter":"4 Survival","heading":"4.24 Prior elicitation via moment matching","text":"prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\) entirely satisfyingThe prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\) entirely satisfyingRemember Beta distributionRemember Beta distributionRecall Beta distribution continuous distribution values 0 1. Useful modelling survival detection probabilities.Recall Beta distribution continuous distribution values 0 1. Useful modelling survival detection probabilities.\\(X \\sim Beta(\\alpha,\\beta)\\), first second moments \\(X\\) :\\(X \\sim Beta(\\alpha,\\beta)\\), first second moments \\(X\\) :\\[\\mu = \\text{E}(X) = \\frac{\\alpha}{\\alpha + \\beta}\\]\\[\\sigma^2 = \\text{Var}(X) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\]","code":""},{"path":"survival.html","id":"moment-matching","chapter":"4 Survival","heading":"4.25 Moment matching","text":"capture-recapture example, know priori mean probability ‚Äôre interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\).capture-recapture example, know priori mean probability ‚Äôre interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\).Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution.Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution.Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\).Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\).need another set equations:need another set equations:\\[\\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2\\]\\[\\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg)\\]model, means:Now use \\(\\phi_{prior} \\sim \\text{Beta}(\\alpha = 25.6,\\beta = 19.3)\\) instead \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\)","code":"\n(alpha <- ( (1 - 0.57)/(0.073*0.073) - (1/0.57) )*0.57^2)\n## [1] 25.65\n(beta <- alpha * ( (1/0.57) - 1))\n## [1] 19.35"},{"path":"survival.html","id":"prior-predictive-checks","chapter":"4 Survival","heading":"4.26 Prior predictive checks","text":"","code":""},{"path":"survival.html","id":"linear-regression","chapter":"4 Survival","heading":"4.27 Linear regression","text":"Unreasonable prior \\(\\beta \\sim N(0, 1000^2)\\)Reasonable prior \\(\\beta \\sim N(2, 0.5^2)\\)","code":""},{"path":"survival.html","id":"logistic-regression","chapter":"4 Survival","heading":"4.28 Logistic regression","text":"Unreasonable prior \\(\\text{logit}(\\phi) = \\beta \\sim N(0, 10^2)\\)Reasonable prior \\(\\text{logit}(\\phi) = \\beta \\sim N(0, 1.5^2)\\)","code":""},{"path":"survival.html","id":"capture-recapture-models-rely-on-assumptions","chapter":"4 Survival","heading":"4.29 Capture-recapture models rely on assumptions","text":"Design\nmark lost\nIdentity individuals recorded without error (false positives)\nCaptured individuals random sample\nmark lostIdentity individuals recorded without error (false positives)Captured individuals random sampleModel\nHomogeneity survival recapture probabilities\nIndependence individuals (overdispersion)\nHomogeneity survival recapture probabilitiesIndependence individuals (overdispersion)Test validity assumptions\nassumptions valid, whatever inferential framework\nUse goodness--fit tests ‚Äî Pradel et al.¬†(2005)\nR implementation package R2ucare\nPosterior predictive checks can also used (covered; Gelman et al.¬†2020)\nassumptions valid, whatever inferential frameworkUse goodness--fit tests ‚Äî Pradel et al.¬†(2005)R implementation package R2ucarePosterior predictive checks can also used (covered; Gelman et al.¬†2020)","code":""},{"path":"survival.html","id":"parameter-redundancy-issue","chapter":"4 Survival","heading":"4.29.1 Parameter-redundancy issue","text":"Last survival recapture probabilities estimated separately.Last survival recapture probabilities estimated separately.Poor mixing chains.Poor mixing chains.","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-phi_4-and-phi_6","chapter":"4 Survival","heading":"4.30 Prior-posterior overlap for \\(\\phi_4\\) and \\(\\phi_6\\)","text":"","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-p_3-and-p_7","chapter":"4 Survival","heading":"4.31 Prior-posterior overlap for \\(p_3\\) and \\(p_7\\)","text":"","code":""},{"path":"survival.html","id":"what-does-survival-actually-mean-in-capture-recapture","chapter":"4 Survival","heading":"4.32 What does survival actually mean in capture-recapture ?","text":"Survival refers study area.Survival refers study area.Mortality permanent emigration confounded.Mortality permanent emigration confounded.Therefore estimate apparent survival, true survival.Therefore estimate apparent survival, true survival.Apparent survival probability = true survival √ó study area fidelity.Apparent survival probability = true survival √ó study area fidelity.Consequently, apparent survival < true survival unless study area fidelity = 1.Consequently, apparent survival < true survival unless study area fidelity = 1.Use caution interpretation. possible, combine ring-recovery data, go spatial get closer true survival.Use caution interpretation. possible, combine ring-recovery data, go spatial get closer true survival.","code":""},{"path":"survival.html","id":"further-reading-1","chapter":"4 Survival","heading":"4.33 Further reading","text":"CJS state-space formulation Gimenez et al.¬†(2007) Royle (2008).CJS state-space formulation Gimenez et al.¬†(2007) Royle (2008).Work missing values Bonner et al.¬†(2006) Langrock King (2013) Worthington et al.¬†(2015).Work missing values Bonner et al.¬†(2006) Langrock King (2013) Worthington et al.¬†(2015).example incorporate prior information McCarthy Masters (2005).example incorporate prior information McCarthy Masters (2005).Combine live recapture w/ dead recoveries Lebreton et al.¬†(1999) go spatial account emigration Gilroy et al.¬†(2012) Schaub & Royle (2014).Combine live recapture w/ dead recoveries Lebreton et al.¬†(1999) go spatial account emigration Gilroy et al.¬†(2012) Schaub & Royle (2014).Non-identifiability Bayesian framework, see Gimenez et al.¬†(2009) book Cole (2020).Non-identifiability Bayesian framework, see Gimenez et al.¬†(2009) book Cole (2020).","code":""},{"path":"transition.html","id":"transition","chapter":"5 Transition","heading":"5 Transition","text":"Thank Canada!","code":"\nknitr::include_graphics(\"images/arnason1973.png\")\nknitr::include_graphics(\"images/schwarz1993.png\")\nknitr::include_graphics(\"images/deadpool.gif\")\nknitr::include_graphics(\"images/nichols.png\")"},{"path":"transition.html","id":"wintering-site-fidelity-in-canada-geese","chapter":"5 Transition","heading":"5.1 Wintering site fidelity in Canada Geese","text":"","code":""},{"path":"transition.html","id":"sites-carolinas-chesapeake-mid-atlantic","chapter":"5 Transition","heading":"5.1.1 3 sites Carolinas, Chesapeake, Mid-Atlantic,","text":"21277 banded geese, data kindly provided Jay Hestbeck (Hestbeck et al.¬†1991)(large areas along East coast US)","code":""},{"path":"transition.html","id":"biological-inference","chapter":"5 Transition","heading":"5.1.2 Biological inference","text":"Observations states closely related, entirely.","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.","chapter":"5 Transition","heading":"5.1.3 The model construction: How we should think.","text":"Generative model. States generate observations.","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-1","chapter":"5 Transition","heading":"5.1.4 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-2","chapter":"5 Transition","heading":"5.1.5 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"the-model-construction-how-we-should-think.-3","chapter":"5 Transition","heading":"5.1.6 The model construction: How we should think.","text":"","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas","chapter":"5 Transition","heading":"5.1.7 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_{t}=& z_{t}=B & z_{t}=D \\\\ \\hdashline\n\\phi_A (1-\\psi_{AB}) & \\phi_A \\psi_{AB} & 1 - \\phi_A\\\\ \n\\phi_B \\psi_{BA} & \\phi_B (1-\\psi_{BA}) & 1 - \\phi_B\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-1","chapter":"5 Transition","heading":"5.1.8 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-2","chapter":"5 Transition","heading":"5.1.9 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: may code non-detections \\(y_t = 2\\), first column observation matrix go last.Quick answer -1 important issue coding states obs. purpose, folks think difference observations states (non-detection obs confused state dead). becomes even crucial get multievent models several observations may generated single state. get intuition argument perfectly, ‚Äôd like fight first, ‚Äôre comfortable difference, may code obs/states see fit. Let‚Äôs see goes. agree mention multistate lecture, spirit ¬´ ‚Äôre free code states jobs way like ¬ª. ‚Äôll add something.","code":""},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b","chapter":"5 Transition","heading":"5.1.10 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiA: survival probability site A\n  # phiB: survival probability site B\n  # psiAB: movement probability from site A to site B\n  # psiBA: movement probability from site B to site A\n  # pA: recapture probability site A\n  # pB: recapture probability site B\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at A\n  # 2 alive at B\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen at A \n  # 3 seen at B\n  # -------------------------------------------------\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1","chapter":"5 Transition","heading":"5.1.11 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...\n  # Priors\n  phiA ~ dunif(0, 1)\n  phiB ~ dunif(0, 1)\n  psiAB ~ dunif(0, 1)\n  psiBA ~ dunif(0, 1)\n  pA ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2","chapter":"5 Transition","heading":"5.1.12 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"Actually, initial state known exactly. alive site initial capture, \\(\\pi_A\\) just proportion individuals first captured site , need estimate .Actually, initial state known exactly. alive site initial capture, \\(\\pi_A\\) just proportion individuals first captured site , need estimate .Instead z[,first[]] ~ dcat(delta[1:3]), use z[,first[]] <- y[,first[]]-1 instead likelihood.Instead z[,first[]] ~ dcat(delta[1:3]), use z[,first[]] <- y[,first[]]-1 instead likelihood.trick applies CJS models.trick applies CJS models.","code":"multisite <- nimbleCode({\n...  \n  # initial state probabilities\n  delta[1] <- piA          # Pr(alive in A t = 1)\n  delta[2] <- 1 - piA      # Pr(alive in B t = 1)\n  delta[3] <- 0            # Pr(dead t = 1) = 0\n...  "},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3","chapter":"5 Transition","heading":"5.1.13 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  # (read as gamma[z(t),z(t+1)] = gamma[fromState,toState])\n  \n  gamma[1,1] <- phiA * (1 - psiAB)\n  gamma[1,2] <- phiA * psiAB\n  gamma[1,3] <- 1 - phiA\n  gamma[2,1] <- phiB * psiBA\n  gamma[2,2] <- phiB * (1 - psiBA)\n  gamma[2,3] <- 1 - phiB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...  "},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4","chapter":"5 Transition","heading":"5.1.14 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  # (read as omega[y(t),z(t)] = omega[Observation,State])\n\n  omega[1,1] <- 1 - pA     # Pr(alive A t -> non-detected t)\n  omega[1,2] <- pA         # Pr(alive A t -> detected A t)\n  omega[1,3] <- 0          # Pr(alive A t -> detected B t)\n  omega[2,1] <- 1 - pB     # Pr(alive B t -> non-detected t)\n  omega[2,2] <- 0          # Pr(alive B t -> detected A t)\n  omega[2,3] <- pB         # Pr(alive B t -> detected B t)\n  omega[3,1] <- 1          # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0          # Pr(dead t -> detected A t)\n  omega[3,3] <- 0          # Pr(dead t -> detected B t)\n..."},{"path":"transition.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5","chapter":"5 Transition","heading":"5.1.15 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"\nmultisite <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA    0.53 0.09 0.36 0.52  0.73 1.04   122\n## pB    0.40 0.04 0.32 0.40  0.48 1.07   165\n## phiA  0.60 0.05 0.50 0.60  0.71 1.01   195\n## phiB  0.69 0.04 0.62 0.69  0.76 1.04   199\n## psiAB 0.27 0.06 0.16 0.26  0.40 1.04   244\n## psiBA 0.07 0.02 0.04 0.07  0.12 1.03   360"},{"path":"transition.html","id":"what-if-there-are-three-sites","chapter":"5 Transition","heading":"5.2 What if there are three sites?","text":"transition probabilities still need 0 1.transition probabilities still need 0 1.Another constraint sum three probabilities departure given site one.Another constraint sum three probabilities departure given site one.Two methods fulfill constraints.\nDirichlet prior\nMultinomial logit link\nTwo methods fulfill constraints.Dirichlet priorMultinomial logit linkDirichlet prior parameter alpha\nFigure 5.1: Dirichlet prior parameter alpha\n","code":""},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior","chapter":"5 Transition","heading":"5.2.1 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: Dirichlet priors\n  psiA[1:3] ~ ddirch(alpha[1:3]) # psiAA, psiAB, psiAC\n  psiB[1:3] ~ ddirch(alpha[1:3]) # psiBA, psiBB, psiCC\n  psiC[1:3] ~ ddirch(alpha[1:3]) # psiCA, psiCB, psiCC\n..."},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-1","chapter":"5 Transition","heading":"5.2.2 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.50 0.09 0.34 0.50  0.70 1.00   153\n## pB      0.47 0.05 0.38 0.46  0.58 1.01   152\n## pC      0.24 0.06 0.14 0.23  0.37 1.01   117\n## phiA    0.61 0.05 0.50 0.61  0.71 1.00   230\n## phiB    0.70 0.04 0.62 0.70  0.77 1.04   183\n## phiC    0.77 0.07 0.64 0.77  0.92 1.07   104\n## psiA[1] 0.75 0.05 0.63 0.75  0.84 1.01   463\n## psiA[2] 0.23 0.05 0.14 0.22  0.34 1.01   441\n## psiA[3] 0.02 0.02 0.00 0.02  0.08 1.03   201\n## psiB[1] 0.07 0.02 0.04 0.07  0.12 1.00   275\n## psiB[2] 0.83 0.04 0.72 0.83  0.90 1.04   129\n## psiB[3] 0.10 0.04 0.04 0.09  0.18 1.06   129\n## psiC[1] 0.02 0.01 0.00 0.02  0.06 1.00   624\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.02   420\n## psiC[3] 0.77 0.06 0.64 0.77  0.86 1.02   419"},{"path":"transition.html","id":"multinomial-logit","chapter":"5 Transition","heading":"5.2.3 Multinomial logit","text":"Say \\(P\\) sites states.Say \\(P\\) sites states.Specify normal prior distribution \\(P-1\\) transition parameters \\(\\alpha_j\\). probabilities multinomial logit scale, possibly function covariates.Specify normal prior distribution \\(P-1\\) transition parameters \\(\\alpha_j\\). probabilities multinomial logit scale, possibly function covariates.back-transform parameters, use:back-transform parameters, use:\\[\\beta_j = \\displaystyle{\\frac{\\exp(\\alpha_j)}{1+\\displaystyle{\\sum_{p=1}^P{\\exp(\\alpha_p)}}}}, j = 1,\\ldots,P-1\\]ensures \\(\\beta_j\\) 0 1, sum 1.ensures \\(\\beta_j\\) 0 1, sum 1.Last parameter calculated complement \\(\\beta_P = 1 - \\displaystyle{\\sum_{j=1}^{P-1}{\\exp(\\beta_j)}}\\)Last parameter calculated complement \\(\\beta_P = 1 - \\displaystyle{\\sum_{j=1}^{P-1}{\\exp(\\beta_j)}}\\)","code":""},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-2","chapter":"5 Transition","heading":"5.2.4 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: multinomial logit\n  # normal priors on logit of all but one transition probs\n  for (i in 1:2){\n    lpsiA[i] ~ dnorm(0, sd = 1000)\n    lpsiB[i] ~ dnorm(0, sd = 1000)\n    lpsiC[i] ~ dnorm(0, sd = 1000)\n  }\n  # constrain the transitions such that their sum is < 1\n  for (i in 1:2){\n    psiA[i] <- exp(lpsiA[i]) / (1 + exp(lpsiA[1]) + exp(lpsiA[2]))\n    psiB[i] <- exp(lpsiB[i]) / (1 + exp(lpsiB[1]) + exp(lpsiB[2]))\n    psiC[i] <- exp(lpsiC[i]) / (1 + exp(lpsiC[1]) + exp(lpsiC[2]))\n  }\n  # last transition probability\n  psiA[3] <- 1 - psiA[1] - psiA[2]\n  psiB[3] <- 1 - psiB[1] - psiB[2]\n  psiC[3] <- 1 - psiC[1] - psiC[2]\n..."},{"path":"transition.html","id":"nimble-implementation-of-the-dirichlet-prior-3","chapter":"5 Transition","heading":"5.2.5 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.52 0.08 0.36 0.52  0.69 1.02   154\n## pB      0.45 0.05 0.35 0.44  0.55 1.10   129\n## pC      0.26 0.06 0.15 0.25  0.39 1.01    94\n## phiA    0.60 0.05 0.50 0.60  0.71 1.01   244\n## phiB    0.70 0.04 0.63 0.70  0.77 1.11   168\n## phiC    0.76 0.07 0.63 0.76  0.88 1.03   126\n## psiA[1] 0.76 0.05 0.64 0.76  0.85 1.02   477\n## psiA[2] 0.24 0.05 0.15 0.24  0.36 1.01   486\n## psiA[3] 0.00 0.00 0.00 0.00  0.00 1.35    47\n## psiB[1] 0.07 0.02 0.04 0.06  0.11 1.03   394\n## psiB[2] 0.85 0.04 0.77 0.86  0.91 1.04   133\n## psiB[3] 0.08 0.03 0.04 0.08  0.16 1.01    79\n## psiC[1] 0.01 0.01 0.00 0.01  0.04 1.00   514\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.00   299\n## psiC[3] 0.78 0.06 0.65 0.78  0.88 1.00   270"},{"path":"transition.html","id":"sites-may-be-states.","chapter":"5 Transition","heading":"5.3 Sites may be states.","text":"","code":""},{"path":"transition.html","id":"examples-of-multistate-models","chapter":"5 Transition","heading":"5.4 Examples of multistate models","text":"Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Morphological states: small/medium/big, light/medium/heavy.Morphological states: small/medium/big, light/medium/heavy.Breeding states: e.g.¬†breeder/non-breeder, failed breeder, first-time breeder.Breeding states: e.g.¬†breeder/non-breeder, failed breeder, first-time breeder.Developmental life-history states: e.g.¬†juvenile/subadult/adult.Developmental life-history states: e.g.¬†juvenile/subadult/adult.Social states: e.g.¬†solitary/group-living, subordinate/dominant.Social states: e.g.¬†solitary/group-living, subordinate/dominant.Death states: e.g.¬†alive, dead harvest, dead natural causes.Death states: e.g.¬†alive, dead harvest, dead natural causes.States = individual, time-specific categorical covariates.","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"transition.html","id":"sooty-shearwater-david-boyle","chapter":"5 Transition","heading":"5.4.1 Sooty shearwater (David Boyle)","text":"","code":""},{"path":"transition.html","id":"sooty-shearwaters-and-life-history-tradeoffs","chapter":"5 Transition","heading":"5.5 Sooty shearwaters and life-history tradeoffs","text":"consider data collected 1940 1957 Lance Richdale Sooty shearwaters (aka titis).consider data collected 1940 1957 Lance Richdale Sooty shearwaters (aka titis).data reanalyzed multistate models Scofield et al.¬†(2001) kindly provided us data.data reanalyzed multistate models Scofield et al.¬†(2001) kindly provided us data.Following way data collected, four states originally considered:\nAlive breeder;\nAccompanied another bird burrow;\nAlone burrow;\nsurface;\nDead.\nFollowing way data collected, four states originally considered:Alive breeder;Accompanied another bird burrow;Alone burrow;surface;Dead.","code":""},{"path":"transition.html","id":"sooty-shearwaters-and-life-history-tradeoffs-1","chapter":"5 Transition","heading":"5.6 Sooty shearwaters and life-history tradeoffs","text":"numerical issues, pooled alive states breeder together non-breeder state (NB) includes:\nfailed breeders (birds bred previously ‚Äì skip reproduction divorce) pre-breeders (birds yet breed).\nNote burrows checked hatching, birds category NB might already failed.\ntherefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.\nnumerical issues, pooled alive states breeder together non-breeder state (NB) includes:failed breeders (birds bred previously ‚Äì skip reproduction divorce) pre-breeders (birds yet breed).failed breeders (birds bred previously ‚Äì skip reproduction divorce) pre-breeders (birds yet breed).Note burrows checked hatching, birds category NB might already failed.Note burrows checked hatching, birds category NB might already failed.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.Observations non-detections, detections breeder non-breederObservations non-detections, detections breeder non-breederDoes breeding affect survival? breeding current year affect breeding next year?breeding affect survival? breeding current year affect breeding next year?","code":""},{"path":"transition.html","id":"hmm-model-for-transition-between-states","chapter":"5 Transition","heading":"5.6.1 HMM model for transition between states","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\ \n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Costs reproduction reflect future reproduction \\(\\psi_{BB} = 1 - \\psi_{BNB} < \\psi_{NBB}\\) survival \\(\\phi_B < \\phi_{NB}\\).","code":""},{"path":"transition.html","id":"hmm-model-for-transition-between-states-1","chapter":"5 Transition","heading":"5.6.2 HMM model for transition between states","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_B & p_B & 0\\\\ \n1 - p_{NB} & 0 & p_{NB}\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b","chapter":"5 Transition","heading":"5.6.3 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen as B \n  # 3 seen as NB\n  # -------------------------------------------------\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1","chapter":"5 Transition","heading":"5.6.4 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2","chapter":"5 Transition","heading":"5.6.5 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...  "},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3","chapter":"5 Transition","heading":"5.6.6 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB    # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB        # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0         # Pr(alive B t -> detected NB t)\n  omega[2,1] <- 1 - pNB   # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0         # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB       # Pr(alive NB t -> detected NB t)\n  omega[3,1] <- 1         # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0         # Pr(dead t -> detected N t)\n  omega[3,3] <- 0         # Pr(dead t -> detected NB t)\n..."},{"path":"transition.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4","chapter":"5 Transition","heading":"5.6.7 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"\nFigure 5.2: Dirichlet prior parameter alpha\n","code":"\nmultistate <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pB     0.60 0.03 0.54 0.59  0.66 1.00   202\n## pNB    0.57 0.03 0.51 0.57  0.62 1.01   281\n## phiB   0.80 0.02 0.77 0.80  0.83 1.01   313\n## phiNB  0.85 0.02 0.82 0.85  0.88 1.00   404\n## psiBNB 0.25 0.02 0.21 0.25  0.30 1.00   434\n## psiNBB 0.24 0.02 0.20 0.24  0.29 1.03   478"},{"path":"transition.html","id":"multistate-models-are-very-flexible","chapter":"5 Transition","heading":"5.7 Multistate models are very flexible","text":"Access reproductionAccess reproductionTemporary emigrationTemporary emigrationCombination life dead encountersCombination life dead encounters","code":""},{"path":"transition.html","id":"access-to-reproduction","chapter":"5 Transition","heading":"5.7.1 Access to reproduction","text":"Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=J & z_t=1yNB & z_t=2yNB & z_t=B & z_t=D \\\\ \\hdashline\n0 & \\phi_1 (1-\\alpha_1) & 0 & \\phi_1 \\alpha_1 & 1 - \\phi_1\\\\ \n0 & 0 & \\phi_2 (1-\\alpha_2) & \\phi_2 \\alpha_2 & 1 - \\phi_2\\\\ \n0 & 0 & 0 & \\phi_3 & 1 - \\phi_3\\\\ \n0 & 0 & 0 & \\phi_B & 1 - \\phi_B\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1} = J \\\\ z_{t-1} = 1yNB \\\\ z_{t-1} = 2yNB \\\\ z_{t-1} = B \\\\ z_{t-1} = D\n    \\end{matrix}\n\\end{matrix}\n\\]First-year second-year individuals breed probabilities \\(\\alpha_1\\) \\(\\alpha_2\\).First-year second-year individuals breed probabilities \\(\\alpha_1\\) \\(\\alpha_2\\)., everybody breeds age 3., everybody breeds age 3.","code":""},{"path":"transition.html","id":"access-to-reproduction-1","chapter":"5 Transition","heading":"5.7.2 Access to reproduction","text":"Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t = 0 & y_t = 1 & y_t = 2 & y_t = 3\\\\ \\hdashline\n1 & 0 & 0 & 0\\\\\n1 - p_1 & p_1 & 0 & 0\\\\ \n1 - p_2 & 0 & p_2 & 0\\\\ \n1 - p_3 & 0 & 0 & p_3\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t = J \\\\ z_t = 1yNB \\\\ z_t = 2yNB \\\\ z_t = B \\\\ z_t = D\n    \\end{matrix}\n\\end{matrix}\n\\]Juveniles never detected.","code":""},{"path":"transition.html","id":"temporary-emigration","chapter":"5 Transition","heading":"5.8 Temporary emigration","text":"Transition matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=\\text{} & z_t=\\text{} & z_t=\\text{D} \\\\ \\hdashline\n\\phi (1-\\psi_{\\text{} \\rightarrow \\text{}}) & \\phi \\psi_{\\text{} \\rightarrow \\text{}} & 1 - \\phi\\\\ \n\\phi \\psi_{\\text{} \\rightarrow \\text{}} & \\phi (1-\\psi_{\\text{} \\rightarrow \\text{}}) & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\text{} \\\\ z_{t-1}=\\text{} \\\\ z_{t-1}=\\text{D}\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 \\\\ \\hdashline\n1 - p & p\\\\ \n1 & 0\\\\\n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\text{} \\\\ z_{t}=\\text{} \\\\ z_{t}=\\text{D}\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"combination-of-life-and-dead-encounters","chapter":"5 Transition","heading":"5.8.1 Combination of life and dead encounters","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=JD & z_t=D \\\\ \\hdashline\ns & 1-s & 0\\\\ \n0 & 0 & 1\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\text{alive} \\\\ z_{t-1}=\\text{just dead} \\\\ z_{t-1}=\\text{dead good}\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p & 0 & p\\\\ \n1 - r & r & 0\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=JD \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"transition.html","id":"issue-of-local-minima","chapter":"5 Transition","heading":"5.9 Issue of local minima","text":"Simulated data\n2 sites states, 7 occasions\nSurvival \\(\\phi = 1\\), detection \\(p = 0.6\\)\nTransition \\(\\psi_{12} = 0.6\\)\nTransition \\(\\psi_{21} = 0.85\\)\n2 sites states, 7 occasionsSurvival \\(\\phi = 1\\), detection \\(p = 0.6\\)Transition \\(\\psi_{12} = 0.6\\)Transition \\(\\psi_{21} = 0.85\\)Courtesy J√©r√¥me Dupuis, used Gimenez et al.¬†(2005).","code":""},{"path":"transition.html","id":"data-1","chapter":"5 Transition","heading":"5.9.1 Data","text":"","code":"\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_05.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_06.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_07.png\")"},{"path":"transition.html","id":"further-reading-2","chapter":"5 Transition","heading":"5.10 Further reading","text":"Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel J. . Spendelow (2009). Modeling Individual Animal Histories Multistate Capture‚ÄìRecapture Models. Advances Ecological Research, 41:87-173.","code":""},{"path":"covariates.html","id":"covariates","chapter":"6 Covariates","heading":"6 Covariates","text":"","code":""},{"path":"uncertainty.html","id":"uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7 Uncertainty in state assignment","text":"Multievent models extend multistate models uncertainty state assignmentIn module, ‚Äôre going talk multievent models.module, ‚Äôre going talk multievent models.Multievent models extend multistate models uncertainty state assignment.Multievent models extend multistate models uncertainty state assignment.Let‚Äôs see examples fix ideas.Let‚Äôs see examples fix ideas.examples published papers used multievent models.examples published papers used multievent models.Breeding status female roe deer ascertained based fawn detectionBreeding status female roe deer ascertained based fawn detectionSex status ascertained based morphological criteria Audouin‚Äôs gullsSex status ascertained based morphological criteria Audouin‚Äôs gullsDisease status house finches ascertained based birds‚Äô eyes examinationDisease status house finches ascertained based birds‚Äô eyes examinationHybrid status wolves ascertained based geneticsHybrid status wolves ascertained based geneticsDominance status wolves ascertained based heterogeneity detectionDominance status wolves ascertained based heterogeneity detectionWe need explicitly consider state assignment modelThe common thing examples .need explicitly consider state assignment model.HMMs rescue!, ‚Äôll use HMMs !","code":""},{"path":"uncertainty.html","id":"examples","chapter":"7 Uncertainty in state assignment","heading":"7.1 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionIn module, ‚Äôll go 3 examples.module, ‚Äôll go 3 examples.Testing life-history trade-offs accounting uncertainty breeding status.Testing life-history trade-offs accounting uncertainty breeding status.Quantifying disease dynamics accounting uncertainty disease status.Quantifying disease dynamics accounting uncertainty disease status.Estimating survival accounting individual heterogeneity detection.Estimating survival accounting individual heterogeneity detection.","code":""},{"path":"uncertainty.html","id":"examples-1","chapter":"7 Uncertainty in state assignment","heading":"7.2 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detection","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"uncertainty.html","id":"sooty-shearwater-david-boyle-1","chapter":"7 Uncertainty in state assignment","heading":"7.2.1 Sooty shearwater (David Boyle)","text":"","code":""},{"path":"uncertainty.html","id":"uncertainty-in-breeding-status","chapter":"7 Uncertainty in state assignment","heading":"7.3 Uncertainty in breeding status","text":"3 states\nbreeding (B)\nnon-breeding (NB)\ndead (D)\nbreeding (B)non-breeding (NB)dead (D)4 observations\nencountered (0)\nfound, ascertained breeder (1)\nfound, ascertained non-breeder (2)\nfound, status unknown (3)\nencountered (0)found, ascertained breeder (1)found, ascertained non-breeder (2)found, status unknown (3)still 3 states, breeding, non-breeding dead.regard observations, bird may encountered.may also encountered, contrast multistate CR data, don‚Äôt know state sure.may found ascertained classified breeder.may found ascertained classified non-breeder.may found unable determine whether ‚Äôs breeding non-breeding.","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations","chapter":"7 Uncertainty in state assignment","heading":"7.3.1 How states generate observations","text":"Now states generate observations?","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.2 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.3 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.4 How states generate observations","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations-4","chapter":"7 Uncertainty in state assignment","heading":"7.3.5 How states generate observations","text":"wrap live state can generate 3 observations.deterministic link dead state observation non-encountered.Cause ‚Äôre dead, detected sure.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7.3.6 HMM model for breeding states with uncertainty","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\pi_B & 1 - \\pi_{B} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\pi_B\\) probability newly encountered individual breeder\\(\\pi_{NB} = 1 - \\pi_B\\) probability newly encountered individual non-breeder\\(\\pi_{NB} = 1 - \\pi_B\\) probability newly encountered individual non-breederOK now let‚Äôs specify model.OK now let‚Äôs specify model.First thing need, ‚Äôs big difference multistate models, need initial state probabilities cause assign states individuals w/ certainty.First thing need, ‚Äôs big difference multistate models, need initial state probabilities cause assign states individuals w/ certainty.Let‚Äôs define pi_B prob newly encountered individual breeding individual.Let‚Äôs define pi_B prob newly encountered individual breeding individual.write prob state first encounter. pi_B, prob NB complementary. prob dead first encounter 0 course.write prob state first encounter. pi_B, prob NB complementary. prob dead first encounter 0 course.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.7 HMM model for breeding states with uncertainty","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\ \n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi_B\\) breeder survival, \\(\\phi_{NB}\\) non-breeders.\\(\\phi_B\\) breeder survival, \\(\\phi_{NB}\\) non-breeders.\\(\\psi_{BNB}\\) probability individual breeding year non-breeder next year.\\(\\psi_{BNB}\\) probability individual breeding year non-breeder next year.\\(\\psi_{NBB}\\) probability non-breeder individual breeder next year.\\(\\psi_{NBB}\\) probability non-breeder individual breeder next year.transition parameters matrix similar one used multistate models.transition parameters matrix similar one used multistate models.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.8 HMM model for breeding states with uncertainty","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n1 - p_B & p_B \\beta_B & 0 & p_B (1-\\beta_B) \\\\ \n1-p_{NB} & 0 & p_{NB} \\beta_{NB} & p_{NB} (1-\\beta_{NB})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\beta_B\\) probability assign individual state B state B.\\(\\beta_B\\) probability assign individual state B state B.\\(\\beta_{NB}\\) probability assign individual state NB state NB.\\(\\beta_{NB}\\) probability assign individual state NB state NB.\\(p_B\\) detection probability breeders, \\(p_{NB}\\) non-breeders.\\(p_B\\) detection probability breeders, \\(p_{NB}\\) non-breeders.main difference multistate multievent models , observation parameters.main difference multistate multievent models , observation parameters.introduce two new parameters.introduce two new parameters.deltaB: prob. correctly assign indiv. state B state BdeltaB: prob. correctly assign indiv. state B state BdeltaNB: prob. correctly assign indiv. state NB state NBdeltaNB: prob. correctly assign indiv. state NB state NBWe put everything matrix, usual. observation matrix.put everything matrix, usual. observation matrix.rows states, breeding, non-breeding dead.rows states, breeding, non-breeding dead.columns, occasion, observation, detected ascertained B,\ndetected ascertained NB, detected state unknown, detected.columns, occasion, observation, detected ascertained B,\ndetected ascertained NB, detected state unknown, detected.example, prob detected assigned state B, given ‚Äôre state B product detection prob B delta prob correctly assigning B individual state B.example, prob detected assigned state B, given ‚Äôre state B product detection prob B delta prob correctly assigning B individual state B.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-breeding-states-with-uncertainty-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.9 HMM model for breeding states with uncertainty","text":"animals captured, \\(p_B = p_{NB} = 1\\) first encounter:\\[\n\\begin{matrix}\n& \\\\\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n 0 & \\beta_B & 0 & (1-\\beta_B)\\\\ \n0 & 0 & \\beta_{NB} & (1-\\beta_{NB})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: Breeding assessment unaffected.first encounter, happens step 1 encounter degenerate individuals captured. Just set p‚Äôs 1 encounter matrix.first encounter, happens step 1 encounter degenerate individuals captured. Just set p‚Äôs 1 encounter matrix.breeding assessment matrix remains unchanged.breeding assessment matrix remains unchanged.","code":""},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi","chapter":"7 Uncertainty in state assignment","heading":"7.3.10 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # piB prob. of being in initial state breeder\n  # betaNB prob to ascertain the breeding status of an individual encountered as non-breeder\n  # betaB prob to ascertain the breeding status of an individual encountered as breeder\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):  \n  # 1 = non-detected\n  # 2 = seen and ascertained as breeder\n  # 3 = seen and ascertained as non-breeder\n  # 4 = not ascertained\n  # -------------------------------------------------\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-1","chapter":"7 Uncertainty in state assignment","heading":"7.3.11 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"]","code":"multievent <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n  piB ~ dunif(0, 1)\n  betaNB ~ dunif(0, 1)\n  betaB ~ dunif(0, 1)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-2","chapter":"7 Uncertainty in state assignment","heading":"7.3.12 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # vector of initial stats probs\n  delta[1] <- piB # prob. of being in initial state B\n  delta[2] <- 1 - piB # prob. of being in initial state NB\n  delta[3] <- 0 # prob. of being in initial state dead\n...  "},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-3","chapter":"7 Uncertainty in state assignment","heading":"7.3.13 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-4","chapter":"7 Uncertainty in state assignment","heading":"7.3.14 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0                  # Pr(alive B t -> detected NB t)\n  omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t)\n  omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0                  # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t)\n  omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t)\n  omega[3,1] <- 1                  # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0                  # Pr(dead t -> detected N t)\n  omega[3,3] <- 0                  # Pr(dead t -> detected NB t)\n  omega[3,4] <- 0                  # Pr(dead t -> detected U t)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-5","chapter":"7 Uncertainty in state assignment","heading":"7.3.15 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"multievent <- nimbleCode({\n...  \n  # probabilities of y(first) given z(first)\n  omega.init[1,1] <- 0          # Pr(alive B t = 1 -> non-detected t = 1)\n  omega.init[1,2] <- betaB      # Pr(alive B t = 1 -> detected B t = 1)\n  omega.init[1,3] <- 0          # Pr(alive B t = 1 -> detected NB t = 1)\n  omega.init[1,4] <- 1 - betaB  # Pr(alive B t = 1 -> detected U t = 1)\n  omega.init[2,1] <- 0          # Pr(alive NB t = 1 -> non-detected t = 1)\n  omega.init[2,2] <- 0          # Pr(alive NB t = 1 -> detected B t = 1)\n  omega.init[2,3] <- betaNB     # Pr(alive NB t = 1 -> detected NB t = 1)\n  omega.init[2,4] <- 1 - betaNB # Pr(alive NB t = 1 -> detected U t = 1)\n  omega.init[3,1] <- 1          # Pr(dead t = 1 -> non-detected t = 1)\n  omega.init[3,2] <- 0          # Pr(dead t = 1 -> detected N t = 1)\n  omega.init[3,3] <- 0          # Pr(dead t = 1 -> detected NB t = 1)\n  omega.init[3,4] <- 0          # Pr(dead t = 1 -> detected U t = 1)\n..."},{"path":"uncertainty.html","id":"our-model-phi_b-phi_nb-psi_bnb-psi_nbb-p_b-p_nb-beta_b-beta_nb-pi-6","chapter":"7 Uncertainty in state assignment","heading":"7.3.16 Our model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","text":"","code":"\nmultievent <- nimbleCode({\n...\n  # likelihood \n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] ~ dcat(delta[1:3])\n    y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4])\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:4])\n    }\n  }\n})"},{"path":"uncertainty.html","id":"results","chapter":"7 Uncertainty in state assignment","heading":"7.4 Results","text":"Breeders difficult assigned correct state.Non-breeders relatively well classified non-breeders.cost breeding, neither survival, future reproduction.","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaB  0.19 0.01 0.16 0.19  0.21 1.01   332\n## betaNB 0.76 0.05 0.66 0.76  0.86 1.01    65\n## pB     0.56 0.03 0.51 0.56  0.62 1.06   229\n## pNB    0.60 0.04 0.53 0.60  0.67 1.03   142\n## phiB   0.81 0.02 0.78 0.81  0.85 1.01   312\n## phiNB  0.84 0.02 0.80 0.84  0.87 1.00   354\n## piB    0.71 0.03 0.66 0.71  0.76 1.02   115\n## psiBNB 0.23 0.02 0.18 0.22  0.27 1.00   214\n## psiNBB 0.25 0.04 0.17 0.25  0.34 1.00    95"},{"path":"uncertainty.html","id":"examples-2","chapter":"7 Uncertainty in state assignment","heading":"7.5 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionLet‚Äôs look another example.Let‚Äôs look another example.similar previous example.similar previous example.","code":""},{"path":"uncertainty.html","id":"animal-epidemiology-with-uncertain-disease-states","chapter":"7 Uncertainty in state assignment","heading":"7.6 Animal epidemiology with uncertain disease states","text":"consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus M√ºller.","code":"\nknitr::include_graphics(\"images/infectedhousefinch.jpg\")"},{"path":"uncertainty.html","id":"a-house-finch-with-a-heavy-infection-jim-mondok.","chapter":"7 Uncertainty in state assignment","heading":"7.6.1 A house finch with a heavy infection (Jim Mondok).","text":"","code":""},{"path":"uncertainty.html","id":"animal-epidemiology-with-uncertain-disease-states-1","chapter":"7 Uncertainty in state assignment","heading":"7.7 Animal epidemiology with uncertain disease states","text":"consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus M√ºller.consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus M√ºller.Faustino et al.¬†(2004) Conn & Cooch (2009) studied impact pathogen host demographic rates.Faustino et al.¬†(2004) Conn & Cooch (2009) studied impact pathogen host demographic rates.Problem true disease state encountered individuals ambiguous seen distance.Problem true disease state encountered individuals ambiguous seen distance.context, study dynamics disease?context, study dynamics disease?","code":""},{"path":"uncertainty.html","id":"states-and-observations","chapter":"7 Uncertainty in state assignment","heading":"7.8 States and observations","text":"3 states\nhealthy (H)\nill ()\ndead (D)\nhealthy (H)ill ()dead (D)4 observations\nseen (0)\ncaptured healthy (1)\ncaptured ill (2)\nhealth status unknown, .e.¬†seen distance (3)\nseen (0)captured healthy (1)captured ill (2)health status unknown, .e.¬†seen distance (3)","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.","chapter":"7 Uncertainty in state assignment","heading":"7.8.1 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.2 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-2","chapter":"7 Uncertainty in state assignment","heading":"7.8.3 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-3","chapter":"7 Uncertainty in state assignment","heading":"7.8.4 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"how-states-generate-observations.-4","chapter":"7 Uncertainty in state assignment","heading":"7.8.5 How states generate observations.","text":"","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty","chapter":"7 Uncertainty in state assignment","heading":"7.8.6 HMM model for disease states with uncertainty","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\pi_H & 1 - \\pi_{H} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\pi_H\\) probability newly encountered individual healthy.\\(\\pi_H\\) probability newly encountered individual healthy.\\(\\pi_{} = 1 - \\pi_H\\) probability newly encountered individual ill.\\(\\pi_{} = 1 - \\pi_H\\) probability newly encountered individual ill.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.7 HMM model for disease states with uncertainty","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\phi_H (1-\\psi_{HI}) & \\phi_H \\psi_{HI} & 1 - \\phi_H\\\\ \n\\phi_{} \\psi_{IH} & \\phi_{} (1-\\psi_{IH}) & 1 - \\phi_{}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi_H\\) survival probability healthy individuals, \\(\\phi_I\\) ill individuals.\\(\\phi_H\\) survival probability healthy individuals, \\(\\phi_I\\) ill individuals.\\(\\psi_{HI}\\) probability getting sick, \\(\\psi_{IH}\\) recovering disease.\\(\\psi_{HI}\\) probability getting sick, \\(\\psi_{IH}\\) recovering disease.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-2","chapter":"7 Uncertainty in state assignment","heading":"7.8.8 HMM model for disease states with uncertainty","text":"Transition matrix, incurable disease\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\ \\hdashline\n\\phi_H (1-\\psi_{HI}) & \\phi_H \\psi_{HI} & 1 - \\phi_H\\\\ \n0 & \\phi_{}  & 1 - \\phi_{}\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]possibility recovering disease, \\(\\psi_{IH} = 0\\). get sick, remain sick \\(\\psi_{II} = 1 - \\psi_{IH} = 1\\).possibility recovering disease, \\(\\psi_{IH} = 0\\). get sick, remain sick \\(\\psi_{II} = 1 - \\psi_{IH} = 1\\).analysing house finch data, allow recovering disease, use transition matrix previous slide.analysing house finch data, allow recovering disease, use transition matrix previous slide.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-disease-states-with-uncertainty-3","chapter":"7 Uncertainty in state assignment","heading":"7.8.9 HMM model for disease states with uncertainty","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n1-p_H & p_H \\beta_H & 0 & p_H (1-\\beta_H)\\\\ \n1-p_I & 0 & p_{} \\beta_{} & p_{} (1-\\beta_{})\\\\ \n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=H \\\\ z_{t}=\\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\beta_H\\) probability assign healthy individual state H.\\(\\beta_H\\) probability assign healthy individual state H.\\(\\beta_{}\\) probability assign sick individual state .\\(\\beta_{}\\) probability assign sick individual state .\\(p_H\\) detection probability healthy individuals, \\(p_I\\) sick individuals.\\(p_H\\) detection probability healthy individuals, \\(p_I\\) sick individuals.","code":""},{"path":"uncertainty.html","id":"results-1","chapter":"7 Uncertainty in state assignment","heading":"7.8.10 Results","text":"Healthy individuals correctly assigned, infected individuals difficult ascertain.Sounds like infected effect detection survival. Run models without effects compare WAIC formal testing.Infection rate 22%, recovery rate 46%.","code":"##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaH 0.99 0.01 0.97 0.99  1.00 1.01  1421\n## betaI 0.05 0.01 0.03 0.05  0.08 1.00  6477\n## pH    0.17 0.02 0.13 0.17  0.22 1.01   331\n## pI    0.58 0.10 0.41 0.57  0.80 1.04   220\n## phiH  0.88 0.02 0.84 0.88  0.92 1.01   360\n## phiI  0.99 0.01 0.96 0.99  1.00 1.00  1004\n## pi    0.96 0.01 0.93 0.96  0.98 1.00  4190\n## psiHI 0.22 0.04 0.16 0.22  0.32 1.02   311\n## psiIH 0.46 0.08 0.32 0.45  0.63 1.02   392"},{"path":"uncertainty.html","id":"examples-3","chapter":"7 Uncertainty in state assignment","heading":"7.9 Examples","text":"Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionOur last example individual heterogeneity account HMMs.last example individual heterogeneity account HMMs.","code":""},{"path":"uncertainty.html","id":"individual-heterogeneity-with-finite-mixtures.","chapter":"7 Uncertainty in state assignment","heading":"7.10 Individual heterogeneity with finite mixtures.","text":"Gray wolf social species hierarchy packs may reflect species demography.Gray wolf social species hierarchy packs may reflect species demography.example, ‚Äôll work gray wolves.example, ‚Äôll work gray wolves.","code":"\nknitr::include_graphics(\"images/wolfdominance.jpg\")"},{"path":"uncertainty.html","id":"individual-heterogeneity-with-finite-mixtures.-1","chapter":"7 Uncertainty in state assignment","heading":"7.11 Individual heterogeneity with finite mixtures.","text":"Gray wolf social species hierarchy packs may reflect demography.Gray wolf social species hierarchy packs may reflect demography.Shirley Pledger series papers developed heterogeneity models individuals assigned two classes class-specific survival/detection probabilities.Shirley Pledger series papers developed heterogeneity models individuals assigned two classes class-specific survival/detection probabilities.Cubaynes et al.¬†(2010) used HMMs account heterogeneity detection process due social status, see also Pradel et al.¬†(2009).Cubaynes et al.¬†(2010) used HMMs account heterogeneity detection process due social status, see also Pradel et al.¬†(2009).Dominant individuals tend use path often others, paths look scats.","code":""},{"path":"uncertainty.html","id":"individual-heterogeneity","chapter":"7 Uncertainty in state assignment","heading":"7.12 Individual heterogeneity","text":"3 states\nalive class 1 (A1)\nalive class 2 (A2)\ndead (D)\nalive class 1 (A1)alive class 2 (A2)dead (D)4 observations\ncaptured (0)\ncaptured (1)\ncaptured (0)captured (1)","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity","chapter":"7 Uncertainty in state assignment","heading":"7.12.1 HMM model for individual heterogeneity","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\pi & 1 - \\pi & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\pi\\) probability alive class 1.\\(\\pi\\) probability alive class 1.\\(1 - \\pi\\) probability class 2.\\(1 - \\pi\\) probability class 2.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-1","chapter":"7 Uncertainty in state assignment","heading":"7.12.2 HMM model for individual heterogeneity","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\phi  & 0 & 1 - \\phi\\\\ \n0 & \\phi & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi\\) survival probability, made heterogeneous.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-2","chapter":"7 Uncertainty in state assignment","heading":"7.12.3 HMM model for individual heterogeneity","text":"Transition matrix, change heterogeneity class\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=A1 & z_t=A2 & z_t=D \\\\ \\hdashline\n\\phi (1-\\psi_{12}) & \\phi \\psi_{12} & 1 - \\phi\\\\ \n\\phi \\psi_{21} & \\phi (1-\\psi_{21}) & 1 - \\phi\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\psi_{12}\\) probability individual change class heterogeneity, 1 2.\\(\\psi_{12}\\) probability individual change class heterogeneity, 1 2.\\(\\psi_{21}\\) probability individual change class heterogeneity, 2 1.\\(\\psi_{21}\\) probability individual change class heterogeneity, 2 1.","code":""},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-3","chapter":"7 Uncertainty in state assignment","heading":"7.12.4 HMM model for individual heterogeneity","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1\\\\ \\hdashline\n1 - p_1 & p_1\\\\ \n1 - p_2 & p_2\\\\ \n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=A1 \\\\ z_{t}=A2 \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(p_1\\) detection individuals class 1, \\(p_2\\) individuals class 2.","code":""},{"path":"uncertainty.html","id":"results-2","chapter":"7 Uncertainty in state assignment","heading":"7.13 Results","text":"lowly detectable individuals (class A1 \\(p_1\\)) proportion 62%.lowly detectable individuals (class A1 \\(p_1\\)) proportion 62%.highly () detectable individuals (class A2 \\(p_2\\)) proportion 38%.highly () detectable individuals (class A2 \\(p_2\\)) proportion 38%.Note interpretation classes made posteriori.Note interpretation classes made posteriori.Survival 81%.Survival 81%.","code":"##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1  0.38 0.09 0.23 0.38  0.56 1.04   210\n## p2  0.50 0.12 0.25 0.50  0.73 1.01   229\n## phi 0.81 0.05 0.71 0.81  0.91 1.04   317\n## pi  0.62 0.12 0.36 0.63  0.83 1.02   164"},{"path":"uncertainty.html","id":"hmm-model-for-individual-heterogeneity-4","chapter":"7 Uncertainty in state assignment","heading":"7.13.1 HMM model for individual heterogeneity","text":"may consider classes, select among models, see Cubaynes et al.¬†(2012).may consider classes, select among models, see Cubaynes et al.¬†(2012).may also go non-parametric approach let data tell many classes need. relatively easy Nimble, see Turek et al.¬†(2021).may also go non-parametric approach let data tell many classes need. relatively easy Nimble, see Turek et al.¬†(2021).individual heterogeneity Gimenez et al.¬†(2018).individual heterogeneity Gimenez et al.¬†(2018).","code":""},{"path":"uncertainty.html","id":"hmms-to-analyse-capture-recapture-data","chapter":"7 Uncertainty in state assignment","heading":"7.14 HMMs to analyse capture-recapture data","text":"data, ask questions, just consider different states.","code":""},{"path":"uncertainty.html","id":"how-to-make-our-models-remember","chapter":"7 Uncertainty in state assignment","heading":"7.14.1 How to make our models remember?","text":"far, dynamics states first-order Makovian.far, dynamics states first-order Makovian.site depends site , sites previously.site depends site , sites previously.relax assumption, go second-order Markovian?relax assumption, go second-order Markovian?Memory models initially proposed Hestbeck et al.¬†(1991) Brownie et al.¬†(1993), formulated HMMs Rouan et al.¬†(2009). See also Cole et al.¬†(2014).Memory models initially proposed Hestbeck et al.¬†(1991) Brownie et al.¬†(1993), formulated HMMs Rouan et al.¬†(2009). See also Cole et al.¬†(2014).","code":""},{"path":"uncertainty.html","id":"remember-hmm-model-for-dispersal-between-2-sites","chapter":"7 Uncertainty in state assignment","heading":"7.14.2 Remember HMM model for dispersal between 2 sites","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=& z_t=B & z_t=D \\\\ \\hdashline\n\\phi_A (1-\\psi_{AB}) & \\phi_A \\psi_{AB} & 1 - \\phi_A\\\\ \n\\phi_B \\psi_{BA} & \\phi_B (1-\\psi_{BA}) & 1 - \\phi_B\\\\ \n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model","chapter":"7 Uncertainty in state assignment","heading":"7.15 HMM formulation of the memory model","text":"keep track sites previously visited, trick consider states pairs sites occupiedTo keep track sites previously visited, trick consider states pairs sites occupiedStates\nAA alive site \\(t\\) alive site \\(t-1\\)\nAB alive site \\(t\\) alive site B \\(t-1\\)\nBA alive site B \\(t\\) alive site \\(t-1\\)\nBB alive site B \\(t\\) alive site B \\(t-1\\)\nD dead\nStatesAA alive site \\(t\\) alive site \\(t-1\\)AB alive site \\(t\\) alive site B \\(t-1\\)BA alive site B \\(t\\) alive site \\(t-1\\)BB alive site B \\(t\\) alive site B \\(t-1\\)D deadObservations\n0 captured\n1 captured site \n2 captured site B\nObservations0 captured1 captured site A2 captured site B","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-1","chapter":"7 Uncertainty in state assignment","heading":"7.16 HMM formulation of the memory model","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\\\ \\hdashline\n\\pi_{AA} & \\pi_{AB} & \\pi_{BA} & \\pi_{BB} & 0\\\\ \n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\pi_{BB} = 1 - (\\pi_{AA} + \\pi_{AB} + \\pi_{BA})\\),\\(\\pi_{ij}\\) site \\(j\\) first captured \\(t\\) site \\(\\) \\(t - 1\\).","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-2","chapter":"7 Uncertainty in state assignment","heading":"7.17 HMM formulation of the memory model","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\ \\hdashline\n\\phi_{AAA} & \\phi_{AAB} & 0 & 0 & 1 - \\phi_{AAA} - \\phi_{AAB}\\\\ \n0 & 0 & \\phi_{ABA} & \\phi_{ABB} & 1 - \\phi_{ABA} - \\phi_{ABB}\\\\ \n\\phi_{BAA} & \\phi_{BAB} & 0 & 0 & 1 - \\phi_{BAA} - \\phi_{BAB}\\\\ \n0 & 0 & \\phi_{BBA} & \\phi_{BBB} & 1 - \\phi_{BBA} - \\phi_{BBB}\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\phi_{ijk}\\) probability site \\(k\\) time \\(t + 1\\) individual\npresent site \\(j\\) \\(t\\) site \\(\\) \\(t - 1\\)","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-3","chapter":"7 Uncertainty in state assignment","heading":"7.18 HMM formulation of the memory model","text":"Transition matrix, alternate parameterization\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\ \\hdashline\n\\phi \\psi_{AAA} & \\phi (1 - \\psi_{AAA}) & 0 & 0 & 1 - \\phi\\\\ \n0 & 0 & \\phi (1 - \\psi_{ABB}) & \\phi \\psi_{ABB} & 1 - \\phi\\\\ \n\\phi \\psi_{BAA} & \\phi (1 - \\psi_{BAA}) & 0 & 0 & 1 - \\phi\\\\ \n0 & 0 & \\phi (1-\\psi_{BBB}) & \\phi \\psi_{BBB} & 1 - \\phi\\\\ \n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]\n+ \\(\\phi\\) probability surviving one occasion next.\\(\\psi_{ijj}\\) probability animal stays site \\(j\\) given site \\(\\) previous occasion.","code":""},{"path":"uncertainty.html","id":"hmm-formulation-of-the-memory-model-4","chapter":"7 Uncertainty in state assignment","heading":"7.19 HMM formulation of the memory model","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} = \n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 - p_A & p_A & 0\\\\ \n1 - p_B & 0 & p_B\\\\ \n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"uncertainty.html","id":"further-reading-3","chapter":"7 Uncertainty in state assignment","heading":"7.20 Further reading","text":"Seminal paper Pradel (2005) Multievent: Extension Multistate Capture‚ÄìRecapture Models Uncertain States. Biometrics, 61: 442-447.Seminal paper Pradel (2005) Multievent: Extension Multistate Capture‚ÄìRecapture Models Uncertain States. Biometrics, 61: 442-447.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.See also review Gimenez et al.¬†(2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.See also review Gimenez et al.¬†(2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.","code":""},{"path":"abundance.html","id":"abundance","chapter":"8 Abundance","heading":"8 Abundance","text":"","code":""},{"path":"hsmm.html","id":"hsmm","chapter":"9 Hidden semi-Markov models","heading":"9 Hidden semi-Markov models","text":"","code":""},{"path":"states.html","id":"states","chapter":"10 Hidden states","heading":"10 Hidden states","text":"","code":""},{"path":"speed.html","id":"speed","chapter":"11 Speed up MCMC","heading":"11 Speed up MCMC","text":"","code":""},{"path":"speed.html","id":"our-nimble-workflow-so-far-1","chapter":"11 Speed up MCMC","heading":"11.1 Our nimble workflow so far","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow_sofar.png\")"},{"path":"speed.html","id":"but-nimble-gives-full-access-to-the-mcmc-engine-1","chapter":"11 Speed up MCMC","heading":"11.2 But nimble gives full access to the MCMC engine","text":"","code":"\nknitr::include_graphics(\"images/nimble_workflow.png\")"},{"path":"speed.html","id":"steps-to-use-nimble-at-full-capacity","chapter":"11 Speed up MCMC","heading":"11.3 Steps to use NIMBLE at full capacity","text":"Build model. R object.Build MCMC.Compile model MCMC.Run MCMC.Extract samples.nimbleMCMC .","code":""},{"path":"speed.html","id":"back-to-cjs-models-with-dipper-data.","chapter":"11 Speed up MCMC","heading":"11.4 Back to CJS models with Dipper data.","text":"","code":""},{"path":"speed.html","id":"define-model","chapter":"11 Speed up MCMC","heading":"11.4.1 Define model","text":"","code":"\nhmm.phip <- nimbleCode({\n  delta[1] <- 1              # Pr(alive t = 1) = 1\n  delta[2] <- 0              # Pr(dead t = 1) = 0\n    phi ~ dunif(0, 1)     # prior survival\n    gamma[1,1] <- phi        # Pr(alive t -> alive t+1)\n    gamma[1,2] <- 1 - phi    # Pr(alive t -> dead t+1)\n    gamma[2,1] <- 0          # Pr(dead t -> alive t+1)\n    gamma[2,2] <- 1          # Pr(dead t -> dead t+1)\n    p ~ dunif(0, 1)       # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"speed.html","id":"run-and-summarise","chapter":"11 Speed up MCMC","heading":"11.4.2 Run and summarise","text":"","code":"\nmcmc.phip <- nimbleMCMC(code = hmm.phip, \n                         constants = my.constants,\n                         data = my.data,              \n                         inits = initial.values,\n                         monitors = parameters.to.save,\n                         niter = n.iter,\n                         nburnin = n.burnin, \n                         nchains = n.chains)\n## defining model...\n## building model...\n## setting data and initial values...\n## running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n## checking model sizes and dimensions...\n## checking model calculations...\n## model building finished.\n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished.\n## running chain 1...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## running chain 2...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.phip, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.90 0.03 0.83 0.90  0.95    1   253\n## phi 0.56 0.03 0.51 0.56  0.61    1   528"},{"path":"speed.html","id":"detailed-nimble-workflow","chapter":"11 Speed up MCMC","heading":"11.5 Detailed Nimble workflow","text":"","code":""},{"path":"speed.html","id":"build-the-model-r-object","chapter":"11 Speed up MCMC","heading":"11.6 1. Build the model (R object)","text":"","code":"\nhmm.phip <- nimbleModel(code = hmm.phip,\n                        constants = my.constants,\n                        data = my.data,\n                        inits = initial.values())\n## defining model...\n## building model...\n## setting data and initial values...\n## running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n## checking model sizes and dimensions...\n## model building finished."},{"path":"speed.html","id":"build-the-mcmc","chapter":"11 Speed up MCMC","heading":"11.7 2. Build the MCMC","text":"","code":"\nphip.mcmc.configuration <- configureMCMC(hmm.phip)\n## ===== Monitors =====\n## thin = 1: phi, p, z\n## ===== Samplers =====\n## RW sampler (2)\n##   - phi\n##   - p\n## posterior_predictive sampler (39)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)\nphip.mcmc <- buildMCMC(phip.mcmc.configuration)"},{"path":"speed.html","id":"compile-the-model-and-mcmc","chapter":"11 Speed up MCMC","heading":"11.8 3. Compile the model and MCMC","text":"","code":"\nphip.model <- compileNimble(hmm.phip) \n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished.\nc.phip.mcmc <- compileNimble(phip.mcmc, project = phip.model)\n## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n## compilation finished."},{"path":"speed.html","id":"run-the-mcmc","chapter":"11 Speed up MCMC","heading":"11.9 4. Run the MCMC","text":"","code":"\nsamples <- runMCMC(c.phip.mcmc, niter = 1000)\n## running chain 1...\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# Alternative:\n# c.phip.mcmc$run(1000)\n# samples <- as.matrix(c.phip.mcmc$mvSamples)"},{"path":"speed.html","id":"look-at-results","chapter":"11 Speed up MCMC","heading":"11.10 5. Look at results","text":"","code":"\nsummary(samples[,\"phi\"])\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.380   0.552   0.565   0.572   0.589   0.780\nsummary(samples[,\"p\"])\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.146   0.874   0.885   0.864   0.902   0.946"},{"path":"speed.html","id":"why-is-it-useful","chapter":"11 Speed up MCMC","heading":"11.11 Why is it useful?","text":"","code":""},{"path":"speed.html","id":"use-and-debug-model-in-r","chapter":"11 Speed up MCMC","heading":"11.12 Use and debug model in R","text":"Makes life easier comes debuggingMakes life easier comes debuggingInspect variablesInspect variablesCalculate likelihood","code":"\nhmm.phip$gamma\n##        [,1]   [,2]\n## [1,] 0.3795 0.6205\n## [2,] 0.0000 1.0000\nhmm.phip$calculate()\n## [1] -2383"},{"path":"speed.html","id":"example-of-debugging-a-model-in-r","chapter":"11 Speed up MCMC","heading":"11.13 Example of debugging a model in R","text":"Pretend impossible state given inits, making dead bird alive .","code":"\nphip.model$calculate(\"z\")        # We can see there is a problem in z (states).\n## [1] -Inf\nc(phip.model$calculate(\"z[5,]\"), # Bird 5 is valid.\n  phip.model$calculate(\"z[6,]\")) # Bird 6 isn't.\n## [1] -3.327   -Inf\nphip.model$z[6,]                 # We have found the problem\n## [1] 1 1 2 1 2 2 2"},{"path":"speed.html","id":"open-the-hood-and-changemodifywrite-samplers","chapter":"11 Speed up MCMC","heading":"11.14 Open the hood, and change/modify/write samplers","text":"Slice samplers instead Metropolis-Hastings.Slice samplers instead Metropolis-Hastings.Samplers log scale, especially variance, standard deviation, precision parameter.Samplers log scale, especially variance, standard deviation, precision parameter.Blocking correlated parameters.Blocking correlated parameters.know samplers available Nimble, type help(samplers).know samplers available Nimble, type help(samplers).Source code samplers distributions R can copied modified.Source code samplers distributions R can copied modified.Use compareMCMCs package compare options (including Stan Jags!).Use compareMCMCs package compare options (including Stan Jags!).","code":""},{"path":"speed.html","id":"consider-a-model-with-wing-length-and-individual-random-effect-on-survival.","chapter":"11 Speed up MCMC","heading":"11.15 Consider a model with wing length and individual random effect on survival.","text":"","code":"\nhmm.phiwlrep <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i] #<<\n    eps[i] ~ dnorm(mean = 0, sd = sdeps) #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  sdeps ~ dunif(0, 10)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})"},{"path":"speed.html","id":"trace-plot-for-standard-deviation-of-the-random-effect-default-sampler","chapter":"11 Speed up MCMC","heading":"11.16 Trace plot for standard deviation of the random effect (default sampler)","text":"","code":""},{"path":"speed.html","id":"change-samplers","chapter":"11 Speed up MCMC","heading":"11.17 Change samplers","text":"Good sampling strategies depend model data. samplers used default?","code":"\nmcmcConf <- configureMCMC(hmm.phiwlrep.m)\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## RW sampler (259)\n##   - p\n##   - beta[]  (2 elements)\n##   - sdeps\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)"},{"path":"speed.html","id":"remove-default-sampler-and-use-slice-sampler","chapter":"11 Speed up MCMC","heading":"11.18 Remove default sampler, and use slice sampler","text":"","code":"\nmcmcConf$removeSamplers('sdeps')\nmcmcConf$addSampler(target = 'sdeps',\n                    type = \"slice\") #<<\nmcmcConf\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## slice sampler (1)\n##   - sdeps\n## RW sampler (258)\n##   - p\n##   - beta[]  (2 elements)\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|"},{"path":"speed.html","id":"trace-plot-for-standard-deviation-of-the-random-effect-slice-sampler","chapter":"11 Speed up MCMC","heading":"11.19 Trace plot for standard deviation of the random effect (slice sampler)","text":"","code":""},{"path":"speed.html","id":"which-is-better","chapter":"11 Speed up MCMC","heading":"11.20 Which is better?","text":"MCMC efficiency depends mixing computation time.MCMC efficiency depends mixing computation time.MCMC efficiency = Effective Sample Size (ESS) / computation time.MCMC efficiency = Effective Sample Size (ESS) / computation time.MCMC efficiency number effectively independent posterior samples generated per second.MCMC efficiency number effectively independent posterior samples generated per second.ESS different parameter. (Computation time parameter.)ESS different parameter. (Computation time parameter.)ESS can estimated packages coda mcmcse. give statistical estimates, different runs give different estimates.ESS can estimated packages coda mcmcse. give statistical estimates, different runs give different estimates.Efficiency default sampler = 25.7 / 21.53 = 1.19.Efficiency default sampler = 25.7 / 21.53 = 1.19.Efficiency slice sampler = 19.14 / 17.33 = 1.1.Efficiency slice sampler = 19.14 / 17.33 = 1.1.","code":""},{"path":"speed.html","id":"block-sampling","chapter":"11 Speed up MCMC","heading":"11.21 Block sampling","text":"High correlation (regression) parameters may make independent samplers inefficient.Block sampling (propose candidate values multivariate distribution) might help.","code":""},{"path":"speed.html","id":"block-sampling-1","chapter":"11 Speed up MCMC","heading":"11.22 Block sampling","text":"Remove replace independent RW samples block sampling. proceed usual.","code":"\nmcmcConf$removeSamplers(c('beta[1]','beta[2]'))\nmcmcConf$addSampler(target = c('beta[1]','beta[2]'),\n                    type = \"RW_block\") #<<"},{"path":"speed.html","id":"block-sampling-2","chapter":"11 Speed up MCMC","heading":"11.23 Block sampling","text":"","code":"\nmcmcConf\n## ===== Monitors =====\n## thin = 1: p, beta, sdeps, z\n## ===== Samplers =====\n## slice sampler (1)\n##   - sdeps\n## RW_block sampler (1)\n##   - beta[1], beta[2] \n## RW sampler (256)\n##   - p\n##   - eps[]  (255 elements)\n## posterior_predictive sampler (78)\n##   - eps[]  (39 elements)\n##   - z[]  (39 elements)\n## categorical sampler (1103)\n##   - z[]  (1103 elements)"},{"path":"speed.html","id":"summary-of-strategies-for-improving-mcmc","chapter":"11 Speed up MCMC","heading":"11.24 Summary of strategies for improving MCMC","text":"Choose better initial values.Choose better initial values.Customize sampler choice (Chapter 7 User‚Äôs manual).Customize sampler choice (Chapter 7 User‚Äôs manual).Reparameterize, e.g.¬†standardize covariates, deal parameter redundancy.Reparameterize, e.g.¬†standardize covariates, deal parameter redundancy.Rewrite model.\nVectorize improve computational efficiency (covered).\nAvoid long chains deterministic dependencies.\nMarginalize remove parameters\nUse new functions new distributions written nimbleFunctions.\nRewrite model.Vectorize improve computational efficiency (covered).Avoid long chains deterministic dependencies.Marginalize remove parametersUse new functions new distributions written nimbleFunctions.Write new samplers take advantage particular model structures (covered).Write new samplers take advantage particular model structures (covered).Using multiple cores parallelization: see -https://r-nimble.org/nimbleExamples/parallelizing_NIMBLE.htmlUsing multiple cores parallelization: see -https://r-nimble.org/nimbleExamples/parallelizing_NIMBLE.html","code":""},{"path":"speed.html","id":"marginalization","chapter":"11 Speed up MCMC","heading":"11.25 Marginalization","text":"User-defined distributions another neat feature Nimble.User-defined distributions another neat feature Nimble.Integrate latent states focus ecological inference (marginalization).Integrate latent states focus ecological inference (marginalization).Marginalization often (always) improves MCMC. See Ponisio et al.¬†2020 examples.Marginalization often (always) improves MCMC. See Ponisio et al.¬†2020 examples.nimbleEcology package implements capture-recapture models HMMs marginalization.nimbleEcology package implements capture-recapture models HMMs marginalization.","code":""},{"path":"speed.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-6","chapter":"11 Speed up MCMC","heading":"11.25.1 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"\nmultisite <- nimbleCode({\n...\n  # Likelihood \n  for (i in 1:N){\n    # Define latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # State process: draw S(t) given S(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # Observation process: draw O(t) given S(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})"},{"path":"speed.html","id":"same-model-with-nimbleecology","chapter":"11 Speed up MCMC","heading":"11.25.2 Same model with nimbleEcology","text":"runs twice fast standard formulation explicit latent states.runs twice fast standard formulation explicit latent states.Marginalizing typically gives better mixing.Marginalizing typically gives better mixing.","code":"multisite <- nimbleCode({\n...\n# initial state probs\nfor(i in 1:N) {\n  init[i, 1:4] <- gamma[ y[i, first[i] ] - 1, 1:4 ] # first state propagation\n}\n    \n# likelihood \nfor (i in 1:N){\n  y[i,(first[i]+1):K] ~ dHMM(init = init[i,1:4],           # count data from first[i] + 1\n                             probObs = omega[1:4,1:4],     # observation matrix\n                             probTrans = gamma[1:4,1:4],   # transition matrix\n                             len = K - first[i],           # nb of occasions\n                             checkRowSums = 0)             # do not check whether elements in a row sum tp 1\n}\n..."},{"path":"speed.html","id":"reducing-redundant-calculations","chapter":"11 Speed up MCMC","heading":"11.25.3 Reducing redundant calculations","text":"far, row dataset individual. However, several individuals may share encounter history.far, row dataset individual. However, several individuals may share encounter history.contribution \\(M\\) individuals encounter history likelihood particular encounter history raised power \\(M\\).contribution \\(M\\) individuals encounter history likelihood particular encounter history raised power \\(M\\).Using -called weighted likelihood greatly decreases computational burden.Using -called weighted likelihood greatly decreases computational burden.idea used computer programs implement maximum likelihood. Bayesian framework, idea proposed Turek et al.¬†(2016).idea used computer programs implement maximum likelihood. Bayesian framework, idea proposed Turek et al.¬†(2016).done Jags. Can done nimble thanks nimble functions!done Jags. Can done nimble thanks nimble functions!run much faster. Also allows fitting models big datasets. details dedicated Worksheet.run much faster. Also allows fitting models big datasets. details dedicated Worksheet.","code":""},{"path":"speed.html","id":"no-live-demo-but-there-is-a-worksheet.","chapter":"11 Speed up MCMC","heading":"11.26 No live demo, but there is a worksheet.","text":"","code":""},{"path":"speed.html","id":"future-directions-for-nimble","chapter":"11 Speed up MCMC","heading":"11.27 Future directions for NIMBLE","text":"NIMBLE active development. Contributors welcome, including want get involved don‚Äôt know .NIMBLE active development. Contributors welcome, including want get involved don‚Äôt know .Faster building models algorithms. Ability save re-load compiled work.Faster building models algorithms. Ability save re-load compiled work.Automatic differentiation model calculations, enabling Hamiltonian Monte Carlo, sampling strategies, Laplace approximation.Automatic differentiation model calculations, enabling Hamiltonian Monte Carlo, sampling strategies, Laplace approximation.Tools building packages use NIMBLE ‚Äúhood.‚ÄùTools building packages use NIMBLE ‚Äúhood.‚Äù","code":""},{"path":"speed.html","id":"further-reading-4","chapter":"11 Speed up MCMC","heading":"11.28 Further reading","text":"Turek, D., de Valpine, P. & Paciorek, C.J. Efficient Markov chain Monte Carlo sampling hierarchical hidden Markov models Environ Ecol Stat 23: 549‚Äì564 (2016).Turek, D., de Valpine, P. & Paciorek, C.J. Efficient Markov chain Monte Carlo sampling hierarchical hidden Markov models Environ Ecol Stat 23: 549‚Äì564 (2016).Ponisio, L.C., de Valpine, P., Michaud, N., Turek, D. One size fit : Customizing MCMC methods hierarchical models using NIMBLE Ecol Evol. 10: 2385‚Äì2416 (2020).Ponisio, L.C., de Valpine, P., Michaud, N., Turek, D. One size fit : Customizing MCMC methods hierarchical models using NIMBLE Ecol Evol. 10: 2385‚Äì2416 (2020).Nimble workshop come 26-28 May, check .Nimble workshop come 26-28 May, check .Nimble workshop material online available .Nimble workshop material online available .Nimble manual cheatsheet.Nimble manual cheatsheet.","code":""},{"path":"conclusions.html","id":"conclusions","chapter":"12 Conclusions","heading":"12 Conclusions","text":"","code":""},{"path":"conclusions.html","id":"take-home-messages-and-recommendations","chapter":"12 Conclusions","heading":"12.1 Take-home messages and recommendations","text":"‚Äôll wrap workshop take-home messagesAnd recommendations conducting analyses.","code":""},{"path":"conclusions.html","id":"make-the-best-of-your-data-with-hmms","chapter":"12 Conclusions","heading":"12.2 Make the best of your data with HMMs","text":"searchable list HMM analyses capture-recapture data.searchable list HMM analyses capture-recapture data.hope provided useful overview use hidden Markov models analyze capture-recapture data.hope provided useful overview use hidden Markov models analyze capture-recapture data.scratched surface can models.scratched surface can models.assembled searchable list HMM analyses capture-recapture data get inspiration.assembled searchable list HMM analyses capture-recapture data get inspiration.list exhaustive, please get touch us ‚Äôd like add reference.list exhaustive, please get touch us ‚Äôd like add reference.exhaustive, ‚Äôll continue updating . Feel free suggest papers add list.exhaustive, ‚Äôll continue updating . Feel free suggest papers add list.","code":""},{"path":"conclusions.html","id":"bayesian-capture-recapture-analysis-with-hmms","chapter":"12 Conclusions","heading":"12.3 Bayesian capture-recapture analysis with HMMs","text":"leave, ‚Äôd like give pieces advice.leave, ‚Äôd like give pieces advice.rocket science.rocket science.Just things based experience Bayesian capture-recapture analysis HMMS.Just things based experience Bayesian capture-recapture analysis HMMS.Make ecological question explicit.Make ecological question explicit.First things first. Make sure ‚Äôve spent time make ecological question explicit.First things first. Make sure ‚Äôve spent time make ecological question explicit.step help stay course, make right choices.step help stay course, make right choices.example, ‚Äôs ok use subsets data address different questions.example, ‚Äôs ok use subsets data address different questions.Think observations states first.Think observations states first.Now terms modeling. Don‚Äôt jump keyboard right away.Now terms modeling. Don‚Äôt jump keyboard right away.Spend time thinking model pen paper.Spend time thinking model pen paper.particular make sure observations states HMM.particular make sure observations states HMM.write observation transition matrices paper.write observation transition matrices paper.write transition matrix. may act imperfect detection. really ‚Äôre , ecological process (survival, dispersal, etc).write transition matrix. may act imperfect detection. really ‚Äôre , ecological process (survival, dispersal, etc).Proceed observation matrix.Proceed observation matrix.Start simple, parameters constant example. Make sure convergence reached.Start simple, parameters constant example. Make sure convergence reached.comes model fitting Nimble, start simple.comes model fitting Nimble, start simple.Consider parameters constant.Consider parameters constant.Make sure convergence reached.Make sure convergence reached.Add complexity one step time.Add complexity one step time.add complexity. Time effect example. random effects.add complexity. Time effect example. random effects.uncertainty assignment states.uncertainty assignment states.","code":""},{"path":"conclusions.html","id":"bayesian-capture-recapture-analysis-with-hmms-1","chapter":"12 Conclusions","heading":"12.4 Bayesian capture-recapture analysis with HMMs","text":"Use simulations better understand model.Use simulations better understand model.Nimble models can used simulate data, check tutorial.Nimble models can used simulate data, check tutorial.comes model building, consider simulating data better understand model.comes model building, consider simulating data better understand model.always learn something model seeing engine generate data, instead estimating parameters.always learn something model seeing engine generate data, instead estimating parameters.cool thing nimble can models simulate data. tutorial .cool thing nimble can models simulate data. tutorial .try optimize code. Make work first, think optimization.try optimize code. Make work first, think optimization.‚ÄúPremature optimization root evil‚Äù - Donald Knuth (creator TeX author ‚ÄúArt Computer Programming‚Äù)Another advice, quite general programming, try optimize codeAnother advice, quite general programming, try optimize codeOr try make elegant right away. Make work first.try make elegant right away. Make work first.think optimization.think optimization.Read Bayesian workflow Gelman et al.¬†(2021).Read Bayesian workflow Gelman et al.¬†(2021).recommendations Bayesian analyses recent paper Gelman collaborations.recommendations Bayesian analyses recent paper Gelman collaborations.offer workflow bayesian analyses.offer workflow bayesian analyses.discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.","code":""},{"path":"conclusions.html","id":"till-next-time","chapter":"12 Conclusions","heading":"12.5 Till next time","text":"Slack space remain time. Happy answer questions might related workshop.Slack space remain time. Happy answer questions might related workshop.Slack space remain time.Slack space remain time.‚Äôll happy answer questions might related workshop.‚Äôll happy answer questions might related workshop.Website updated \nvideo recordings\nfeedbacks\nFAQ section based questions\nWebsite updated withvideo recordingsyour feedbacksa FAQ section based questionsWe update workshop website coming weeks.update workshop website coming weeks.video recordings course.video recordings course.feedback might . Please get touch , great.feedback might . Please get touch , great.plan also gather exchanges Frequently Asked Questions section website.plan also gather exchanges Frequently Asked Questions section website.book way. 2022 hopefully.book way. 2022 hopefully.last, book way. Based material used workshop stuff.last, book way. Based material used workshop stuff.Also half book case studies reproducing analysis published papers.Also half book case studies reproducing analysis published papers.2022 hopefully.2022 hopefully.","code":""},{"path":"conclusions.html","id":"lets-see-if-i-can-put-to-use-my-own-pieces-of-advice---case-studies","chapter":"12 Conclusions","heading":"12.6 Let‚Äôs see if I can put to use my own pieces of advice - case studies","text":"","code":""},{"path":"senescence.html","id":"senescence","chapter":"13 Actuarial senescence","heading":"13 Actuarial senescence","text":"Choquet et al. (2011), P√©ron et al. (2016)","code":""},{"path":"heterogeneity.html","id":"heterogeneity","chapter":"14 Individual heterogeneity","heading":"14 Individual heterogeneity","text":"Cubaynes et al. (2010), Gimenez Choquet (2010), Turek, Wehrhahn, Gimenez (2021)","code":""},{"path":"tradeoffs.html","id":"tradeoffs","chapter":"15 Life-history tradeoffs","heading":"15 Life-history tradeoffs","text":"Morano et al. (2013), Shefferson et al. (2003), Cruz-Flores et al. (n.d.)","code":""},{"path":"breeding.html","id":"breeding","chapter":"16 Breeding dynamics","heading":"16 Breeding dynamics","text":"Pradel, Choquet, B√©chet (2012), Desprez et al. (2011), Desprez et al. (2013), Pacoureau et al. (2019)","code":""},{"path":"rd.html","id":"rd","chapter":"17 Robust design","heading":"17 Robust design","text":"Karamanlidis et al. (2015), Santostasi et al. (2016), Gibson et al. (2018), Rankin et al. (2016)","code":""},{"path":"stopover.html","id":"stopover","chapter":"18 Stopover duration","heading":"18 Stopover duration","text":"Gu√©rin et al. (2017)","code":""},{"path":"disease.html","id":"disease","chapter":"19 Disease dynamics","heading":"19 Disease dynamics","text":"Marescot et al. (2018) Santoro et al. (2014)","code":""},{"path":"sex.html","id":"sex","chapter":"20 Sex uncertainty","heading":"20 Sex uncertainty","text":"Pradel et al. (2008) Genovart, Pradel, Oro (2012)","code":""},{"path":"dependence.html","id":"dependence","chapter":"21 Dependence among individuals","heading":"21 Dependence among individuals","text":"Culina et al. (2013) Cubaynes et al. (2021)","code":""},{"path":"covariateselection.html","id":"covariateselection","chapter":"22 Individual and temporal variability","heading":"22 Individual and temporal variability","text":"Grosbois et al. (2008), Cubaynes et al. (2012), Gimenez et al. (2006), Bonner, Morgan, King (2010)","code":""},{"path":"mortalities.html","id":"mortalities","chapter":"23 Cause-specific mortalities","heading":"23 Cause-specific mortalities","text":"Fern√°ndez-Chac√≥n et al. (2016) Ruette et al. (2015)","code":""},{"path":"prevalence.html","id":"prevalence","chapter":"24 Prevalence","heading":"24 Prevalence","text":"(Santostasi et al. 2019)","code":""},{"path":"faq.html","id":"faq","chapter":"FAQ","heading":"FAQ","text":"complete list frequently asked questions (FAQ). Yes, one question . Personally like FAQs. often mean surprises, surprises good software users.Q: bookdown features X, Y, Z?\n: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.\nUsers asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.Q: bookdown features X, Y, Z?: short answer , asked three times ‚Äúreally need ‚Äù answer still ‚Äúyes,‚Äù please feel free file feature request https://github.com/rstudio/bookdown/issues.Users asking features often come LaTeX world. case , answer question yes, Pandoc‚Äôs Markdown supports raw LaTeX code. Whenever feel Markdown job , always option apply raw LaTeX code Markdown document. example, can create glossaries using glossaries package, embed complicated LaTeX table, long know LaTeX syntax. However, please keep mind LaTeX content portable. work LaTeX/PDF output, ignored types output. Depending request, may port LaTeX features bookdown future, general philosophy Markdown kept simple possible.challenging thing world learn fancy technologies, control wild heart.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
