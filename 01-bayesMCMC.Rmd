\mainmatter

# (PART) Theory {-}

# Bayesian statistics & MCMC {#crashcourse}

## Bayes' theorem

A theorem about conditional probabilities.

$\Pr(B \mid A) = \displaystyle{\frac{ \Pr(A \mid B) \; \Pr(B)}{\Pr(A)}}$

```{r, echo = FALSE, fig.cap = "Bayes' theorem spelt out in blue neon at the offices of Autonomy in Cambridge. Source: Wikipedia"}
knitr::include_graphics("images/bayes_neon.jpeg")
```

I always forget what the letters mean. 

Might be easier to remember when written like this:

$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$

The "hypothesis" is typically something unobserved or unknown. It's what you want to learn about using the data. 

For regression models, the "hypothesis" is a parameter (intercept, slopes or error terms).

Bayes theorem tells you the probability of the hypothesis given the data.

Cool because what is doing science after all?

How plausible is some hypothesis given the data?

$$ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} $$

The Bayesian reasoning echoes the scientific reasoning. You might ask then, why is Bayesian statistics not the default?

You may ask: Why is Bayesian statistics not the default?

Due to practical problems of implementing the Bayesian approach, and futile wars between (male) statisticians, little progress was made for over two centuries.

Recent advances in computational power coupled with the development of new methodology have led to a great increase in the application of Bayesian methods within the last two decades.

## Frequentist versus Bayesian	

Typical stats problems involve estimating parameter $\theta$ with available data.

The frequentist approach (maximum likelihood estimation â€“ MLE) assumes that the parameters are fixed, but have unknown values to be estimated.

Classical estimates are generally point estimates of the parameters of interest.

The Bayesian approach assumes that the parameters are not fixed but have some fixed  unknown distribution - a distribution for the parameter.

## What is the Bayesian approach?	

The approach is based upon the idea that the experimenter begins with some prior beliefs about the system.

You never start from scratch. 

And then updates these beliefs on the basis of observed data.

This updating procedure is based upon the Bayes' Theorem:

$$\Pr(A \mid B) = \frac{\Pr(B \mid A) \; \Pr(A)}{\Pr(B)}$$
 
Schematically if $A = \theta$ and $B = \text{data}$, then

The Bayes' theorem

$$\Pr(A \mid B) = \frac{\Pr(B \mid A) \; \Pr(A)}{\Pr(B)}$$

Translates into:

$$\Pr(\theta \mid \text{data}) = \frac{\Pr(\text{data} \mid \theta) \; \Pr(\theta)}{\Pr(\text{data})}$$

## Bayes' theorem	

$${\color{red}{\Pr(\theta \mid \text{data})}} = \frac{\color{blue}{\Pr(\text{data} \mid \theta)} \; \color{green}{\Pr(\theta)}}{\color{orange}{\Pr(\text{data})}}$$

$\color{red}{\text{Posterior distribution}}$: Represents what you know after having seen the data. The basis for inference, a distribution, possibly multivariate if more than one parameter. 

$\color{blue}{\text{Likelihood}}$: This quantity is the same as in the MLE approach.

$\color{green}{\text{Prior distribution}}$: Represents what you know before seeing the data. The source of much discussion about the Bayesian approach.

$\color{orange}{\Pr(\text{data}) = \int{L(\text{data} \mid \theta)\Pr(\theta) d\theta}}$ is a $N$-dimensional integral if $\theta = \theta_1, \ldots, \theta_N$. 

Difficult if not impossible to calculate. This is one of the reasons why we need simulation (MCMC) methods.

## Brute force via numerical integration

Say we release $n$ animals at the beginning of the winter, out of which $y$ survive, and we'd like to estimate winter survival $\theta$. 
```{r}
y <- 19 # nb of success
n <- 57 # nb of attempts
```



## Further reading

+ McCarthy, M. (2007). [Bayesian Methods for Ecology](https://www.cambridge.org/core/books/bayesian-methods-for-ecology/9225F65B8A25D69B0B6C50B5A9A78201). Cambridge: Cambridge University Press.

+ McElreath, R. (2020). [Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.)](https://xcelab.net/rm/statistical-rethinking/). CRC Press.

+ Gelman, A. and Hill, J. (2006). [Data Analysis Using Regression and Multilevel/Hierarchical Models (Analytical Methods for Social Research)](https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983). Cambridge: Cambridge University Press.