# NIMBLE {#intronimble}

**coder Metropolis d'au-dessus dans Nimble**
**basculer des trucs de speed up ici**

## What is NIMBLE?

```{r pressure, echo=FALSE, fig.cap="(Meme created by Todd Arnold's wonderful students)", out.width = c('24%', '60%')}
knitr::include_graphics(c("images/ToddStudents_Meme.jpg","images/RobRob_Comment_edited.png"))
```

+ **N**umerical **I**nference for statistical **M**odels using **B**ayesian and **L**ikelihood **E**stimation.

+ A framework for hierarchical statistical models and algorithms.

+ Uses almost the same model code as WinBUGS, OpenBUGS, and JAGS.

+ An extension of the BUGS language: additional syntax, custom functions and distributions.

+ A configurable system for MCMC.

+ A library of other methods (SMC, MCEM).

+ Sequential Monte Carlo (particle filtering)
+ Monte Carlo Expectation Maximization (maximum likelihood)

+ A model-generic programming system to write new analysis methods.

+ because it extends the BUGS language for writing new functions and distributions,

+ and provides samplers that can deal with discrete latent states

The proposed semiparametric LVM and Bayesian inference were implemented via nimble. nimble is an R package for programming with BUGS models, which allows for fitting models specified using syntax similar to WinBUGS and JAGS, but with more flexibility in defining the models and algorithms. Users can operate from within R, and nimble will generate the C++ code for faster computation. In this section, we introduce how to carry out the proposed analysis using nimble 0.6–10 in R 3.4.1.


## Load `nimble` package

```{r}
library(nimble)
```

## Build model, made of likelihood and priors

```{r}
naive.survival.model <- nimbleCode({
  # prior
  phi ~ dunif(0, 1)
  # likelihood
  y ~ dbinom(phi, n)
})
```

## Syntax: what's new/better/different?

+ Vectorization
```{r, eval = FALSE}
# JAGS (& Nimble)
for(t in 1:Tmax){
  x[t] <- Mu.x + epsilon[t]
}

# Nimble
x[1:Tmax] <- Mu.x + epsilon[1:Tmax]
```

+ More flexible specification of distributions
```{r, eval = FALSE}
# JAGS (& Nimble)
for(t in 1:Tmax){
  epsilon[t] ~ dnorm(0, tau)
}
tau <- pow(sigma, -2)
sigma ~ dunif(0, 5)

# Nimble
for(t in 1:Tmax){
  epsilon[t] ~ dnorm(0, sd = sigma)
}
sigma ~ dunif(0, 5)
```

+ Your own functions and distributions
```{r, eval = FALSE}
x[1:Tmax] <- myNimbleFunction(a = Mu.x, b = epsilon[1:Tmax])
```

```{r, eval = FALSE}
sigma ~ dCustomDistr(c = 0.5, z = 10)
```

+ The end of empty indices
```{r, eval = FALSE}
# JAGS
sum.x <- sum(x[])

# Nimble
sum.x <- sum(x[1:Tmax])
```

+ & more...


## Read in data

Back to our naive survival model:

```{r}
naive.survival.model <- nimbleCode({
  # prior
  phi ~ dunif(0, 1)
  # likelihood
  y ~ dbinom(phi, n)
})
```

```{r}
my.data <- list(n = 57, y = 19)
```


## Distinguish constants and data

To Nimble, not all "data" is data...
```{r}
my.constants <- list(n = 57)
my.data <- list(y = 19)
```

**Constants**:
+ Can never be changed
+ Must be provided when a model is defined (part of the model structure)
+ E.g. vector of known index values, variables used to define for-loops, etc.

After defining the model code, we should define the constants, initial values and data list. Compared to WinBUGS and JAGS, data and initial values can be defined in the same way, while ‘constants’ is a new list that contains the values that would not change, including the variables that define for-loop indices. In our settings, the lists of data, constants and initial values are given as follows:

To Nimble, not all "data" is data...
```{r}
my.constants <- list(n = 57)
my.data <- list(y = 19)
```

**Data**:
+ Can be changed without re-building the model
+ Can be (re-)simulated within a model
+ E.g. stuff that *only* appears to the left of a "~"

For computational efficiency, better to specify as much as possible as constants.

Nimble will help you with this!

## Specify initial values

```{r}
initial.values <- function() list(phi = runif(1,0,1))
```

```{r}
initial.values()
```


## Which parameters to save?

```{r}
parameters.to.save <- c("phi")
```

## MCMC details

```{r}
n.iter <- 5000
n.burnin <- 1000
n.chains <- 2
n.thin <- 1
```

Number of posterior samples per chain:

$$n.posterior = \frac{n.iter - n.burnin}{n.thin}$$

## Run model, tadaa!

```{r, eval = FALSE}
mcmc.output <- nimbleMCMC(code = naive.survival.model,
                          data = my.data,
                          constants = my.constants,
                          inits = initial.values,
                          monitors = parameters.to.save,
                          thin = n.thin,
                          niter = n.iter,
                          nburnin = n.burnin,
                          nchains = n.chains)
```

```{r, cache = TRUE, echo = FALSE}
mcmc.output <- nimbleMCMC(code = naive.survival.model,
                          data = my.data,
                          constants = my.constants,
                          inits = initial.values,
                          monitors = parameters.to.save,
                          niter = n.iter,
                          nburnin = n.burnin,
                          nchains = n.chains,
                          progressBar = FALSE)
```

## Explore MCMC outputs

```{r}
str(mcmc.output)
```

```{r}
head(mcmc.output$chain1)
```


```{r, echo = FALSE}
mcmc.output %>%
  as_tibble() %>%
  janitor::clean_names() %>%
  ggplot() +
  geom_histogram(aes(x = chain1[,"phi"]), color = "white") +
  labs(x = "survival probability")
```

## Numerical summaries

```{r}
library(MCMCvis)
MCMCsummary(mcmc.output, round = 2)
```

## Trace and posterior density

```{r eval = FALSE}
MCMCtrace(mcmc.output,
          pdf = FALSE)
```

```{r eval = FALSE}
MCMCtrace(mcmc.output,
          pdf = FALSE,
          ind = TRUE,
          Rhat = TRUE,
          n.eff = TRUE)
```

## Our `nimble` workflow so far

```{r}
knitr::include_graphics("images/nimble_workflow_sofar.png")
```


## But `nimble` gives full access to the MCMC engine


```{r}
knitr::include_graphics("images/nimble_workflow.png")
```

```{r}
knitr::include_graphics("images/I1bIY06.gif")
```

## Functions


Say we want an R function that adds 2 to every value in a vector.
```{r}
add2 <- function(x) {
   x + 2 
}
Radd2 <- nimbleRcall(function(x = double(0)){}, 
                     Rfun = 'add2',
                     returnType = double(0))
demoCode <- nimbleCode({
  mu ~ dnorm(0,1)
  for(i in 1:n) {
    x[i] ~ dnorm(mu, sd = 1)
    z[i] <- Radd2(x[i])
    } 
})

param_names <- c("mu", "z")
mcmc.out <- nimbleMCMC(code = demoCode, 
                      constants = list(n = 4),
                      data = list(x = c(-1, -2, 1, 2)), 
                      inits = list(mu = rnorm(1)),
                      monitors = param_names,
                      nchains = 2, 
                      niter = 1000,
                      nburnin = 500)
library(MCMCvis)
MCMCsummary(object = mcmc.out, round = 2)
```

Change format to vectorise.
```{r}
add2 <- function(x) {
   x + 2 
}
Radd2 <- nimbleRcall(function(x = double(1)){}, 
                     Rfun = 'add2',
                     returnType = double(1))
demoCode <- nimbleCode({
  mu ~ dnorm(0,1)
  for(i in 1:n) {
    x[i] ~ dnorm(mu, sd = 1)
    }
    z[1:4] <- Radd2(x[1:4])
})

param_names <- c("mu", "z")
mcmc.out <- nimbleMCMC(code = demoCode, 
                      constants = list(n = 4),
                      data = list(x = c(-1, -2, 1, 2)), 
                      inits = list(mu = rnorm(1)),
                      monitors = param_names,
                      nchains = 2, 
                      niter = 1000,
                      nburnin = 500)
library(MCMCvis)
MCMCsummary(object = mcmc.out, round = 2)
```

Now have paramater to estimate as parameter of your R function. 
```{r}
add2 <- function(x) {
   x + 2 
}
Radd2 <- nimbleRcall(function(x = double(0)){}, 
                     Rfun = 'add2',
                     returnType = double(0))
demoCode <- nimbleCode({
  mu ~ dnorm(0,1)
  for(i in 1:n) {x[i] ~ dnorm(mu, sd = 1)} 
  z <- Radd2(mu)
})

param_names <- c("mu", "z")
mcmc.out <- nimbleMCMC(code = demoCode, 
                      constants = list(n = 4),
                      data = list(x = c(-1, -2, 1, 2)), 
                      inits = list(mu = rnorm(1)),
                      monitors = param_names,
                      nchains = 2, 
                      niter = 1000,
                      nburnin = 500)
library(MCMCvis)
MCMCsummary(object = mcmc.out, round = 2)
```

In general if you do need a nimbleRcall like this, there are a couple of considerations. It is common to need to write a wrapper function, i.e. a function you access via nimbleRcall that calls your actual function of interest with arguments and then return value rearranged as needed. For example, if you just need the eigenvectors, a wrapper function could pick those out and return them.  The bigger issue is the returnType declaration: nimble type declarations do not include an R list of type declarations as a nimble type.  I think you could use a nimbleList data structure for this purpose.  You would have to create a nimbleList type and then use that as the declared returnType.  But you would still need to write a wrapper, so that you could convert the list returned from base::eigen into a nimbleList object to return from your wrapper.  I hope that makes sense.

https://kenkellner.com/blog/models-with-integrals.html

Same thing w/ global environment.

```{r}
library(nimble)
add2 <- function(x) {
   x + 2 + globvar
}
add2(2)
globvar <- 2020
add2(2)
Radd2 <- nimbleRcall(function(x = double(0)){}, 
                     Rfun = 'add2',
                     returnType = double(0))
demoCode <- nimbleCode({
  mu ~ dnorm(0,1)
  for(i in 1:n) {x[i] ~ dnorm(mu, sd = 1)} 
  z <- Radd2(mu)
})

param_names <- c("mu", "z")
mcmc.out <- nimbleMCMC(code = demoCode, 
                       constants = list(n = 4),
                       data = list(x = c(-1, -2, 1, 2)), 
                       inits = list(mu = rnorm(1)),
                       monitors = param_names,
                       nchains = 2, 
                       niter = 1000,
                       nburnin = 500)
#printErrors()
# pb is y is not recognized
#ls()
# assign y to global env
# https://stackoverflow.com/questions/9726705/assign-multiple-objects-to-globalenv-from-within-a-function
#assign("globvar", 20, envir = .GlobalEnv)

library(MCMCvis)
MCMCsummary(object = mcmc.out, round = 2)
```


## Useful resources

+ Official website [https://r-nimble.org](https://r-nimble.org)

+ User Manual [https://r-nimble.org/html_manual/cha-welcome-nimble.html](https://r-nimble.org/html_manual/cha-welcome-nimble.html) and [cheatsheet](https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf).

+ Users mailing list [https://groups.google.com/forum/#!forum/nimble-users](https://groups.google.com/forum/#!forum/nimble-users)

+ Training material [https://github.com/nimble-training](https://github.com/nimble-training)

+ Reference to cite when using nimble in a publication:

> de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, and R. Bodik (2017). [Programming With Models: Writing Statistical Algorithms for General Model Structures With NIMBLE](https://arxiv.org/pdf/1505.05093.pdf). *Journal of Computational and Graphical Statistics* **26** (2): 403–13.
